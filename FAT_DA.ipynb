{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FAT_DA.ipynb","provenance":[{"file_id":"18Gjp212SC99lVapgPXfVdbAXtv1uAN7q","timestamp":1611837844301}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"UiuP7Z3-bvGO"},"source":["# Setup\r\n"]},{"cell_type":"markdown","metadata":{"id":"e9omtVQe0R2z"},"source":["## Import libraries"]},{"cell_type":"code","metadata":{"id":"9rUAnl_Ma0xC"},"source":["import torch\r\n","import torch.nn as nn\r\n","import torch.nn.functional as F\r\n","import torch.optim as optim\r\n","import torchvision\r\n","from torchvision import transforms\r\n","from torchvision import datasets\r\n","from torch.utils.data import DataLoader\r\n","import random\r\n","random.seed(123)\r\n","\r\n","import time\r\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GBiHNZuWyEGM","executionInfo":{"status":"ok","timestamp":1611838854814,"user_tz":-60,"elapsed":1442,"user":{"displayName":"Thi Que-Lam Elisa Nguyen","photoUrl":"","userId":"14516834551380015257"}},"outputId":"7304fe08-9bd2-4621-d4ca-427c1e9f7c82"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kCE0XAUV0VFI"},"source":["## Check CUDA version"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CJeUYjy8bWfk","executionInfo":{"status":"ok","timestamp":1611838854816,"user_tz":-60,"elapsed":1400,"user":{"displayName":"Thi Que-Lam Elisa Nguyen","photoUrl":"","userId":"14516834551380015257"}},"outputId":"74991ea3-9ad9-4eb7-b47e-b21601ddf123"},"source":["\r\n","use_cuda = True\r\n","\r\n","if use_cuda and torch.cuda.is_available():\r\n","  device = torch.device('cuda')\r\n","else:\r\n","  device = torch.device('cpu')\r\n","\r\n","device"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"8-MZrlZ90aKf"},"source":["## Visualisation functions"]},{"cell_type":"code","metadata":{"id":"DrRTDEo_bZu0"},"source":["\r\n","%matplotlib inline\r\n","\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","\r\n","# Function to show an image tensor\r\n","def show(X):\r\n","    if X.dim() == 3 and X.size(2) == 3:\r\n","        plt.imshow(X.numpy())\r\n","        #plt.show()\r\n","    elif X.dim() == 2:\r\n","        plt.imshow(   X.numpy() , cmap='gray'  )\r\n","        #plt.show()\r\n","    else:\r\n","        print('WRONG TENSOR SIZE')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_8inPkgS0dyj"},"source":["## Download dataset"]},{"cell_type":"code","metadata":{"id":"cxOP14uSc_7E"},"source":["transform = transforms.Compose([transforms.ToTensor(),\r\n","                                transforms.Lambda(lambda x: x.squeeze()),  # Squeeze the data to remove the redundant channel dimension\r\n","                                ])\r\n","\r\n","trainset = torchvision.datasets.FashionMNIST(root='./data_FashionMNIST',\r\n","                                      train=True,\r\n","                                      download=True,\r\n","                                      transform=transform\r\n","                                      )\r\n","\r\n","testset = torchvision.datasets.FashionMNIST(root='./data_FashionMNIST',\r\n","                                     train=False,\r\n","                                     download=True,\r\n","                                     transform=transform\r\n","                                     )\r\n","\r\n","classes = (\r\n","    'T-shirt/top',\r\n","    'Trouser',\r\n","    'Pullover',\r\n","    'Dress',\r\n","    'Coat',\r\n","    'Sandal',\r\n","    'Shirt',\r\n","    'Sneaker',\r\n","    'Bag',\r\n","    'Ankle boot',\r\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y89pc5QX0g5p"},"source":["# Data preprocessing"]},{"cell_type":"markdown","metadata":{"id":"Rxf0nE3V0i6V"},"source":["## Augment the data"]},{"cell_type":"code","metadata":{"id":"LNNmJyX4uwh9"},"source":["train_hflip = transforms.functional.hflip(trainset.data)\r\n","\r\n","train_brightness = [transforms.functional.adjust_brightness(x, brightness_factor=random.choice([0.5, 0.75, 1.25, 1.5])) for x in trainset.data]\r\n","train_brightness = torch.stack(train_brightness)\r\n","\r\n","train_blur = transforms.functional.gaussian_blur(trainset.data, kernel_size=3)\r\n","\r\n","train_rotate = [transforms.functional.rotate(torch.unsqueeze(x, dim=0), angle=random.randrange(30,330,5)).squeeze() for x in trainset.data]\r\n","train_rotate = torch.stack(train_rotate)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q4ws2-l30m4D"},"source":["## Split training data into train and validation data"]},{"cell_type":"code","metadata":{"id":"diuqdGuYu1_r"},"source":["trainset.data = torch.cat((trainset.data, train_hflip, train_brightness, train_blur, train_rotate),dim=0)\r\n","trainset.targets = torch.cat((trainset.targets, trainset.targets, trainset.targets, trainset.targets, trainset.targets))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bIc6MGQ_dES8"},"source":["from sklearn.model_selection import train_test_split\r\n","targets = trainset.targets\r\n","train_idx, val_idx= train_test_split(np.arange(len(targets)),test_size=0.2,shuffle=True, stratify=targets, random_state=123)\r\n","\r\n","train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\r\n","val_sampler = torch.utils.data.SubsetRandomSampler(val_idx)\r\n","\r\n","batch_size=128\r\n","\r\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=train_sampler)\r\n","valloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=val_sampler)\r\n","testloader = torch.utils.data.DataLoader(testset,\r\n","                                         batch_size=batch_size,\r\n","                                         shuffle=True,\r\n","                                         drop_last=True\r\n","                                         )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rM4vgbQY0zuV"},"source":["# Model architecture"]},{"cell_type":"markdown","metadata":{"id":"zik0fWJW02CY"},"source":["## Create the model"]},{"cell_type":"code","metadata":{"id":"kEqjg3jobdBX"},"source":["class Net(nn.Module):\r\n","\r\n","    def __init__(self, kernel_size, pool_function, nfilters_conv1, nfilters_conv2):\r\n","\r\n","        super(Net, self).__init__()\r\n","        self.nfilters_conv2 = nfilters_conv2\r\n","\r\n","        # CL1:   1 x 28 x 28 (grayscale) -->    nfilters_conv1 x 28 x 28 \r\n","        self.conv1 = nn.Conv2d(1, nfilters_conv1,  kernel_size=kernel_size,  padding=kernel_size//2)\r\n","\r\n","        # MP1: nfilters_conv1 x 28 x 28  -->    nfilters_conv1 x 14 x 14\r\n","        self.pool1  = pool_function(2,2)\r\n","        \r\n","        # CL2:   nfilters_conv1 x 14 x 14  -->    nfilters_conv2 x 14 x 14\r\n","        self.conv2 = nn.Conv2d(nfilters_conv1,  nfilters_conv2,  kernel_size=kernel_size,  padding=kernel_size//2)\r\n","        \r\n","        # MP2:  nfilters_conv2 x 14 x 14 -->    nfilters_conv2 x 7 x 7\r\n","        self.pool2 = pool_function(2,2)\r\n","        \r\n","        # LL1:   nfilters_conv2 x 7 x 7 -->  100 \r\n","        self.linear1 = nn.Linear((nfilters_conv2*7*7), 100)\r\n","        \r\n","        # LL2:   100  -->  10 \r\n","        self.linear2 = nn.Linear(100,10)\r\n","\r\n","\r\n","    def forward(self, x):\r\n","        x = x.unsqueeze(1)\r\n","\r\n","        # CL1:   \r\n","        x = self.conv1(x)\r\n","        x = F.relu(x)\r\n","        \r\n","        # MP1: \r\n","        x = self.pool1(x)\r\n","        \r\n","        # CL2:   \r\n","        x = self.conv2(x)\r\n","        x = F.relu(x)\r\n","        \r\n","        # MP2: \r\n","        x = self.pool2(x)\r\n","\r\n","        # LL1:   \r\n","        x = x.view(-1, self.nfilters_conv2*7*7)\r\n","        x = self.linear1(x)\r\n","        x = F.relu(x)\r\n","        \r\n","        # LL2:  \r\n","        x = self.linear2(x)\r\n","    \r\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V_Be5wuG0D_N"},"source":["# best results from hyperparameter tuning\n","kernel_size= 5\n","pool_function = nn.AvgPool2d\n","nfilters_conv1 = 128\n","nfilters_conv2 = 128\n","\n","model_fatda = Net(kernel_size=kernel_size,pool_function=pool_function,nfilters_conv1=nfilters_conv1,nfilters_conv2=nfilters_conv2).to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","my_lr=0.01\n","\n","optimizer=torch.optim.Adam(model_fatda.parameters(), lr=my_lr) # change here"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kvbvwMpZbGuC"},"source":["# model = torch.load(\"/content/drive/MyDrive/Deep Learning/Project/model.pckl\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OFMuWfPbbLGS","executionInfo":{"status":"ok","timestamp":1611838874323,"user_tz":-60,"elapsed":20693,"user":{"displayName":"Thi Que-Lam Elisa Nguyen","photoUrl":"","userId":"14516834551380015257"}},"outputId":"e0d3a6d9-5434-4c66-cda9-2013ad80f356"},"source":["print(model_fatda)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["LeNet(\n","  (conv1): Conv2d(1, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","  (conv2): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","  (pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","  (linear1): Linear(in_features=6272, out_features=100, bias=True)\n","  (linear2): Linear(in_features=100, out_features=10, bias=True)\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7TjdOEDdb36K"},"source":["# Attack!"]},{"cell_type":"markdown","metadata":{"id":"VWNhMeQq04x-"},"source":["## Import libraries"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YLsi9F6Nbpqq","executionInfo":{"status":"ok","timestamp":1611838876400,"user_tz":-60,"elapsed":22740,"user":{"displayName":"Thi Que-Lam Elisa Nguyen","photoUrl":"","userId":"14516834551380015257"}},"outputId":"6d325582-15ce-4be0-9453-60d3e59acd4d"},"source":["!pip install advertorch"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: advertorch in /usr/local/lib/python3.6/dist-packages (0.2.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hNhbmqREb_ON"},"source":["from advertorch.attacks import PGDAttack"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rVNPgGfK08ym"},"source":["## Create adversary"]},{"cell_type":"code","metadata":{"id":"w08vXgmfcE3g"},"source":["# prepare your pytorch model as \"model\"\r\n","# prepare a batch of data and label as \"cln_data\" and \"true_label\"\r\n","# prepare attack instance\r\n","\r\n","adversary = PGDAttack(\r\n","    model_fatda, loss_fn=nn.CrossEntropyLoss(), eps=0.3,\r\n","    nb_iter=10, eps_iter=0.01, rand_init=True, clip_min=0.0, clip_max=1.0,\r\n","    targeted=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S5diexOoBxrL"},"source":["plot_valloss = []"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b1FDKB1m0_JV"},"source":["## Train the model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UaYh5LW-zMIB","executionInfo":{"status":"ok","timestamp":1611859642905,"user_tz":-60,"elapsed":20789164,"user":{"displayName":"Thi Que-Lam Elisa Nguyen","photoUrl":"","userId":"14516834551380015257"}},"outputId":"e5740431-0310-48a4-9d30-e2d6afef151e"},"source":["start=time.time()\n","\n","min_loss = 20 #initial loss to be overwritten\n","\n","epochs_no_improve = 0\n","patience = 20 # high patience to overcome local minima\n","\n","for epoch in range(1,200):\n","\n","  model_fatda.train()\n","  for i, (x_batch, y_batch) in enumerate(trainloader):\n","    x_batch, y_batch = x_batch.to(device), y_batch.to(device)  # Move the data to the device that is used\n","    x_adv = adversary.perturb(x_batch, y_batch)\n","    \n","    optimizer.zero_grad()  # Set all currenly stored gradients to zero \n","\n","    # randomly choose either perturbed data or clean data\n","    y_pred = model_fatda(x_adv)\n","\n","    loss = criterion(y_pred, y_batch)\n","\n","    loss.backward()\n","\n","    optimizer.step()\n","\n","    # Compute relevant metrics\n","    \n","    y_pred_max = torch.argmax(y_pred, dim=1)  # Get the labels with highest output probability\n","\n","    correct = torch.sum(torch.eq(y_pred_max, y_batch)).item()  # Count how many are equal to the true labels\n","\n","    elapsed = time.time() - start  # Keep track of how much time has elapsed\n","\n","    # Show progress every 50 batches \n","    if not i % 50:\n","      print(f'epoch: {epoch}, time: {elapsed:.3f}s, loss: {loss.item():.3f}, train accuracy: {correct / batch_size:.3f}')\n","\n","  model_fatda.eval()\n","  val_loss = 0\n","  counter = 0\n","  for i, (x_batch, y_batch) in enumerate(valloader):\n","    counter += 1\n","    x_batch, y_batch = x_batch.to(device), y_batch.to(device)  # Move the data to the device that is used\n","\n","    y_pred = model_fatda(x_batch)\n","    val_loss += criterion(y_pred, y_batch).item()\n","\n","  val_loss = val_loss/counter\n","  plot_valloss.append([val_loss, epoch])\n","  print(f'epoch: {epoch}, validation loss: {val_loss}')\n","  # save the model\n","  if val_loss < min_loss:\n","    torch.save(model_fatda, \"/content/drive/MyDrive/Deep Learning/Project/model_fatda.pckl\")\n","    epochs_no_improve = 0\n","    min_loss = val_loss\n","  else:\n","    epochs_no_improve += 1\n","    if epochs_no_improve == patience and epoch > 5:\n","      print(\"Early Stopping!\")\n","      break\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["epoch: 1, time: 0.960s, loss: 2.318, train accuracy: 0.023\n","epoch: 1, time: 10.914s, loss: 2.177, train accuracy: 0.125\n","epoch: 1, time: 20.929s, loss: 1.638, train accuracy: 0.391\n","epoch: 1, time: 31.011s, loss: 1.421, train accuracy: 0.500\n","epoch: 1, time: 41.140s, loss: 1.420, train accuracy: 0.469\n","epoch: 1, time: 51.317s, loss: 1.401, train accuracy: 0.523\n","epoch: 1, time: 61.540s, loss: 1.361, train accuracy: 0.492\n","epoch: 1, time: 71.843s, loss: 1.389, train accuracy: 0.461\n","epoch: 1, time: 82.205s, loss: 1.365, train accuracy: 0.477\n","epoch: 1, time: 92.598s, loss: 1.201, train accuracy: 0.492\n","epoch: 1, time: 103.050s, loss: 1.240, train accuracy: 0.484\n","epoch: 1, time: 113.564s, loss: 1.297, train accuracy: 0.445\n","epoch: 1, time: 124.108s, loss: 1.327, train accuracy: 0.484\n","epoch: 1, time: 134.697s, loss: 1.277, train accuracy: 0.453\n","epoch: 1, time: 145.308s, loss: 1.247, train accuracy: 0.430\n","epoch: 1, time: 155.967s, loss: 1.133, train accuracy: 0.562\n","epoch: 1, time: 166.696s, loss: 1.231, train accuracy: 0.445\n","epoch: 1, time: 177.441s, loss: 1.198, train accuracy: 0.523\n","epoch: 1, time: 188.201s, loss: 1.131, train accuracy: 0.594\n","epoch: 1, time: 198.933s, loss: 1.257, train accuracy: 0.523\n","epoch: 1, time: 209.671s, loss: 1.220, train accuracy: 0.516\n","epoch: 1, time: 220.383s, loss: 1.163, train accuracy: 0.562\n","epoch: 1, time: 231.073s, loss: 1.288, train accuracy: 0.469\n","epoch: 1, time: 241.782s, loss: 1.067, train accuracy: 0.625\n","epoch: 1, time: 252.487s, loss: 1.358, train accuracy: 0.523\n","epoch: 1, time: 263.197s, loss: 1.195, train accuracy: 0.555\n","epoch: 1, time: 273.905s, loss: 1.198, train accuracy: 0.539\n","epoch: 1, time: 284.621s, loss: 1.428, train accuracy: 0.406\n","epoch: 1, time: 295.321s, loss: 1.289, train accuracy: 0.477\n","epoch: 1, time: 306.032s, loss: 1.227, train accuracy: 0.516\n","epoch: 1, time: 316.758s, loss: 1.191, train accuracy: 0.531\n","epoch: 1, time: 327.444s, loss: 1.105, train accuracy: 0.570\n","epoch: 1, time: 338.144s, loss: 1.160, train accuracy: 0.531\n","epoch: 1, time: 348.833s, loss: 1.291, train accuracy: 0.477\n","epoch: 1, time: 359.516s, loss: 0.991, train accuracy: 0.562\n","epoch: 1, time: 370.208s, loss: 1.259, train accuracy: 0.531\n","epoch: 1, time: 380.896s, loss: 1.120, train accuracy: 0.586\n","epoch: 1, time: 391.577s, loss: 1.229, train accuracy: 0.508\n","epoch: 1, validation loss: 0.7986345774075115\n","epoch: 2, time: 405.701s, loss: 1.237, train accuracy: 0.531\n","epoch: 2, time: 416.351s, loss: 1.138, train accuracy: 0.586\n","epoch: 2, time: 427.062s, loss: 1.130, train accuracy: 0.523\n","epoch: 2, time: 437.801s, loss: 1.046, train accuracy: 0.562\n","epoch: 2, time: 448.497s, loss: 0.931, train accuracy: 0.633\n","epoch: 2, time: 459.128s, loss: 1.107, train accuracy: 0.531\n","epoch: 2, time: 469.749s, loss: 1.203, train accuracy: 0.523\n","epoch: 2, time: 480.386s, loss: 1.022, train accuracy: 0.648\n","epoch: 2, time: 491.082s, loss: 1.140, train accuracy: 0.539\n","epoch: 2, time: 501.774s, loss: 0.954, train accuracy: 0.609\n","epoch: 2, time: 512.455s, loss: 1.162, train accuracy: 0.492\n","epoch: 2, time: 523.132s, loss: 1.216, train accuracy: 0.484\n","epoch: 2, time: 533.790s, loss: 1.162, train accuracy: 0.531\n","epoch: 2, time: 544.429s, loss: 1.093, train accuracy: 0.562\n","epoch: 2, time: 555.094s, loss: 1.019, train accuracy: 0.609\n","epoch: 2, time: 565.745s, loss: 1.186, train accuracy: 0.531\n","epoch: 2, time: 576.391s, loss: 1.229, train accuracy: 0.477\n","epoch: 2, time: 587.042s, loss: 1.003, train accuracy: 0.578\n","epoch: 2, time: 597.710s, loss: 1.082, train accuracy: 0.562\n","epoch: 2, time: 608.369s, loss: 0.989, train accuracy: 0.578\n","epoch: 2, time: 619.035s, loss: 1.037, train accuracy: 0.586\n","epoch: 2, time: 629.703s, loss: 1.162, train accuracy: 0.578\n","epoch: 2, time: 640.362s, loss: 1.092, train accuracy: 0.602\n","epoch: 2, time: 651.032s, loss: 1.017, train accuracy: 0.570\n","epoch: 2, time: 661.709s, loss: 1.183, train accuracy: 0.516\n","epoch: 2, time: 672.399s, loss: 1.022, train accuracy: 0.562\n","epoch: 2, time: 683.066s, loss: 1.094, train accuracy: 0.602\n","epoch: 2, time: 693.723s, loss: 1.216, train accuracy: 0.516\n","epoch: 2, time: 704.391s, loss: 0.999, train accuracy: 0.555\n","epoch: 2, time: 715.044s, loss: 1.107, train accuracy: 0.609\n","epoch: 2, time: 725.692s, loss: 1.158, train accuracy: 0.531\n","epoch: 2, time: 736.321s, loss: 1.040, train accuracy: 0.555\n","epoch: 2, time: 746.971s, loss: 1.023, train accuracy: 0.570\n","epoch: 2, time: 757.633s, loss: 1.209, train accuracy: 0.555\n","epoch: 2, time: 768.257s, loss: 0.956, train accuracy: 0.594\n","epoch: 2, time: 778.905s, loss: 1.131, train accuracy: 0.531\n","epoch: 2, time: 789.545s, loss: 1.107, train accuracy: 0.531\n","epoch: 2, time: 800.201s, loss: 0.885, train accuracy: 0.641\n","epoch: 2, validation loss: 0.7729705448852164\n","epoch: 3, time: 813.722s, loss: 1.060, train accuracy: 0.586\n","epoch: 3, time: 824.341s, loss: 1.192, train accuracy: 0.555\n","epoch: 3, time: 835.013s, loss: 0.889, train accuracy: 0.672\n","epoch: 3, time: 845.688s, loss: 0.978, train accuracy: 0.641\n","epoch: 3, time: 856.328s, loss: 1.157, train accuracy: 0.531\n","epoch: 3, time: 866.990s, loss: 1.071, train accuracy: 0.562\n","epoch: 3, time: 877.660s, loss: 1.095, train accuracy: 0.570\n","epoch: 3, time: 888.318s, loss: 1.152, train accuracy: 0.531\n","epoch: 3, time: 898.951s, loss: 1.251, train accuracy: 0.547\n","epoch: 3, time: 909.596s, loss: 1.130, train accuracy: 0.609\n","epoch: 3, time: 920.227s, loss: 1.108, train accuracy: 0.570\n","epoch: 3, time: 930.852s, loss: 1.012, train accuracy: 0.562\n","epoch: 3, time: 941.493s, loss: 1.027, train accuracy: 0.555\n","epoch: 3, time: 952.170s, loss: 1.116, train accuracy: 0.562\n","epoch: 3, time: 962.820s, loss: 0.879, train accuracy: 0.656\n","epoch: 3, time: 973.491s, loss: 1.078, train accuracy: 0.531\n","epoch: 3, time: 984.174s, loss: 1.219, train accuracy: 0.500\n","epoch: 3, time: 994.874s, loss: 1.114, train accuracy: 0.508\n","epoch: 3, time: 1005.561s, loss: 1.055, train accuracy: 0.586\n","epoch: 3, time: 1016.232s, loss: 1.271, train accuracy: 0.547\n","epoch: 3, time: 1026.899s, loss: 1.090, train accuracy: 0.594\n","epoch: 3, time: 1037.532s, loss: 1.062, train accuracy: 0.562\n","epoch: 3, time: 1048.183s, loss: 0.988, train accuracy: 0.625\n","epoch: 3, time: 1058.833s, loss: 1.294, train accuracy: 0.469\n","epoch: 3, time: 1069.499s, loss: 1.256, train accuracy: 0.531\n","epoch: 3, time: 1080.155s, loss: 0.894, train accuracy: 0.578\n","epoch: 3, time: 1090.805s, loss: 0.938, train accuracy: 0.664\n","epoch: 3, time: 1101.449s, loss: 1.152, train accuracy: 0.531\n","epoch: 3, time: 1112.101s, loss: 1.098, train accuracy: 0.562\n","epoch: 3, time: 1122.743s, loss: 1.018, train accuracy: 0.547\n","epoch: 3, time: 1133.361s, loss: 1.095, train accuracy: 0.570\n","epoch: 3, time: 1144.002s, loss: 1.137, train accuracy: 0.570\n","epoch: 3, time: 1154.626s, loss: 1.060, train accuracy: 0.516\n","epoch: 3, time: 1165.240s, loss: 1.004, train accuracy: 0.633\n","epoch: 3, time: 1175.871s, loss: 1.102, train accuracy: 0.617\n","epoch: 3, time: 1186.527s, loss: 0.975, train accuracy: 0.602\n","epoch: 3, time: 1197.176s, loss: 1.228, train accuracy: 0.477\n","epoch: 3, time: 1207.840s, loss: 0.907, train accuracy: 0.641\n","epoch: 3, validation loss: 0.7652800460614121\n","epoch: 4, time: 1220.797s, loss: 1.164, train accuracy: 0.539\n","epoch: 4, time: 1231.426s, loss: 1.122, train accuracy: 0.586\n","epoch: 4, time: 1242.080s, loss: 1.094, train accuracy: 0.492\n","epoch: 4, time: 1252.739s, loss: 1.206, train accuracy: 0.586\n","epoch: 4, time: 1263.387s, loss: 1.076, train accuracy: 0.586\n","epoch: 4, time: 1274.069s, loss: 1.121, train accuracy: 0.594\n","epoch: 4, time: 1284.732s, loss: 1.249, train accuracy: 0.477\n","epoch: 4, time: 1295.396s, loss: 0.997, train accuracy: 0.586\n","epoch: 4, time: 1306.073s, loss: 1.142, train accuracy: 0.562\n","epoch: 4, time: 1316.730s, loss: 1.105, train accuracy: 0.562\n","epoch: 4, time: 1327.377s, loss: 1.015, train accuracy: 0.562\n","epoch: 4, time: 1338.027s, loss: 0.955, train accuracy: 0.648\n","epoch: 4, time: 1348.691s, loss: 1.363, train accuracy: 0.453\n","epoch: 4, time: 1359.343s, loss: 1.194, train accuracy: 0.547\n","epoch: 4, time: 1369.986s, loss: 1.179, train accuracy: 0.539\n","epoch: 4, time: 1380.626s, loss: 1.120, train accuracy: 0.578\n","epoch: 4, time: 1391.288s, loss: 1.013, train accuracy: 0.617\n","epoch: 4, time: 1401.949s, loss: 1.272, train accuracy: 0.531\n","epoch: 4, time: 1412.604s, loss: 1.042, train accuracy: 0.586\n","epoch: 4, time: 1423.261s, loss: 1.103, train accuracy: 0.539\n","epoch: 4, time: 1433.903s, loss: 1.147, train accuracy: 0.547\n","epoch: 4, time: 1444.564s, loss: 0.995, train accuracy: 0.570\n","epoch: 4, time: 1455.239s, loss: 1.052, train accuracy: 0.594\n","epoch: 4, time: 1465.897s, loss: 1.123, train accuracy: 0.555\n","epoch: 4, time: 1476.549s, loss: 1.087, train accuracy: 0.539\n","epoch: 4, time: 1487.205s, loss: 0.978, train accuracy: 0.609\n","epoch: 4, time: 1497.838s, loss: 1.086, train accuracy: 0.570\n","epoch: 4, time: 1508.486s, loss: 1.142, train accuracy: 0.570\n","epoch: 4, time: 1519.139s, loss: 1.114, train accuracy: 0.586\n","epoch: 4, time: 1529.815s, loss: 1.184, train accuracy: 0.555\n","epoch: 4, time: 1540.462s, loss: 1.087, train accuracy: 0.570\n","epoch: 4, time: 1551.116s, loss: 1.042, train accuracy: 0.578\n","epoch: 4, time: 1561.767s, loss: 1.083, train accuracy: 0.570\n","epoch: 4, time: 1572.407s, loss: 1.172, train accuracy: 0.547\n","epoch: 4, time: 1583.044s, loss: 1.105, train accuracy: 0.570\n","epoch: 4, time: 1593.677s, loss: 0.999, train accuracy: 0.625\n","epoch: 4, time: 1604.311s, loss: 1.031, train accuracy: 0.594\n","epoch: 4, time: 1614.958s, loss: 1.275, train accuracy: 0.562\n","epoch: 4, validation loss: 0.7808647901772945\n","epoch: 5, time: 1628.347s, loss: 0.937, train accuracy: 0.633\n","epoch: 5, time: 1638.985s, loss: 1.238, train accuracy: 0.500\n","epoch: 5, time: 1649.631s, loss: 1.084, train accuracy: 0.586\n","epoch: 5, time: 1660.316s, loss: 1.096, train accuracy: 0.578\n","epoch: 5, time: 1670.981s, loss: 1.189, train accuracy: 0.539\n","epoch: 5, time: 1681.628s, loss: 1.065, train accuracy: 0.594\n","epoch: 5, time: 1692.287s, loss: 1.186, train accuracy: 0.594\n","epoch: 5, time: 1702.934s, loss: 0.926, train accuracy: 0.648\n","epoch: 5, time: 1713.595s, loss: 1.122, train accuracy: 0.484\n","epoch: 5, time: 1724.278s, loss: 1.074, train accuracy: 0.562\n","epoch: 5, time: 1734.948s, loss: 1.048, train accuracy: 0.648\n","epoch: 5, time: 1745.626s, loss: 0.980, train accuracy: 0.570\n","epoch: 5, time: 1756.286s, loss: 0.945, train accuracy: 0.625\n","epoch: 5, time: 1766.955s, loss: 1.065, train accuracy: 0.555\n","epoch: 5, time: 1777.613s, loss: 1.140, train accuracy: 0.562\n","epoch: 5, time: 1788.288s, loss: 1.037, train accuracy: 0.586\n","epoch: 5, time: 1798.956s, loss: 1.152, train accuracy: 0.617\n","epoch: 5, time: 1809.630s, loss: 1.087, train accuracy: 0.570\n","epoch: 5, time: 1820.294s, loss: 1.130, train accuracy: 0.531\n","epoch: 5, time: 1830.974s, loss: 1.070, train accuracy: 0.531\n","epoch: 5, time: 1841.659s, loss: 1.176, train accuracy: 0.531\n","epoch: 5, time: 1852.329s, loss: 1.131, train accuracy: 0.562\n","epoch: 5, time: 1863.007s, loss: 0.985, train accuracy: 0.617\n","epoch: 5, time: 1873.686s, loss: 1.063, train accuracy: 0.555\n","epoch: 5, time: 1884.339s, loss: 1.013, train accuracy: 0.594\n","epoch: 5, time: 1894.985s, loss: 1.039, train accuracy: 0.586\n","epoch: 5, time: 1905.646s, loss: 1.091, train accuracy: 0.602\n","epoch: 5, time: 1916.306s, loss: 0.969, train accuracy: 0.617\n","epoch: 5, time: 1927.006s, loss: 1.092, train accuracy: 0.555\n","epoch: 5, time: 1937.678s, loss: 1.203, train accuracy: 0.523\n","epoch: 5, time: 1948.354s, loss: 1.066, train accuracy: 0.578\n","epoch: 5, time: 1959.026s, loss: 1.151, train accuracy: 0.547\n","epoch: 5, time: 1969.688s, loss: 1.200, train accuracy: 0.547\n","epoch: 5, time: 1980.351s, loss: 1.038, train accuracy: 0.578\n","epoch: 5, time: 1991.009s, loss: 1.140, train accuracy: 0.555\n","epoch: 5, time: 2001.648s, loss: 0.993, train accuracy: 0.617\n","epoch: 5, time: 2012.308s, loss: 1.046, train accuracy: 0.555\n","epoch: 5, time: 2022.970s, loss: 1.008, train accuracy: 0.609\n","epoch: 5, validation loss: 0.7560840110534798\n","epoch: 6, time: 2036.232s, loss: 0.945, train accuracy: 0.594\n","epoch: 6, time: 2046.871s, loss: 1.011, train accuracy: 0.539\n","epoch: 6, time: 2057.533s, loss: 1.141, train accuracy: 0.547\n","epoch: 6, time: 2068.221s, loss: 0.964, train accuracy: 0.602\n","epoch: 6, time: 2078.878s, loss: 1.069, train accuracy: 0.570\n","epoch: 6, time: 2089.505s, loss: 1.105, train accuracy: 0.531\n","epoch: 6, time: 2100.150s, loss: 1.043, train accuracy: 0.539\n","epoch: 6, time: 2110.779s, loss: 1.024, train accuracy: 0.617\n","epoch: 6, time: 2121.410s, loss: 1.054, train accuracy: 0.570\n","epoch: 6, time: 2132.067s, loss: 1.205, train accuracy: 0.523\n","epoch: 6, time: 2142.742s, loss: 0.967, train accuracy: 0.555\n","epoch: 6, time: 2153.417s, loss: 1.036, train accuracy: 0.586\n","epoch: 6, time: 2164.075s, loss: 1.101, train accuracy: 0.594\n","epoch: 6, time: 2174.744s, loss: 1.022, train accuracy: 0.508\n","epoch: 6, time: 2185.433s, loss: 1.137, train accuracy: 0.547\n","epoch: 6, time: 2196.098s, loss: 1.048, train accuracy: 0.594\n","epoch: 6, time: 2206.752s, loss: 1.025, train accuracy: 0.555\n","epoch: 6, time: 2217.420s, loss: 1.029, train accuracy: 0.594\n","epoch: 6, time: 2228.087s, loss: 1.007, train accuracy: 0.602\n","epoch: 6, time: 2238.749s, loss: 1.258, train accuracy: 0.484\n","epoch: 6, time: 2249.396s, loss: 1.221, train accuracy: 0.484\n","epoch: 6, time: 2260.067s, loss: 1.087, train accuracy: 0.602\n","epoch: 6, time: 2270.728s, loss: 1.049, train accuracy: 0.539\n","epoch: 6, time: 2281.390s, loss: 1.027, train accuracy: 0.648\n","epoch: 6, time: 2292.026s, loss: 1.061, train accuracy: 0.570\n","epoch: 6, time: 2302.700s, loss: 0.993, train accuracy: 0.586\n","epoch: 6, time: 2313.346s, loss: 0.905, train accuracy: 0.617\n","epoch: 6, time: 2323.990s, loss: 1.020, train accuracy: 0.625\n","epoch: 6, time: 2334.649s, loss: 1.136, train accuracy: 0.531\n","epoch: 6, time: 2345.283s, loss: 1.071, train accuracy: 0.570\n","epoch: 6, time: 2355.919s, loss: 1.024, train accuracy: 0.578\n","epoch: 6, time: 2366.577s, loss: 0.895, train accuracy: 0.656\n","epoch: 6, time: 2377.212s, loss: 1.016, train accuracy: 0.570\n","epoch: 6, time: 2387.830s, loss: 0.887, train accuracy: 0.625\n","epoch: 6, time: 2398.486s, loss: 1.049, train accuracy: 0.578\n","epoch: 6, time: 2409.135s, loss: 0.913, train accuracy: 0.625\n","epoch: 6, time: 2419.770s, loss: 1.007, train accuracy: 0.578\n","epoch: 6, time: 2430.408s, loss: 1.002, train accuracy: 0.617\n","epoch: 6, validation loss: 0.7675409611862606\n","epoch: 7, time: 2443.677s, loss: 0.992, train accuracy: 0.594\n","epoch: 7, time: 2454.275s, loss: 1.087, train accuracy: 0.586\n","epoch: 7, time: 2464.927s, loss: 0.912, train accuracy: 0.617\n","epoch: 7, time: 2475.579s, loss: 1.082, train accuracy: 0.555\n","epoch: 7, time: 2486.264s, loss: 0.943, train accuracy: 0.625\n","epoch: 7, time: 2496.927s, loss: 0.967, train accuracy: 0.625\n","epoch: 7, time: 2507.567s, loss: 1.011, train accuracy: 0.617\n","epoch: 7, time: 2518.211s, loss: 0.960, train accuracy: 0.633\n","epoch: 7, time: 2528.832s, loss: 0.857, train accuracy: 0.680\n","epoch: 7, time: 2539.453s, loss: 1.113, train accuracy: 0.547\n","epoch: 7, time: 2550.083s, loss: 1.061, train accuracy: 0.633\n","epoch: 7, time: 2560.725s, loss: 0.947, train accuracy: 0.625\n","epoch: 7, time: 2571.395s, loss: 0.954, train accuracy: 0.602\n","epoch: 7, time: 2582.060s, loss: 1.047, train accuracy: 0.586\n","epoch: 7, time: 2592.731s, loss: 1.045, train accuracy: 0.508\n","epoch: 7, time: 2603.384s, loss: 1.085, train accuracy: 0.539\n","epoch: 7, time: 2614.049s, loss: 1.103, train accuracy: 0.539\n","epoch: 7, time: 2624.715s, loss: 1.012, train accuracy: 0.602\n","epoch: 7, time: 2635.398s, loss: 1.115, train accuracy: 0.508\n","epoch: 7, time: 2646.048s, loss: 1.053, train accuracy: 0.609\n","epoch: 7, time: 2656.718s, loss: 0.981, train accuracy: 0.648\n","epoch: 7, time: 2667.366s, loss: 1.014, train accuracy: 0.555\n","epoch: 7, time: 2678.003s, loss: 1.120, train accuracy: 0.531\n","epoch: 7, time: 2688.649s, loss: 1.023, train accuracy: 0.602\n","epoch: 7, time: 2699.288s, loss: 0.934, train accuracy: 0.594\n","epoch: 7, time: 2709.909s, loss: 1.106, train accuracy: 0.586\n","epoch: 7, time: 2720.547s, loss: 1.204, train accuracy: 0.523\n","epoch: 7, time: 2731.187s, loss: 1.174, train accuracy: 0.492\n","epoch: 7, time: 2741.831s, loss: 0.964, train accuracy: 0.555\n","epoch: 7, time: 2752.474s, loss: 1.061, train accuracy: 0.586\n","epoch: 7, time: 2763.135s, loss: 1.157, train accuracy: 0.531\n","epoch: 7, time: 2773.784s, loss: 1.044, train accuracy: 0.570\n","epoch: 7, time: 2784.426s, loss: 1.063, train accuracy: 0.578\n","epoch: 7, time: 2795.060s, loss: 1.186, train accuracy: 0.586\n","epoch: 7, time: 2805.742s, loss: 0.946, train accuracy: 0.648\n","epoch: 7, time: 2816.394s, loss: 0.951, train accuracy: 0.594\n","epoch: 7, time: 2827.049s, loss: 0.999, train accuracy: 0.648\n","epoch: 7, time: 2837.688s, loss: 1.124, train accuracy: 0.555\n","epoch: 7, validation loss: 0.7542840495292567\n","epoch: 8, time: 2850.868s, loss: 1.044, train accuracy: 0.562\n","epoch: 8, time: 2861.489s, loss: 1.038, train accuracy: 0.570\n","epoch: 8, time: 2872.155s, loss: 0.977, train accuracy: 0.516\n","epoch: 8, time: 2882.850s, loss: 1.041, train accuracy: 0.539\n","epoch: 8, time: 2893.529s, loss: 1.013, train accuracy: 0.539\n","epoch: 8, time: 2904.181s, loss: 0.955, train accuracy: 0.609\n","epoch: 8, time: 2914.842s, loss: 0.867, train accuracy: 0.656\n","epoch: 8, time: 2925.482s, loss: 1.044, train accuracy: 0.570\n","epoch: 8, time: 2936.108s, loss: 1.122, train accuracy: 0.547\n","epoch: 8, time: 2946.742s, loss: 1.097, train accuracy: 0.578\n","epoch: 8, time: 2957.366s, loss: 0.966, train accuracy: 0.625\n","epoch: 8, time: 2968.014s, loss: 1.218, train accuracy: 0.539\n","epoch: 8, time: 2978.639s, loss: 0.987, train accuracy: 0.617\n","epoch: 8, time: 2989.268s, loss: 0.931, train accuracy: 0.609\n","epoch: 8, time: 2999.902s, loss: 1.024, train accuracy: 0.555\n","epoch: 8, time: 3010.540s, loss: 0.974, train accuracy: 0.672\n","epoch: 8, time: 3021.183s, loss: 1.118, train accuracy: 0.531\n","epoch: 8, time: 3031.838s, loss: 1.006, train accuracy: 0.586\n","epoch: 8, time: 3042.488s, loss: 1.136, train accuracy: 0.633\n","epoch: 8, time: 3053.152s, loss: 1.189, train accuracy: 0.539\n","epoch: 8, time: 3063.843s, loss: 1.028, train accuracy: 0.617\n","epoch: 8, time: 3074.510s, loss: 0.960, train accuracy: 0.531\n","epoch: 8, time: 3085.177s, loss: 1.009, train accuracy: 0.562\n","epoch: 8, time: 3095.851s, loss: 1.108, train accuracy: 0.508\n","epoch: 8, time: 3106.503s, loss: 1.117, train accuracy: 0.555\n","epoch: 8, time: 3117.145s, loss: 0.895, train accuracy: 0.578\n","epoch: 8, time: 3127.781s, loss: 0.971, train accuracy: 0.602\n","epoch: 8, time: 3138.424s, loss: 0.989, train accuracy: 0.609\n","epoch: 8, time: 3149.089s, loss: 1.021, train accuracy: 0.609\n","epoch: 8, time: 3159.717s, loss: 1.201, train accuracy: 0.531\n","epoch: 8, time: 3170.380s, loss: 1.089, train accuracy: 0.516\n","epoch: 8, time: 3180.994s, loss: 1.225, train accuracy: 0.492\n","epoch: 8, time: 3191.627s, loss: 1.181, train accuracy: 0.516\n","epoch: 8, time: 3202.246s, loss: 1.216, train accuracy: 0.508\n","epoch: 8, time: 3212.868s, loss: 0.940, train accuracy: 0.570\n","epoch: 8, time: 3223.493s, loss: 1.011, train accuracy: 0.547\n","epoch: 8, time: 3234.125s, loss: 1.080, train accuracy: 0.578\n","epoch: 8, time: 3244.776s, loss: 1.191, train accuracy: 0.609\n","epoch: 8, validation loss: 0.7536456071491688\n","epoch: 9, time: 3258.079s, loss: 1.115, train accuracy: 0.570\n","epoch: 9, time: 3268.706s, loss: 1.033, train accuracy: 0.594\n","epoch: 9, time: 3279.380s, loss: 1.005, train accuracy: 0.609\n","epoch: 9, time: 3290.076s, loss: 0.948, train accuracy: 0.633\n","epoch: 9, time: 3300.743s, loss: 0.935, train accuracy: 0.617\n","epoch: 9, time: 3311.387s, loss: 1.001, train accuracy: 0.641\n","epoch: 9, time: 3321.996s, loss: 1.004, train accuracy: 0.594\n","epoch: 9, time: 3332.629s, loss: 1.124, train accuracy: 0.562\n","epoch: 9, time: 3343.260s, loss: 1.243, train accuracy: 0.547\n","epoch: 9, time: 3353.924s, loss: 1.026, train accuracy: 0.555\n","epoch: 9, time: 3364.589s, loss: 0.989, train accuracy: 0.578\n","epoch: 9, time: 3375.249s, loss: 1.095, train accuracy: 0.531\n","epoch: 9, time: 3385.928s, loss: 1.028, train accuracy: 0.617\n","epoch: 9, time: 3396.603s, loss: 0.989, train accuracy: 0.594\n","epoch: 9, time: 3407.278s, loss: 1.029, train accuracy: 0.570\n","epoch: 9, time: 3417.942s, loss: 1.048, train accuracy: 0.578\n","epoch: 9, time: 3428.586s, loss: 1.014, train accuracy: 0.586\n","epoch: 9, time: 3439.249s, loss: 1.140, train accuracy: 0.523\n","epoch: 9, time: 3449.921s, loss: 1.004, train accuracy: 0.625\n","epoch: 9, time: 3460.610s, loss: 1.193, train accuracy: 0.484\n","epoch: 9, time: 3471.286s, loss: 1.043, train accuracy: 0.609\n","epoch: 9, time: 3481.980s, loss: 1.064, train accuracy: 0.562\n","epoch: 9, time: 3492.645s, loss: 0.996, train accuracy: 0.570\n","epoch: 9, time: 3503.323s, loss: 1.050, train accuracy: 0.547\n","epoch: 9, time: 3513.997s, loss: 0.987, train accuracy: 0.570\n","epoch: 9, time: 3524.653s, loss: 0.902, train accuracy: 0.562\n","epoch: 9, time: 3535.297s, loss: 1.066, train accuracy: 0.648\n","epoch: 9, time: 3545.978s, loss: 0.944, train accuracy: 0.602\n","epoch: 9, time: 3556.635s, loss: 1.102, train accuracy: 0.570\n","epoch: 9, time: 3567.307s, loss: 0.996, train accuracy: 0.586\n","epoch: 9, time: 3577.984s, loss: 1.088, train accuracy: 0.586\n","epoch: 9, time: 3588.677s, loss: 1.091, train accuracy: 0.586\n","epoch: 9, time: 3599.354s, loss: 1.101, train accuracy: 0.516\n","epoch: 9, time: 3610.042s, loss: 1.103, train accuracy: 0.562\n","epoch: 9, time: 3620.736s, loss: 1.125, train accuracy: 0.570\n","epoch: 9, time: 3631.419s, loss: 1.015, train accuracy: 0.578\n","epoch: 9, time: 3642.084s, loss: 0.944, train accuracy: 0.633\n","epoch: 9, time: 3652.769s, loss: 1.117, train accuracy: 0.531\n","epoch: 9, validation loss: 0.7658484185428254\n","epoch: 10, time: 3665.595s, loss: 1.068, train accuracy: 0.602\n","epoch: 10, time: 3676.219s, loss: 0.975, train accuracy: 0.586\n","epoch: 10, time: 3686.868s, loss: 1.095, train accuracy: 0.609\n","epoch: 10, time: 3697.527s, loss: 1.024, train accuracy: 0.586\n","epoch: 10, time: 3708.175s, loss: 1.034, train accuracy: 0.617\n","epoch: 10, time: 3718.811s, loss: 1.124, train accuracy: 0.508\n","epoch: 10, time: 3729.449s, loss: 1.038, train accuracy: 0.602\n","epoch: 10, time: 3740.071s, loss: 1.029, train accuracy: 0.656\n","epoch: 10, time: 3750.717s, loss: 0.990, train accuracy: 0.547\n","epoch: 10, time: 3761.362s, loss: 0.864, train accuracy: 0.625\n","epoch: 10, time: 3772.033s, loss: 0.965, train accuracy: 0.578\n","epoch: 10, time: 3782.690s, loss: 0.886, train accuracy: 0.633\n","epoch: 10, time: 3793.330s, loss: 1.009, train accuracy: 0.617\n","epoch: 10, time: 3803.973s, loss: 1.240, train accuracy: 0.445\n","epoch: 10, time: 3814.614s, loss: 0.998, train accuracy: 0.594\n","epoch: 10, time: 3825.260s, loss: 1.088, train accuracy: 0.578\n","epoch: 10, time: 3835.915s, loss: 0.997, train accuracy: 0.578\n","epoch: 10, time: 3846.559s, loss: 1.205, train accuracy: 0.531\n","epoch: 10, time: 3857.250s, loss: 1.008, train accuracy: 0.617\n","epoch: 10, time: 3867.907s, loss: 0.854, train accuracy: 0.656\n","epoch: 10, time: 3878.533s, loss: 1.006, train accuracy: 0.602\n","epoch: 10, time: 3889.177s, loss: 1.083, train accuracy: 0.625\n","epoch: 10, time: 3899.844s, loss: 0.959, train accuracy: 0.625\n","epoch: 10, time: 3910.484s, loss: 0.936, train accuracy: 0.656\n","epoch: 10, time: 3921.129s, loss: 1.039, train accuracy: 0.617\n","epoch: 10, time: 3931.767s, loss: 1.151, train accuracy: 0.555\n","epoch: 10, time: 3942.432s, loss: 0.947, train accuracy: 0.648\n","epoch: 10, time: 3953.118s, loss: 0.872, train accuracy: 0.656\n","epoch: 10, time: 3963.785s, loss: 0.894, train accuracy: 0.656\n","epoch: 10, time: 3974.433s, loss: 1.109, train accuracy: 0.562\n","epoch: 10, time: 3985.077s, loss: 1.070, train accuracy: 0.570\n","epoch: 10, time: 3995.717s, loss: 0.986, train accuracy: 0.648\n","epoch: 10, time: 4006.385s, loss: 0.990, train accuracy: 0.602\n","epoch: 10, time: 4017.030s, loss: 0.996, train accuracy: 0.617\n","epoch: 10, time: 4027.691s, loss: 0.994, train accuracy: 0.562\n","epoch: 10, time: 4038.356s, loss: 1.162, train accuracy: 0.539\n","epoch: 10, time: 4049.027s, loss: 1.140, train accuracy: 0.578\n","epoch: 10, time: 4059.682s, loss: 1.090, train accuracy: 0.586\n","epoch: 10, validation loss: 0.7685696748273967\n","epoch: 11, time: 4072.613s, loss: 1.124, train accuracy: 0.516\n","epoch: 11, time: 4083.256s, loss: 1.060, train accuracy: 0.586\n","epoch: 11, time: 4093.914s, loss: 1.134, train accuracy: 0.484\n","epoch: 11, time: 4104.577s, loss: 0.973, train accuracy: 0.555\n","epoch: 11, time: 4115.241s, loss: 1.122, train accuracy: 0.547\n","epoch: 11, time: 4125.905s, loss: 0.965, train accuracy: 0.594\n","epoch: 11, time: 4136.564s, loss: 0.981, train accuracy: 0.578\n","epoch: 11, time: 4147.246s, loss: 1.078, train accuracy: 0.547\n","epoch: 11, time: 4157.929s, loss: 1.161, train accuracy: 0.531\n","epoch: 11, time: 4168.611s, loss: 1.117, train accuracy: 0.578\n","epoch: 11, time: 4179.283s, loss: 0.969, train accuracy: 0.625\n","epoch: 11, time: 4189.944s, loss: 1.042, train accuracy: 0.547\n","epoch: 11, time: 4200.605s, loss: 0.967, train accuracy: 0.609\n","epoch: 11, time: 4211.282s, loss: 1.045, train accuracy: 0.594\n","epoch: 11, time: 4221.956s, loss: 0.828, train accuracy: 0.656\n","epoch: 11, time: 4232.616s, loss: 1.012, train accuracy: 0.609\n","epoch: 11, time: 4243.261s, loss: 1.040, train accuracy: 0.609\n","epoch: 11, time: 4253.903s, loss: 1.029, train accuracy: 0.609\n","epoch: 11, time: 4264.568s, loss: 0.830, train accuracy: 0.656\n","epoch: 11, time: 4275.240s, loss: 1.125, train accuracy: 0.594\n","epoch: 11, time: 4285.902s, loss: 0.883, train accuracy: 0.617\n","epoch: 11, time: 4296.540s, loss: 1.112, train accuracy: 0.516\n","epoch: 11, time: 4307.184s, loss: 0.922, train accuracy: 0.664\n","epoch: 11, time: 4317.826s, loss: 1.007, train accuracy: 0.586\n","epoch: 11, time: 4328.467s, loss: 1.122, train accuracy: 0.539\n","epoch: 11, time: 4339.141s, loss: 1.109, train accuracy: 0.617\n","epoch: 11, time: 4349.817s, loss: 0.960, train accuracy: 0.602\n","epoch: 11, time: 4360.487s, loss: 1.036, train accuracy: 0.609\n","epoch: 11, time: 4371.136s, loss: 0.878, train accuracy: 0.594\n","epoch: 11, time: 4381.804s, loss: 1.025, train accuracy: 0.570\n","epoch: 11, time: 4392.482s, loss: 1.025, train accuracy: 0.555\n","epoch: 11, time: 4403.163s, loss: 1.094, train accuracy: 0.562\n","epoch: 11, time: 4413.841s, loss: 1.031, train accuracy: 0.594\n","epoch: 11, time: 4424.486s, loss: 0.944, train accuracy: 0.625\n","epoch: 11, time: 4435.128s, loss: 0.982, train accuracy: 0.562\n","epoch: 11, time: 4445.790s, loss: 1.033, train accuracy: 0.555\n","epoch: 11, time: 4456.454s, loss: 0.826, train accuracy: 0.688\n","epoch: 11, time: 4467.130s, loss: 1.008, train accuracy: 0.625\n","epoch: 11, validation loss: 0.7703659552246777\n","epoch: 12, time: 4480.611s, loss: 0.977, train accuracy: 0.578\n","epoch: 12, time: 4491.241s, loss: 1.039, train accuracy: 0.602\n","epoch: 12, time: 4501.902s, loss: 1.113, train accuracy: 0.578\n","epoch: 12, time: 4512.570s, loss: 0.954, train accuracy: 0.641\n","epoch: 12, time: 4523.221s, loss: 1.025, train accuracy: 0.578\n","epoch: 12, time: 4533.857s, loss: 1.177, train accuracy: 0.484\n","epoch: 12, time: 4544.469s, loss: 1.048, train accuracy: 0.609\n","epoch: 12, time: 4555.094s, loss: 1.117, train accuracy: 0.555\n","epoch: 12, time: 4565.727s, loss: 0.973, train accuracy: 0.656\n","epoch: 12, time: 4576.367s, loss: 1.088, train accuracy: 0.547\n","epoch: 12, time: 4587.021s, loss: 0.893, train accuracy: 0.625\n","epoch: 12, time: 4597.678s, loss: 0.918, train accuracy: 0.617\n","epoch: 12, time: 4608.347s, loss: 1.026, train accuracy: 0.555\n","epoch: 12, time: 4618.994s, loss: 0.959, train accuracy: 0.625\n","epoch: 12, time: 4629.652s, loss: 0.800, train accuracy: 0.648\n","epoch: 12, time: 4640.353s, loss: 0.946, train accuracy: 0.609\n","epoch: 12, time: 4651.050s, loss: 0.894, train accuracy: 0.633\n","epoch: 12, time: 4661.722s, loss: 1.047, train accuracy: 0.578\n","epoch: 12, time: 4672.407s, loss: 0.886, train accuracy: 0.617\n","epoch: 12, time: 4683.064s, loss: 1.031, train accuracy: 0.539\n","epoch: 12, time: 4693.741s, loss: 0.981, train accuracy: 0.641\n","epoch: 12, time: 4704.409s, loss: 1.114, train accuracy: 0.578\n","epoch: 12, time: 4715.073s, loss: 1.107, train accuracy: 0.617\n","epoch: 12, time: 4725.749s, loss: 1.252, train accuracy: 0.523\n","epoch: 12, time: 4736.424s, loss: 0.922, train accuracy: 0.586\n","epoch: 12, time: 4747.073s, loss: 1.109, train accuracy: 0.516\n","epoch: 12, time: 4757.735s, loss: 0.882, train accuracy: 0.641\n","epoch: 12, time: 4768.404s, loss: 1.220, train accuracy: 0.531\n","epoch: 12, time: 4779.071s, loss: 1.032, train accuracy: 0.617\n","epoch: 12, time: 4789.730s, loss: 1.064, train accuracy: 0.570\n","epoch: 12, time: 4800.400s, loss: 1.142, train accuracy: 0.570\n","epoch: 12, time: 4811.075s, loss: 1.069, train accuracy: 0.578\n","epoch: 12, time: 4821.753s, loss: 1.251, train accuracy: 0.539\n","epoch: 12, time: 4832.421s, loss: 1.000, train accuracy: 0.672\n","epoch: 12, time: 4843.086s, loss: 1.040, train accuracy: 0.562\n","epoch: 12, time: 4853.761s, loss: 0.895, train accuracy: 0.617\n","epoch: 12, time: 4864.401s, loss: 0.927, train accuracy: 0.648\n","epoch: 12, time: 4875.084s, loss: 0.982, train accuracy: 0.625\n","epoch: 12, validation loss: 0.7720126643109677\n","epoch: 13, time: 4888.077s, loss: 1.068, train accuracy: 0.586\n","epoch: 13, time: 4898.719s, loss: 0.886, train accuracy: 0.594\n","epoch: 13, time: 4909.367s, loss: 0.882, train accuracy: 0.695\n","epoch: 13, time: 4920.020s, loss: 1.116, train accuracy: 0.555\n","epoch: 13, time: 4930.669s, loss: 1.002, train accuracy: 0.531\n","epoch: 13, time: 4941.333s, loss: 1.131, train accuracy: 0.531\n","epoch: 13, time: 4951.995s, loss: 1.175, train accuracy: 0.547\n","epoch: 13, time: 4962.691s, loss: 1.019, train accuracy: 0.578\n","epoch: 13, time: 4973.375s, loss: 0.967, train accuracy: 0.602\n","epoch: 13, time: 4984.067s, loss: 1.016, train accuracy: 0.617\n","epoch: 13, time: 4994.767s, loss: 1.300, train accuracy: 0.586\n","epoch: 13, time: 5005.421s, loss: 1.009, train accuracy: 0.508\n","epoch: 13, time: 5016.068s, loss: 1.073, train accuracy: 0.578\n","epoch: 13, time: 5026.736s, loss: 0.979, train accuracy: 0.594\n","epoch: 13, time: 5037.386s, loss: 1.070, train accuracy: 0.531\n","epoch: 13, time: 5048.052s, loss: 1.040, train accuracy: 0.562\n","epoch: 13, time: 5058.709s, loss: 0.966, train accuracy: 0.594\n","epoch: 13, time: 5069.373s, loss: 1.162, train accuracy: 0.523\n","epoch: 13, time: 5080.031s, loss: 0.925, train accuracy: 0.594\n","epoch: 13, time: 5090.695s, loss: 1.114, train accuracy: 0.570\n","epoch: 13, time: 5101.359s, loss: 1.145, train accuracy: 0.547\n","epoch: 13, time: 5111.990s, loss: 1.091, train accuracy: 0.586\n","epoch: 13, time: 5122.625s, loss: 1.138, train accuracy: 0.523\n","epoch: 13, time: 5133.265s, loss: 0.972, train accuracy: 0.633\n","epoch: 13, time: 5143.902s, loss: 1.129, train accuracy: 0.570\n","epoch: 13, time: 5154.535s, loss: 0.905, train accuracy: 0.648\n","epoch: 13, time: 5165.188s, loss: 0.840, train accuracy: 0.656\n","epoch: 13, time: 5175.859s, loss: 1.056, train accuracy: 0.609\n","epoch: 13, time: 5186.503s, loss: 1.025, train accuracy: 0.594\n","epoch: 13, time: 5197.162s, loss: 1.325, train accuracy: 0.453\n","epoch: 13, time: 5207.839s, loss: 1.021, train accuracy: 0.633\n","epoch: 13, time: 5218.489s, loss: 1.000, train accuracy: 0.570\n","epoch: 13, time: 5229.175s, loss: 0.959, train accuracy: 0.664\n","epoch: 13, time: 5239.818s, loss: 1.047, train accuracy: 0.586\n","epoch: 13, time: 5250.497s, loss: 1.019, train accuracy: 0.594\n","epoch: 13, time: 5261.152s, loss: 0.983, train accuracy: 0.625\n","epoch: 13, time: 5271.811s, loss: 1.041, train accuracy: 0.617\n","epoch: 13, time: 5282.467s, loss: 1.040, train accuracy: 0.578\n","epoch: 13, validation loss: 0.766272341010413\n","epoch: 14, time: 5295.466s, loss: 0.844, train accuracy: 0.641\n","epoch: 14, time: 5306.086s, loss: 0.999, train accuracy: 0.633\n","epoch: 14, time: 5316.729s, loss: 1.178, train accuracy: 0.578\n","epoch: 14, time: 5327.397s, loss: 0.999, train accuracy: 0.609\n","epoch: 14, time: 5338.079s, loss: 0.990, train accuracy: 0.609\n","epoch: 14, time: 5348.728s, loss: 0.925, train accuracy: 0.641\n","epoch: 14, time: 5359.377s, loss: 1.054, train accuracy: 0.562\n","epoch: 14, time: 5370.023s, loss: 1.182, train accuracy: 0.562\n","epoch: 14, time: 5380.678s, loss: 1.133, train accuracy: 0.547\n","epoch: 14, time: 5391.326s, loss: 1.143, train accuracy: 0.562\n","epoch: 14, time: 5401.958s, loss: 1.067, train accuracy: 0.531\n","epoch: 14, time: 5412.599s, loss: 1.205, train accuracy: 0.539\n","epoch: 14, time: 5423.237s, loss: 1.067, train accuracy: 0.578\n","epoch: 14, time: 5433.874s, loss: 1.203, train accuracy: 0.531\n","epoch: 14, time: 5444.504s, loss: 0.856, train accuracy: 0.695\n","epoch: 14, time: 5455.156s, loss: 1.030, train accuracy: 0.617\n","epoch: 14, time: 5465.794s, loss: 0.923, train accuracy: 0.625\n","epoch: 14, time: 5476.454s, loss: 0.946, train accuracy: 0.625\n","epoch: 14, time: 5487.107s, loss: 0.843, train accuracy: 0.633\n","epoch: 14, time: 5497.777s, loss: 0.937, train accuracy: 0.641\n","epoch: 14, time: 5508.429s, loss: 1.003, train accuracy: 0.609\n","epoch: 14, time: 5519.078s, loss: 1.238, train accuracy: 0.508\n","epoch: 14, time: 5529.752s, loss: 1.078, train accuracy: 0.594\n","epoch: 14, time: 5540.404s, loss: 1.019, train accuracy: 0.539\n","epoch: 14, time: 5551.056s, loss: 1.055, train accuracy: 0.625\n","epoch: 14, time: 5561.709s, loss: 1.031, train accuracy: 0.539\n","epoch: 14, time: 5572.366s, loss: 0.992, train accuracy: 0.625\n","epoch: 14, time: 5583.029s, loss: 1.062, train accuracy: 0.609\n","epoch: 14, time: 5593.660s, loss: 0.945, train accuracy: 0.648\n","epoch: 14, time: 5604.310s, loss: 1.021, train accuracy: 0.570\n","epoch: 14, time: 5614.968s, loss: 0.974, train accuracy: 0.664\n","epoch: 14, time: 5625.623s, loss: 1.056, train accuracy: 0.578\n","epoch: 14, time: 5636.294s, loss: 0.912, train accuracy: 0.633\n","epoch: 14, time: 5646.959s, loss: 1.107, train accuracy: 0.539\n","epoch: 14, time: 5657.629s, loss: 1.031, train accuracy: 0.625\n","epoch: 14, time: 5668.280s, loss: 0.969, train accuracy: 0.617\n","epoch: 14, time: 5678.948s, loss: 0.934, train accuracy: 0.594\n","epoch: 14, time: 5689.594s, loss: 1.000, train accuracy: 0.641\n","epoch: 14, validation loss: 0.7830232899072074\n","epoch: 15, time: 5702.609s, loss: 1.122, train accuracy: 0.500\n","epoch: 15, time: 5713.229s, loss: 0.943, train accuracy: 0.602\n","epoch: 15, time: 5723.883s, loss: 1.000, train accuracy: 0.633\n","epoch: 15, time: 5734.545s, loss: 1.119, train accuracy: 0.508\n","epoch: 15, time: 5745.228s, loss: 0.962, train accuracy: 0.570\n","epoch: 15, time: 5755.922s, loss: 1.174, train accuracy: 0.508\n","epoch: 15, time: 5766.591s, loss: 1.052, train accuracy: 0.609\n","epoch: 15, time: 5777.249s, loss: 1.049, train accuracy: 0.609\n","epoch: 15, time: 5787.922s, loss: 1.102, train accuracy: 0.555\n","epoch: 15, time: 5798.584s, loss: 0.921, train accuracy: 0.562\n","epoch: 15, time: 5809.238s, loss: 0.905, train accuracy: 0.609\n","epoch: 15, time: 5819.877s, loss: 0.939, train accuracy: 0.609\n","epoch: 15, time: 5830.517s, loss: 1.161, train accuracy: 0.547\n","epoch: 15, time: 5841.162s, loss: 0.984, train accuracy: 0.617\n","epoch: 15, time: 5851.808s, loss: 1.075, train accuracy: 0.594\n","epoch: 15, time: 5862.437s, loss: 0.931, train accuracy: 0.625\n","epoch: 15, time: 5873.089s, loss: 0.814, train accuracy: 0.672\n","epoch: 15, time: 5883.731s, loss: 1.044, train accuracy: 0.578\n","epoch: 15, time: 5894.392s, loss: 1.015, train accuracy: 0.609\n","epoch: 15, time: 5905.063s, loss: 1.139, train accuracy: 0.555\n","epoch: 15, time: 5915.702s, loss: 1.204, train accuracy: 0.539\n","epoch: 15, time: 5926.361s, loss: 1.039, train accuracy: 0.578\n","epoch: 15, time: 5937.024s, loss: 1.008, train accuracy: 0.609\n","epoch: 15, time: 5947.681s, loss: 1.062, train accuracy: 0.633\n","epoch: 15, time: 5958.346s, loss: 0.924, train accuracy: 0.633\n","epoch: 15, time: 5969.015s, loss: 0.958, train accuracy: 0.695\n","epoch: 15, time: 5979.681s, loss: 1.146, train accuracy: 0.586\n","epoch: 15, time: 5990.350s, loss: 1.088, train accuracy: 0.641\n","epoch: 15, time: 6001.016s, loss: 1.010, train accuracy: 0.617\n","epoch: 15, time: 6011.712s, loss: 0.939, train accuracy: 0.633\n","epoch: 15, time: 6022.386s, loss: 0.974, train accuracy: 0.570\n","epoch: 15, time: 6033.060s, loss: 1.098, train accuracy: 0.555\n","epoch: 15, time: 6043.735s, loss: 1.113, train accuracy: 0.555\n","epoch: 15, time: 6054.396s, loss: 0.909, train accuracy: 0.641\n","epoch: 15, time: 6065.083s, loss: 1.063, train accuracy: 0.609\n","epoch: 15, time: 6075.762s, loss: 1.106, train accuracy: 0.539\n","epoch: 15, time: 6086.423s, loss: 1.004, train accuracy: 0.586\n","epoch: 15, time: 6097.084s, loss: 1.045, train accuracy: 0.570\n","epoch: 15, validation loss: 0.7891853388184423\n","epoch: 16, time: 6110.189s, loss: 1.084, train accuracy: 0.641\n","epoch: 16, time: 6120.838s, loss: 1.032, train accuracy: 0.617\n","epoch: 16, time: 6131.517s, loss: 0.997, train accuracy: 0.641\n","epoch: 16, time: 6142.174s, loss: 1.003, train accuracy: 0.578\n","epoch: 16, time: 6152.853s, loss: 1.018, train accuracy: 0.539\n","epoch: 16, time: 6163.504s, loss: 0.941, train accuracy: 0.617\n","epoch: 16, time: 6174.164s, loss: 0.976, train accuracy: 0.641\n","epoch: 16, time: 6184.831s, loss: 1.081, train accuracy: 0.570\n","epoch: 16, time: 6195.501s, loss: 1.033, train accuracy: 0.555\n","epoch: 16, time: 6206.169s, loss: 1.071, train accuracy: 0.578\n","epoch: 16, time: 6216.847s, loss: 1.095, train accuracy: 0.547\n","epoch: 16, time: 6227.505s, loss: 1.028, train accuracy: 0.609\n","epoch: 16, time: 6238.189s, loss: 1.004, train accuracy: 0.602\n","epoch: 16, time: 6248.862s, loss: 1.114, train accuracy: 0.570\n","epoch: 16, time: 6259.501s, loss: 0.966, train accuracy: 0.602\n","epoch: 16, time: 6270.179s, loss: 1.000, train accuracy: 0.625\n","epoch: 16, time: 6280.842s, loss: 1.023, train accuracy: 0.539\n","epoch: 16, time: 6291.499s, loss: 1.046, train accuracy: 0.586\n","epoch: 16, time: 6302.159s, loss: 1.099, train accuracy: 0.617\n","epoch: 16, time: 6312.812s, loss: 0.944, train accuracy: 0.555\n","epoch: 16, time: 6323.476s, loss: 1.045, train accuracy: 0.562\n","epoch: 16, time: 6334.115s, loss: 0.940, train accuracy: 0.641\n","epoch: 16, time: 6344.773s, loss: 0.946, train accuracy: 0.602\n","epoch: 16, time: 6355.426s, loss: 0.978, train accuracy: 0.641\n","epoch: 16, time: 6366.065s, loss: 1.015, train accuracy: 0.648\n","epoch: 16, time: 6376.729s, loss: 1.030, train accuracy: 0.586\n","epoch: 16, time: 6387.385s, loss: 0.914, train accuracy: 0.664\n","epoch: 16, time: 6398.054s, loss: 0.993, train accuracy: 0.648\n","epoch: 16, time: 6408.717s, loss: 0.988, train accuracy: 0.570\n","epoch: 16, time: 6419.373s, loss: 0.984, train accuracy: 0.625\n","epoch: 16, time: 6430.053s, loss: 1.132, train accuracy: 0.562\n","epoch: 16, time: 6440.733s, loss: 1.062, train accuracy: 0.594\n","epoch: 16, time: 6451.432s, loss: 1.076, train accuracy: 0.508\n","epoch: 16, time: 6462.117s, loss: 1.090, train accuracy: 0.570\n","epoch: 16, time: 6472.797s, loss: 1.008, train accuracy: 0.586\n","epoch: 16, time: 6483.461s, loss: 1.177, train accuracy: 0.477\n","epoch: 16, time: 6494.130s, loss: 0.865, train accuracy: 0.688\n","epoch: 16, time: 6504.793s, loss: 0.980, train accuracy: 0.617\n","epoch: 16, validation loss: 0.8170422920540198\n","epoch: 17, time: 6518.176s, loss: 1.123, train accuracy: 0.555\n","epoch: 17, time: 6528.780s, loss: 0.937, train accuracy: 0.602\n","epoch: 17, time: 6539.424s, loss: 0.885, train accuracy: 0.680\n","epoch: 17, time: 6550.095s, loss: 0.987, train accuracy: 0.555\n","epoch: 17, time: 6560.782s, loss: 1.110, train accuracy: 0.531\n","epoch: 17, time: 6571.441s, loss: 0.979, train accuracy: 0.625\n","epoch: 17, time: 6582.096s, loss: 1.003, train accuracy: 0.609\n","epoch: 17, time: 6592.750s, loss: 0.922, train accuracy: 0.586\n","epoch: 17, time: 6603.372s, loss: 1.039, train accuracy: 0.531\n","epoch: 17, time: 6613.990s, loss: 0.973, train accuracy: 0.648\n","epoch: 17, time: 6624.628s, loss: 1.098, train accuracy: 0.555\n","epoch: 17, time: 6635.304s, loss: 1.053, train accuracy: 0.602\n","epoch: 17, time: 6645.945s, loss: 1.016, train accuracy: 0.594\n","epoch: 17, time: 6656.640s, loss: 1.079, train accuracy: 0.516\n","epoch: 17, time: 6667.318s, loss: 1.244, train accuracy: 0.492\n","epoch: 17, time: 6677.980s, loss: 1.016, train accuracy: 0.562\n","epoch: 17, time: 6688.655s, loss: 0.938, train accuracy: 0.594\n","epoch: 17, time: 6699.313s, loss: 0.959, train accuracy: 0.609\n","epoch: 17, time: 6709.974s, loss: 0.997, train accuracy: 0.570\n","epoch: 17, time: 6720.618s, loss: 0.939, train accuracy: 0.648\n","epoch: 17, time: 6731.284s, loss: 1.074, train accuracy: 0.586\n","epoch: 17, time: 6741.946s, loss: 1.132, train accuracy: 0.570\n","epoch: 17, time: 6752.644s, loss: 1.075, train accuracy: 0.562\n","epoch: 17, time: 6763.290s, loss: 0.991, train accuracy: 0.539\n","epoch: 17, time: 6773.956s, loss: 0.983, train accuracy: 0.602\n","epoch: 17, time: 6784.636s, loss: 1.067, train accuracy: 0.570\n","epoch: 17, time: 6795.277s, loss: 1.091, train accuracy: 0.555\n","epoch: 17, time: 6805.957s, loss: 1.017, train accuracy: 0.570\n","epoch: 17, time: 6816.619s, loss: 1.071, train accuracy: 0.555\n","epoch: 17, time: 6827.287s, loss: 1.133, train accuracy: 0.562\n","epoch: 17, time: 6837.946s, loss: 1.051, train accuracy: 0.609\n","epoch: 17, time: 6848.640s, loss: 1.030, train accuracy: 0.555\n","epoch: 17, time: 6859.297s, loss: 0.965, train accuracy: 0.562\n","epoch: 17, time: 6869.971s, loss: 1.107, train accuracy: 0.578\n","epoch: 17, time: 6880.673s, loss: 0.937, train accuracy: 0.586\n","epoch: 17, time: 6891.356s, loss: 1.078, train accuracy: 0.523\n","epoch: 17, time: 6902.035s, loss: 1.143, train accuracy: 0.508\n","epoch: 17, time: 6912.713s, loss: 0.985, train accuracy: 0.570\n","epoch: 17, validation loss: 0.7524909706258062\n","epoch: 18, time: 6925.927s, loss: 1.032, train accuracy: 0.594\n","epoch: 18, time: 6936.563s, loss: 0.953, train accuracy: 0.586\n","epoch: 18, time: 6947.235s, loss: 1.034, train accuracy: 0.617\n","epoch: 18, time: 6957.893s, loss: 1.102, train accuracy: 0.539\n","epoch: 18, time: 6968.563s, loss: 0.918, train accuracy: 0.625\n","epoch: 18, time: 6979.230s, loss: 1.048, train accuracy: 0.570\n","epoch: 18, time: 6989.910s, loss: 0.869, train accuracy: 0.680\n","epoch: 18, time: 7000.589s, loss: 0.986, train accuracy: 0.656\n","epoch: 18, time: 7011.265s, loss: 1.075, train accuracy: 0.602\n","epoch: 18, time: 7021.938s, loss: 1.048, train accuracy: 0.578\n","epoch: 18, time: 7032.639s, loss: 0.912, train accuracy: 0.625\n","epoch: 18, time: 7043.323s, loss: 1.059, train accuracy: 0.633\n","epoch: 18, time: 7053.970s, loss: 1.065, train accuracy: 0.570\n","epoch: 18, time: 7064.584s, loss: 0.992, train accuracy: 0.578\n","epoch: 18, time: 7075.200s, loss: 1.005, train accuracy: 0.578\n","epoch: 18, time: 7085.856s, loss: 1.145, train accuracy: 0.578\n","epoch: 18, time: 7096.543s, loss: 1.078, train accuracy: 0.547\n","epoch: 18, time: 7107.243s, loss: 0.969, train accuracy: 0.555\n","epoch: 18, time: 7117.930s, loss: 1.034, train accuracy: 0.562\n","epoch: 18, time: 7128.584s, loss: 0.999, train accuracy: 0.586\n","epoch: 18, time: 7139.240s, loss: 0.968, train accuracy: 0.656\n","epoch: 18, time: 7149.871s, loss: 0.983, train accuracy: 0.625\n","epoch: 18, time: 7160.493s, loss: 1.170, train accuracy: 0.547\n","epoch: 18, time: 7171.129s, loss: 1.156, train accuracy: 0.570\n","epoch: 18, time: 7181.758s, loss: 1.143, train accuracy: 0.555\n","epoch: 18, time: 7192.408s, loss: 1.090, train accuracy: 0.570\n","epoch: 18, time: 7203.068s, loss: 1.076, train accuracy: 0.547\n","epoch: 18, time: 7213.731s, loss: 1.077, train accuracy: 0.641\n","epoch: 18, time: 7224.409s, loss: 1.083, train accuracy: 0.609\n","epoch: 18, time: 7235.082s, loss: 1.003, train accuracy: 0.531\n","epoch: 18, time: 7245.746s, loss: 0.989, train accuracy: 0.625\n","epoch: 18, time: 7256.439s, loss: 1.071, train accuracy: 0.539\n","epoch: 18, time: 7267.133s, loss: 1.207, train accuracy: 0.523\n","epoch: 18, time: 7277.830s, loss: 0.976, train accuracy: 0.633\n","epoch: 18, time: 7288.517s, loss: 0.991, train accuracy: 0.594\n","epoch: 18, time: 7299.216s, loss: 1.032, train accuracy: 0.625\n","epoch: 18, time: 7309.900s, loss: 1.027, train accuracy: 0.602\n","epoch: 18, time: 7320.581s, loss: 1.090, train accuracy: 0.531\n","epoch: 18, validation loss: 0.7791710470531032\n","epoch: 19, time: 7333.699s, loss: 0.924, train accuracy: 0.641\n","epoch: 19, time: 7344.328s, loss: 0.948, train accuracy: 0.586\n","epoch: 19, time: 7354.984s, loss: 1.014, train accuracy: 0.594\n","epoch: 19, time: 7365.683s, loss: 1.081, train accuracy: 0.578\n","epoch: 19, time: 7376.362s, loss: 1.060, train accuracy: 0.586\n","epoch: 19, time: 7387.027s, loss: 1.015, train accuracy: 0.555\n","epoch: 19, time: 7397.682s, loss: 0.906, train accuracy: 0.648\n","epoch: 19, time: 7408.323s, loss: 0.962, train accuracy: 0.570\n","epoch: 19, time: 7418.958s, loss: 0.896, train accuracy: 0.609\n","epoch: 19, time: 7429.614s, loss: 0.980, train accuracy: 0.562\n","epoch: 19, time: 7440.300s, loss: 1.130, train accuracy: 0.523\n","epoch: 19, time: 7450.994s, loss: 0.960, train accuracy: 0.664\n","epoch: 19, time: 7461.691s, loss: 0.838, train accuracy: 0.680\n","epoch: 19, time: 7472.382s, loss: 1.060, train accuracy: 0.539\n","epoch: 19, time: 7483.083s, loss: 1.070, train accuracy: 0.578\n","epoch: 19, time: 7493.777s, loss: 1.074, train accuracy: 0.562\n","epoch: 19, time: 7504.461s, loss: 1.120, train accuracy: 0.570\n","epoch: 19, time: 7515.151s, loss: 1.092, train accuracy: 0.570\n","epoch: 19, time: 7525.847s, loss: 1.018, train accuracy: 0.633\n","epoch: 19, time: 7536.508s, loss: 1.118, train accuracy: 0.531\n","epoch: 19, time: 7547.192s, loss: 1.057, train accuracy: 0.586\n","epoch: 19, time: 7557.878s, loss: 1.001, train accuracy: 0.516\n","epoch: 19, time: 7568.567s, loss: 0.916, train accuracy: 0.609\n","epoch: 19, time: 7579.241s, loss: 1.054, train accuracy: 0.617\n","epoch: 19, time: 7589.924s, loss: 1.029, train accuracy: 0.617\n","epoch: 19, time: 7600.634s, loss: 1.064, train accuracy: 0.609\n","epoch: 19, time: 7611.341s, loss: 0.981, train accuracy: 0.625\n","epoch: 19, time: 7622.028s, loss: 1.015, train accuracy: 0.641\n","epoch: 19, time: 7632.688s, loss: 1.047, train accuracy: 0.539\n","epoch: 19, time: 7643.359s, loss: 1.080, train accuracy: 0.602\n","epoch: 19, time: 7654.021s, loss: 1.073, train accuracy: 0.602\n","epoch: 19, time: 7664.689s, loss: 1.026, train accuracy: 0.617\n","epoch: 19, time: 7675.359s, loss: 0.972, train accuracy: 0.586\n","epoch: 19, time: 7686.047s, loss: 0.871, train accuracy: 0.664\n","epoch: 19, time: 7696.714s, loss: 1.117, train accuracy: 0.531\n","epoch: 19, time: 7707.374s, loss: 1.052, train accuracy: 0.555\n","epoch: 19, time: 7718.018s, loss: 1.135, train accuracy: 0.523\n","epoch: 19, time: 7728.701s, loss: 1.366, train accuracy: 0.578\n","epoch: 19, validation loss: 0.7654518649013821\n","epoch: 20, time: 7741.933s, loss: 1.047, train accuracy: 0.555\n","epoch: 20, time: 7752.575s, loss: 1.169, train accuracy: 0.547\n","epoch: 20, time: 7763.240s, loss: 1.102, train accuracy: 0.633\n","epoch: 20, time: 7773.934s, loss: 1.038, train accuracy: 0.609\n","epoch: 20, time: 7784.632s, loss: 0.936, train accuracy: 0.656\n","epoch: 20, time: 7795.316s, loss: 1.063, train accuracy: 0.562\n","epoch: 20, time: 7805.989s, loss: 1.038, train accuracy: 0.547\n","epoch: 20, time: 7816.647s, loss: 1.141, train accuracy: 0.586\n","epoch: 20, time: 7827.286s, loss: 1.013, train accuracy: 0.609\n","epoch: 20, time: 7837.930s, loss: 1.088, train accuracy: 0.539\n","epoch: 20, time: 7848.570s, loss: 1.139, train accuracy: 0.539\n","epoch: 20, time: 7859.218s, loss: 1.101, train accuracy: 0.602\n","epoch: 20, time: 7869.863s, loss: 1.045, train accuracy: 0.594\n","epoch: 20, time: 7880.525s, loss: 1.143, train accuracy: 0.570\n","epoch: 20, time: 7891.189s, loss: 0.987, train accuracy: 0.633\n","epoch: 20, time: 7901.840s, loss: 0.948, train accuracy: 0.641\n","epoch: 20, time: 7912.503s, loss: 1.203, train accuracy: 0.602\n","epoch: 20, time: 7923.181s, loss: 1.062, train accuracy: 0.562\n","epoch: 20, time: 7933.847s, loss: 1.115, train accuracy: 0.539\n","epoch: 20, time: 7944.504s, loss: 1.056, train accuracy: 0.562\n","epoch: 20, time: 7955.183s, loss: 1.000, train accuracy: 0.586\n","epoch: 20, time: 7965.844s, loss: 1.175, train accuracy: 0.555\n","epoch: 20, time: 7976.541s, loss: 1.185, train accuracy: 0.492\n","epoch: 20, time: 7987.208s, loss: 1.017, train accuracy: 0.594\n","epoch: 20, time: 7997.885s, loss: 0.968, train accuracy: 0.656\n","epoch: 20, time: 8008.549s, loss: 0.938, train accuracy: 0.641\n","epoch: 20, time: 8019.207s, loss: 0.957, train accuracy: 0.594\n","epoch: 20, time: 8029.883s, loss: 1.081, train accuracy: 0.539\n","epoch: 20, time: 8040.572s, loss: 1.155, train accuracy: 0.531\n","epoch: 20, time: 8051.250s, loss: 1.063, train accuracy: 0.594\n","epoch: 20, time: 8061.895s, loss: 1.190, train accuracy: 0.508\n","epoch: 20, time: 8072.567s, loss: 0.989, train accuracy: 0.594\n","epoch: 20, time: 8083.245s, loss: 1.019, train accuracy: 0.625\n","epoch: 20, time: 8093.910s, loss: 0.948, train accuracy: 0.609\n","epoch: 20, time: 8104.584s, loss: 1.063, train accuracy: 0.586\n","epoch: 20, time: 8115.242s, loss: 0.824, train accuracy: 0.648\n","epoch: 20, time: 8125.896s, loss: 1.119, train accuracy: 0.602\n","epoch: 20, time: 8136.567s, loss: 1.044, train accuracy: 0.594\n","epoch: 20, validation loss: 0.7981414958866421\n","epoch: 21, time: 8149.492s, loss: 1.078, train accuracy: 0.625\n","epoch: 21, time: 8160.129s, loss: 0.968, train accuracy: 0.586\n","epoch: 21, time: 8170.785s, loss: 0.952, train accuracy: 0.586\n","epoch: 21, time: 8181.433s, loss: 1.178, train accuracy: 0.516\n","epoch: 21, time: 8192.092s, loss: 1.001, train accuracy: 0.578\n","epoch: 21, time: 8202.783s, loss: 1.095, train accuracy: 0.594\n","epoch: 21, time: 8213.450s, loss: 1.021, train accuracy: 0.570\n","epoch: 21, time: 8224.121s, loss: 1.105, train accuracy: 0.586\n","epoch: 21, time: 8234.781s, loss: 1.094, train accuracy: 0.523\n","epoch: 21, time: 8245.455s, loss: 1.111, train accuracy: 0.633\n","epoch: 21, time: 8256.132s, loss: 1.111, train accuracy: 0.539\n","epoch: 21, time: 8266.804s, loss: 1.040, train accuracy: 0.523\n","epoch: 21, time: 8277.458s, loss: 1.110, train accuracy: 0.578\n","epoch: 21, time: 8288.132s, loss: 1.173, train accuracy: 0.523\n","epoch: 21, time: 8298.795s, loss: 1.158, train accuracy: 0.547\n","epoch: 21, time: 8309.480s, loss: 1.078, train accuracy: 0.516\n","epoch: 21, time: 8320.131s, loss: 1.109, train accuracy: 0.617\n","epoch: 21, time: 8330.795s, loss: 1.071, train accuracy: 0.602\n","epoch: 21, time: 8341.431s, loss: 1.125, train accuracy: 0.555\n","epoch: 21, time: 8352.067s, loss: 0.980, train accuracy: 0.656\n","epoch: 21, time: 8362.697s, loss: 0.874, train accuracy: 0.695\n","epoch: 21, time: 8373.346s, loss: 0.793, train accuracy: 0.727\n","epoch: 21, time: 8383.993s, loss: 1.169, train accuracy: 0.508\n","epoch: 21, time: 8394.613s, loss: 1.134, train accuracy: 0.508\n","epoch: 21, time: 8405.248s, loss: 0.979, train accuracy: 0.641\n","epoch: 21, time: 8415.888s, loss: 0.926, train accuracy: 0.625\n","epoch: 21, time: 8426.533s, loss: 0.979, train accuracy: 0.602\n","epoch: 21, time: 8437.176s, loss: 0.909, train accuracy: 0.664\n","epoch: 21, time: 8447.825s, loss: 1.107, train accuracy: 0.586\n","epoch: 21, time: 8458.472s, loss: 1.198, train accuracy: 0.555\n","epoch: 21, time: 8469.133s, loss: 1.060, train accuracy: 0.578\n","epoch: 21, time: 8479.802s, loss: 1.040, train accuracy: 0.508\n","epoch: 21, time: 8490.462s, loss: 1.108, train accuracy: 0.516\n","epoch: 21, time: 8501.129s, loss: 1.041, train accuracy: 0.555\n","epoch: 21, time: 8511.824s, loss: 1.083, train accuracy: 0.539\n","epoch: 21, time: 8522.501s, loss: 1.066, train accuracy: 0.562\n","epoch: 21, time: 8533.166s, loss: 1.042, train accuracy: 0.641\n","epoch: 21, time: 8543.823s, loss: 1.004, train accuracy: 0.641\n","epoch: 21, validation loss: 0.8127564860305299\n","epoch: 22, time: 8556.635s, loss: 1.000, train accuracy: 0.586\n","epoch: 22, time: 8567.260s, loss: 1.100, train accuracy: 0.570\n","epoch: 22, time: 8577.927s, loss: 0.966, train accuracy: 0.625\n","epoch: 22, time: 8588.593s, loss: 0.930, train accuracy: 0.586\n","epoch: 22, time: 8599.235s, loss: 0.979, train accuracy: 0.578\n","epoch: 22, time: 8609.901s, loss: 1.184, train accuracy: 0.516\n","epoch: 22, time: 8620.558s, loss: 0.992, train accuracy: 0.641\n","epoch: 22, time: 8631.259s, loss: 1.046, train accuracy: 0.617\n","epoch: 22, time: 8641.906s, loss: 1.007, train accuracy: 0.570\n","epoch: 22, time: 8652.537s, loss: 1.205, train accuracy: 0.539\n","epoch: 22, time: 8663.183s, loss: 0.888, train accuracy: 0.656\n","epoch: 22, time: 8673.838s, loss: 1.205, train accuracy: 0.539\n","epoch: 22, time: 8684.525s, loss: 1.037, train accuracy: 0.609\n","epoch: 22, time: 8695.226s, loss: 1.016, train accuracy: 0.641\n","epoch: 22, time: 8705.898s, loss: 1.035, train accuracy: 0.602\n","epoch: 22, time: 8716.555s, loss: 1.132, train accuracy: 0.578\n","epoch: 22, time: 8727.203s, loss: 0.964, train accuracy: 0.602\n","epoch: 22, time: 8737.850s, loss: 1.022, train accuracy: 0.570\n","epoch: 22, time: 8748.514s, loss: 1.144, train accuracy: 0.562\n","epoch: 22, time: 8759.161s, loss: 0.945, train accuracy: 0.656\n","epoch: 22, time: 8769.834s, loss: 0.981, train accuracy: 0.578\n","epoch: 22, time: 8780.473s, loss: 1.023, train accuracy: 0.570\n","epoch: 22, time: 8791.119s, loss: 0.928, train accuracy: 0.664\n","epoch: 22, time: 8801.758s, loss: 0.986, train accuracy: 0.602\n","epoch: 22, time: 8812.418s, loss: 1.073, train accuracy: 0.562\n","epoch: 22, time: 8823.060s, loss: 1.078, train accuracy: 0.594\n","epoch: 22, time: 8833.681s, loss: 0.917, train accuracy: 0.656\n","epoch: 22, time: 8844.334s, loss: 1.052, train accuracy: 0.586\n","epoch: 22, time: 8854.969s, loss: 0.947, train accuracy: 0.648\n","epoch: 22, time: 8865.603s, loss: 0.999, train accuracy: 0.641\n","epoch: 22, time: 8876.236s, loss: 0.939, train accuracy: 0.609\n","epoch: 22, time: 8886.886s, loss: 0.987, train accuracy: 0.570\n","epoch: 22, time: 8897.522s, loss: 1.168, train accuracy: 0.531\n","epoch: 22, time: 8908.155s, loss: 1.014, train accuracy: 0.578\n","epoch: 22, time: 8918.798s, loss: 1.066, train accuracy: 0.516\n","epoch: 22, time: 8929.438s, loss: 1.068, train accuracy: 0.570\n","epoch: 22, time: 8940.078s, loss: 1.276, train accuracy: 0.531\n","epoch: 22, time: 8950.731s, loss: 0.901, train accuracy: 0.680\n","epoch: 22, validation loss: 0.7646085378457742\n","epoch: 23, time: 8964.040s, loss: 1.005, train accuracy: 0.586\n","epoch: 23, time: 8974.669s, loss: 1.178, train accuracy: 0.516\n","epoch: 23, time: 8985.324s, loss: 1.261, train accuracy: 0.555\n","epoch: 23, time: 8995.997s, loss: 1.100, train accuracy: 0.531\n","epoch: 23, time: 9006.678s, loss: 0.976, train accuracy: 0.617\n","epoch: 23, time: 9017.335s, loss: 0.975, train accuracy: 0.641\n","epoch: 23, time: 9027.968s, loss: 0.921, train accuracy: 0.648\n","epoch: 23, time: 9038.611s, loss: 1.007, train accuracy: 0.633\n","epoch: 23, time: 9049.246s, loss: 0.863, train accuracy: 0.664\n","epoch: 23, time: 9059.872s, loss: 1.020, train accuracy: 0.594\n","epoch: 23, time: 9070.519s, loss: 0.868, train accuracy: 0.625\n","epoch: 23, time: 9081.174s, loss: 1.073, train accuracy: 0.586\n","epoch: 23, time: 9091.809s, loss: 0.923, train accuracy: 0.594\n","epoch: 23, time: 9102.460s, loss: 1.093, train accuracy: 0.586\n","epoch: 23, time: 9113.092s, loss: 1.158, train accuracy: 0.531\n","epoch: 23, time: 9123.726s, loss: 1.001, train accuracy: 0.578\n","epoch: 23, time: 9134.381s, loss: 1.221, train accuracy: 0.547\n","epoch: 23, time: 9145.022s, loss: 1.141, train accuracy: 0.555\n","epoch: 23, time: 9155.680s, loss: 1.017, train accuracy: 0.633\n","epoch: 23, time: 9166.348s, loss: 0.994, train accuracy: 0.570\n","epoch: 23, time: 9177.018s, loss: 0.927, train accuracy: 0.617\n","epoch: 23, time: 9187.683s, loss: 1.173, train accuracy: 0.602\n","epoch: 23, time: 9198.338s, loss: 1.072, train accuracy: 0.547\n","epoch: 23, time: 9209.010s, loss: 1.057, train accuracy: 0.625\n","epoch: 23, time: 9219.670s, loss: 1.053, train accuracy: 0.570\n","epoch: 23, time: 9230.343s, loss: 0.938, train accuracy: 0.633\n","epoch: 23, time: 9241.020s, loss: 0.996, train accuracy: 0.602\n","epoch: 23, time: 9251.713s, loss: 1.009, train accuracy: 0.625\n","epoch: 23, time: 9262.385s, loss: 1.047, train accuracy: 0.562\n","epoch: 23, time: 9273.047s, loss: 1.025, train accuracy: 0.594\n","epoch: 23, time: 9283.693s, loss: 1.110, train accuracy: 0.523\n","epoch: 23, time: 9294.329s, loss: 0.946, train accuracy: 0.633\n","epoch: 23, time: 9304.947s, loss: 1.020, train accuracy: 0.625\n","epoch: 23, time: 9315.588s, loss: 1.029, train accuracy: 0.625\n","epoch: 23, time: 9326.241s, loss: 0.957, train accuracy: 0.633\n","epoch: 23, time: 9336.892s, loss: 1.150, train accuracy: 0.539\n","epoch: 23, time: 9347.592s, loss: 0.934, train accuracy: 0.648\n","epoch: 23, time: 9358.260s, loss: 0.841, train accuracy: 0.648\n","epoch: 23, validation loss: 0.7511502869093596\n","epoch: 24, time: 9371.383s, loss: 1.079, train accuracy: 0.578\n","epoch: 24, time: 9382.021s, loss: 0.986, train accuracy: 0.648\n","epoch: 24, time: 9392.664s, loss: 1.087, train accuracy: 0.547\n","epoch: 24, time: 9403.293s, loss: 1.151, train accuracy: 0.531\n","epoch: 24, time: 9413.955s, loss: 1.031, train accuracy: 0.570\n","epoch: 24, time: 9424.667s, loss: 1.034, train accuracy: 0.562\n","epoch: 24, time: 9435.333s, loss: 1.250, train accuracy: 0.547\n","epoch: 24, time: 9445.985s, loss: 0.964, train accuracy: 0.617\n","epoch: 24, time: 9456.648s, loss: 1.017, train accuracy: 0.602\n","epoch: 24, time: 9467.290s, loss: 1.017, train accuracy: 0.688\n","epoch: 24, time: 9477.935s, loss: 1.194, train accuracy: 0.578\n","epoch: 24, time: 9488.586s, loss: 1.053, train accuracy: 0.562\n","epoch: 24, time: 9499.266s, loss: 1.151, train accuracy: 0.516\n","epoch: 24, time: 9509.941s, loss: 1.072, train accuracy: 0.570\n","epoch: 24, time: 9520.602s, loss: 0.936, train accuracy: 0.617\n","epoch: 24, time: 9531.263s, loss: 0.947, train accuracy: 0.656\n","epoch: 24, time: 9541.903s, loss: 1.087, train accuracy: 0.547\n","epoch: 24, time: 9552.571s, loss: 1.165, train accuracy: 0.539\n","epoch: 24, time: 9563.219s, loss: 1.143, train accuracy: 0.562\n","epoch: 24, time: 9573.875s, loss: 1.126, train accuracy: 0.578\n","epoch: 24, time: 9584.550s, loss: 1.035, train accuracy: 0.578\n","epoch: 24, time: 9595.211s, loss: 1.230, train accuracy: 0.516\n","epoch: 24, time: 9605.859s, loss: 1.083, train accuracy: 0.656\n","epoch: 24, time: 9616.507s, loss: 1.149, train accuracy: 0.555\n","epoch: 24, time: 9627.153s, loss: 1.057, train accuracy: 0.602\n","epoch: 24, time: 9637.785s, loss: 1.135, train accuracy: 0.562\n","epoch: 24, time: 9648.440s, loss: 0.980, train accuracy: 0.586\n","epoch: 24, time: 9659.088s, loss: 1.184, train accuracy: 0.539\n","epoch: 24, time: 9669.740s, loss: 1.145, train accuracy: 0.531\n","epoch: 24, time: 9680.394s, loss: 0.957, train accuracy: 0.562\n","epoch: 24, time: 9691.050s, loss: 0.985, train accuracy: 0.578\n","epoch: 24, time: 9701.697s, loss: 0.866, train accuracy: 0.641\n","epoch: 24, time: 9712.338s, loss: 1.075, train accuracy: 0.586\n","epoch: 24, time: 9722.962s, loss: 1.091, train accuracy: 0.586\n","epoch: 24, time: 9733.620s, loss: 1.148, train accuracy: 0.523\n","epoch: 24, time: 9744.269s, loss: 0.991, train accuracy: 0.594\n","epoch: 24, time: 9754.916s, loss: 0.931, train accuracy: 0.641\n","epoch: 24, time: 9765.574s, loss: 1.037, train accuracy: 0.562\n","epoch: 24, validation loss: 0.7820170156991304\n","epoch: 25, time: 9778.567s, loss: 1.161, train accuracy: 0.500\n","epoch: 25, time: 9789.220s, loss: 0.953, train accuracy: 0.656\n","epoch: 25, time: 9799.888s, loss: 1.150, train accuracy: 0.578\n","epoch: 25, time: 9810.588s, loss: 1.007, train accuracy: 0.578\n","epoch: 25, time: 9821.275s, loss: 0.903, train accuracy: 0.648\n","epoch: 25, time: 9831.952s, loss: 0.966, train accuracy: 0.547\n","epoch: 25, time: 9842.622s, loss: 1.012, train accuracy: 0.578\n","epoch: 25, time: 9853.276s, loss: 0.975, train accuracy: 0.539\n","epoch: 25, time: 9863.920s, loss: 1.053, train accuracy: 0.586\n","epoch: 25, time: 9874.568s, loss: 1.061, train accuracy: 0.594\n","epoch: 25, time: 9885.238s, loss: 1.003, train accuracy: 0.594\n","epoch: 25, time: 9895.901s, loss: 0.912, train accuracy: 0.641\n","epoch: 25, time: 9906.542s, loss: 0.919, train accuracy: 0.664\n","epoch: 25, time: 9917.187s, loss: 0.837, train accuracy: 0.680\n","epoch: 25, time: 9927.819s, loss: 1.178, train accuracy: 0.586\n","epoch: 25, time: 9938.460s, loss: 1.133, train accuracy: 0.547\n","epoch: 25, time: 9949.101s, loss: 1.238, train accuracy: 0.508\n","epoch: 25, time: 9959.743s, loss: 1.110, train accuracy: 0.539\n","epoch: 25, time: 9970.392s, loss: 1.024, train accuracy: 0.656\n","epoch: 25, time: 9981.054s, loss: 0.983, train accuracy: 0.641\n","epoch: 25, time: 9991.700s, loss: 1.052, train accuracy: 0.625\n","epoch: 25, time: 10002.386s, loss: 1.120, train accuracy: 0.562\n","epoch: 25, time: 10013.059s, loss: 0.900, train accuracy: 0.617\n","epoch: 25, time: 10023.725s, loss: 0.929, train accuracy: 0.688\n","epoch: 25, time: 10034.391s, loss: 0.943, train accuracy: 0.625\n","epoch: 25, time: 10045.080s, loss: 0.951, train accuracy: 0.602\n","epoch: 25, time: 10055.741s, loss: 0.989, train accuracy: 0.633\n","epoch: 25, time: 10066.399s, loss: 1.126, train accuracy: 0.586\n","epoch: 25, time: 10077.065s, loss: 0.909, train accuracy: 0.641\n","epoch: 25, time: 10087.735s, loss: 0.929, train accuracy: 0.625\n","epoch: 25, time: 10098.413s, loss: 1.088, train accuracy: 0.586\n","epoch: 25, time: 10109.073s, loss: 1.111, train accuracy: 0.586\n","epoch: 25, time: 10119.740s, loss: 1.029, train accuracy: 0.578\n","epoch: 25, time: 10130.383s, loss: 1.026, train accuracy: 0.570\n","epoch: 25, time: 10141.046s, loss: 0.979, train accuracy: 0.594\n","epoch: 25, time: 10151.699s, loss: 1.185, train accuracy: 0.500\n","epoch: 25, time: 10162.346s, loss: 0.880, train accuracy: 0.648\n","epoch: 25, time: 10172.989s, loss: 1.007, train accuracy: 0.609\n","epoch: 25, validation loss: 0.7798298654525773\n","epoch: 26, time: 10185.964s, loss: 1.145, train accuracy: 0.570\n","epoch: 26, time: 10196.575s, loss: 1.015, train accuracy: 0.656\n","epoch: 26, time: 10207.223s, loss: 0.825, train accuracy: 0.727\n","epoch: 26, time: 10217.916s, loss: 0.922, train accuracy: 0.617\n","epoch: 26, time: 10228.600s, loss: 1.024, train accuracy: 0.555\n","epoch: 26, time: 10239.281s, loss: 0.903, train accuracy: 0.695\n","epoch: 26, time: 10249.962s, loss: 1.049, train accuracy: 0.562\n","epoch: 26, time: 10260.613s, loss: 1.047, train accuracy: 0.594\n","epoch: 26, time: 10271.278s, loss: 1.027, train accuracy: 0.609\n","epoch: 26, time: 10281.920s, loss: 1.046, train accuracy: 0.539\n","epoch: 26, time: 10292.557s, loss: 1.182, train accuracy: 0.508\n","epoch: 26, time: 10303.181s, loss: 1.086, train accuracy: 0.562\n","epoch: 26, time: 10313.820s, loss: 0.937, train accuracy: 0.648\n","epoch: 26, time: 10324.460s, loss: 0.911, train accuracy: 0.633\n","epoch: 26, time: 10335.098s, loss: 1.067, train accuracy: 0.531\n","epoch: 26, time: 10345.723s, loss: 0.996, train accuracy: 0.664\n","epoch: 26, time: 10356.346s, loss: 0.929, train accuracy: 0.609\n","epoch: 26, time: 10366.972s, loss: 1.043, train accuracy: 0.586\n","epoch: 26, time: 10377.611s, loss: 1.124, train accuracy: 0.523\n","epoch: 26, time: 10388.234s, loss: 1.110, train accuracy: 0.508\n","epoch: 26, time: 10398.863s, loss: 0.936, train accuracy: 0.578\n","epoch: 26, time: 10409.496s, loss: 1.154, train accuracy: 0.531\n","epoch: 26, time: 10420.129s, loss: 1.031, train accuracy: 0.602\n","epoch: 26, time: 10430.770s, loss: 0.885, train accuracy: 0.648\n","epoch: 26, time: 10441.409s, loss: 1.122, train accuracy: 0.523\n","epoch: 26, time: 10452.070s, loss: 0.974, train accuracy: 0.609\n","epoch: 26, time: 10462.725s, loss: 1.120, train accuracy: 0.547\n","epoch: 26, time: 10473.405s, loss: 1.235, train accuracy: 0.508\n","epoch: 26, time: 10484.053s, loss: 1.029, train accuracy: 0.633\n","epoch: 26, time: 10494.720s, loss: 0.984, train accuracy: 0.672\n","epoch: 26, time: 10505.372s, loss: 1.193, train accuracy: 0.523\n","epoch: 26, time: 10516.036s, loss: 0.979, train accuracy: 0.617\n","epoch: 26, time: 10526.698s, loss: 0.959, train accuracy: 0.586\n","epoch: 26, time: 10537.363s, loss: 0.918, train accuracy: 0.672\n","epoch: 26, time: 10548.032s, loss: 1.079, train accuracy: 0.555\n","epoch: 26, time: 10558.700s, loss: 0.948, train accuracy: 0.633\n","epoch: 26, time: 10569.379s, loss: 1.106, train accuracy: 0.531\n","epoch: 26, time: 10580.018s, loss: 1.006, train accuracy: 0.602\n","epoch: 26, validation loss: 0.7658200839689291\n","epoch: 27, time: 10593.074s, loss: 0.996, train accuracy: 0.586\n","epoch: 27, time: 10603.691s, loss: 1.040, train accuracy: 0.586\n","epoch: 27, time: 10614.328s, loss: 1.083, train accuracy: 0.539\n","epoch: 27, time: 10625.011s, loss: 1.112, train accuracy: 0.594\n","epoch: 27, time: 10635.675s, loss: 1.016, train accuracy: 0.594\n","epoch: 27, time: 10646.347s, loss: 1.089, train accuracy: 0.555\n","epoch: 27, time: 10656.999s, loss: 1.084, train accuracy: 0.586\n","epoch: 27, time: 10667.663s, loss: 1.123, train accuracy: 0.555\n","epoch: 27, time: 10678.322s, loss: 0.914, train accuracy: 0.711\n","epoch: 27, time: 10688.979s, loss: 1.047, train accuracy: 0.594\n","epoch: 27, time: 10699.660s, loss: 1.022, train accuracy: 0.625\n","epoch: 27, time: 10710.323s, loss: 1.030, train accuracy: 0.609\n","epoch: 27, time: 10720.991s, loss: 0.945, train accuracy: 0.641\n","epoch: 27, time: 10731.646s, loss: 1.019, train accuracy: 0.602\n","epoch: 27, time: 10742.296s, loss: 1.124, train accuracy: 0.594\n","epoch: 27, time: 10752.969s, loss: 1.052, train accuracy: 0.656\n","epoch: 27, time: 10763.626s, loss: 0.955, train accuracy: 0.586\n","epoch: 27, time: 10774.282s, loss: 1.159, train accuracy: 0.508\n","epoch: 27, time: 10784.965s, loss: 1.061, train accuracy: 0.641\n","epoch: 27, time: 10795.643s, loss: 0.997, train accuracy: 0.602\n","epoch: 27, time: 10806.295s, loss: 0.993, train accuracy: 0.625\n","epoch: 27, time: 10816.980s, loss: 1.123, train accuracy: 0.547\n","epoch: 27, time: 10827.651s, loss: 1.047, train accuracy: 0.602\n","epoch: 27, time: 10838.283s, loss: 1.189, train accuracy: 0.500\n","epoch: 27, time: 10848.928s, loss: 1.044, train accuracy: 0.641\n","epoch: 27, time: 10859.599s, loss: 1.032, train accuracy: 0.594\n","epoch: 27, time: 10870.261s, loss: 1.132, train accuracy: 0.562\n","epoch: 27, time: 10880.928s, loss: 0.927, train accuracy: 0.680\n","epoch: 27, time: 10891.591s, loss: 1.043, train accuracy: 0.586\n","epoch: 27, time: 10902.229s, loss: 0.907, train accuracy: 0.672\n","epoch: 27, time: 10912.896s, loss: 0.821, train accuracy: 0.648\n","epoch: 27, time: 10923.579s, loss: 1.072, train accuracy: 0.617\n","epoch: 27, time: 10934.280s, loss: 1.032, train accuracy: 0.602\n","epoch: 27, time: 10944.960s, loss: 1.004, train accuracy: 0.641\n","epoch: 27, time: 10955.620s, loss: 1.141, train accuracy: 0.555\n","epoch: 27, time: 10966.285s, loss: 1.129, train accuracy: 0.578\n","epoch: 27, time: 10976.955s, loss: 1.003, train accuracy: 0.617\n","epoch: 27, time: 10987.616s, loss: 0.921, train accuracy: 0.641\n","epoch: 27, validation loss: 0.7832760832457146\n","epoch: 28, time: 11000.967s, loss: 1.071, train accuracy: 0.562\n","epoch: 28, time: 11011.576s, loss: 1.040, train accuracy: 0.617\n","epoch: 28, time: 11022.238s, loss: 0.980, train accuracy: 0.555\n","epoch: 28, time: 11032.934s, loss: 1.079, train accuracy: 0.539\n","epoch: 28, time: 11043.608s, loss: 1.027, train accuracy: 0.555\n","epoch: 28, time: 11054.305s, loss: 1.191, train accuracy: 0.562\n","epoch: 28, time: 11064.946s, loss: 0.984, train accuracy: 0.648\n","epoch: 28, time: 11075.584s, loss: 1.054, train accuracy: 0.602\n","epoch: 28, time: 11086.223s, loss: 1.033, train accuracy: 0.578\n","epoch: 28, time: 11096.857s, loss: 0.998, train accuracy: 0.602\n","epoch: 28, time: 11107.511s, loss: 1.107, train accuracy: 0.594\n","epoch: 28, time: 11118.162s, loss: 0.973, train accuracy: 0.578\n","epoch: 28, time: 11128.800s, loss: 0.988, train accuracy: 0.586\n","epoch: 28, time: 11139.441s, loss: 0.915, train accuracy: 0.633\n","epoch: 28, time: 11150.074s, loss: 0.846, train accuracy: 0.625\n","epoch: 28, time: 11160.728s, loss: 1.061, train accuracy: 0.602\n","epoch: 28, time: 11171.382s, loss: 1.068, train accuracy: 0.617\n","epoch: 28, time: 11182.022s, loss: 1.068, train accuracy: 0.633\n","epoch: 28, time: 11192.657s, loss: 1.234, train accuracy: 0.500\n","epoch: 28, time: 11203.289s, loss: 1.129, train accuracy: 0.562\n","epoch: 28, time: 11213.933s, loss: 0.974, train accuracy: 0.617\n","epoch: 28, time: 11224.570s, loss: 1.138, train accuracy: 0.578\n","epoch: 28, time: 11235.224s, loss: 1.127, train accuracy: 0.547\n","epoch: 28, time: 11245.874s, loss: 0.954, train accuracy: 0.578\n","epoch: 28, time: 11256.524s, loss: 0.973, train accuracy: 0.617\n","epoch: 28, time: 11267.198s, loss: 1.206, train accuracy: 0.562\n","epoch: 28, time: 11277.844s, loss: 1.132, train accuracy: 0.562\n","epoch: 28, time: 11288.512s, loss: 1.007, train accuracy: 0.547\n","epoch: 28, time: 11299.195s, loss: 1.027, train accuracy: 0.602\n","epoch: 28, time: 11309.873s, loss: 0.890, train accuracy: 0.633\n","epoch: 28, time: 11320.544s, loss: 0.901, train accuracy: 0.617\n","epoch: 28, time: 11331.201s, loss: 1.104, train accuracy: 0.547\n","epoch: 28, time: 11341.864s, loss: 1.115, train accuracy: 0.539\n","epoch: 28, time: 11352.519s, loss: 1.163, train accuracy: 0.578\n","epoch: 28, time: 11363.173s, loss: 1.016, train accuracy: 0.586\n","epoch: 28, time: 11373.810s, loss: 0.849, train accuracy: 0.625\n","epoch: 28, time: 11384.451s, loss: 1.061, train accuracy: 0.594\n","epoch: 28, time: 11395.079s, loss: 1.047, train accuracy: 0.586\n","epoch: 28, validation loss: 0.7704328083788662\n","epoch: 29, time: 11407.998s, loss: 1.032, train accuracy: 0.547\n","epoch: 29, time: 11418.616s, loss: 0.924, train accuracy: 0.633\n","epoch: 29, time: 11429.245s, loss: 0.961, train accuracy: 0.594\n","epoch: 29, time: 11439.892s, loss: 1.135, train accuracy: 0.555\n","epoch: 29, time: 11450.547s, loss: 1.007, train accuracy: 0.562\n","epoch: 29, time: 11461.220s, loss: 1.156, train accuracy: 0.531\n","epoch: 29, time: 11471.872s, loss: 0.930, train accuracy: 0.633\n","epoch: 29, time: 11482.524s, loss: 1.017, train accuracy: 0.602\n","epoch: 29, time: 11493.179s, loss: 0.974, train accuracy: 0.625\n","epoch: 29, time: 11503.858s, loss: 1.002, train accuracy: 0.617\n","epoch: 29, time: 11514.543s, loss: 1.054, train accuracy: 0.633\n","epoch: 29, time: 11525.195s, loss: 1.038, train accuracy: 0.570\n","epoch: 29, time: 11535.849s, loss: 1.044, train accuracy: 0.617\n","epoch: 29, time: 11546.497s, loss: 1.216, train accuracy: 0.500\n","epoch: 29, time: 11557.153s, loss: 1.006, train accuracy: 0.570\n","epoch: 29, time: 11567.813s, loss: 1.140, train accuracy: 0.633\n","epoch: 29, time: 11578.464s, loss: 0.980, train accuracy: 0.656\n","epoch: 29, time: 11589.100s, loss: 1.065, train accuracy: 0.617\n","epoch: 29, time: 11599.736s, loss: 1.071, train accuracy: 0.586\n","epoch: 29, time: 11610.376s, loss: 1.066, train accuracy: 0.570\n","epoch: 29, time: 11621.001s, loss: 0.901, train accuracy: 0.633\n","epoch: 29, time: 11631.625s, loss: 0.953, train accuracy: 0.641\n","epoch: 29, time: 11642.269s, loss: 0.935, train accuracy: 0.648\n","epoch: 29, time: 11652.896s, loss: 1.000, train accuracy: 0.602\n","epoch: 29, time: 11663.534s, loss: 1.077, train accuracy: 0.547\n","epoch: 29, time: 11674.178s, loss: 0.899, train accuracy: 0.594\n","epoch: 29, time: 11684.812s, loss: 1.026, train accuracy: 0.578\n","epoch: 29, time: 11695.441s, loss: 0.878, train accuracy: 0.672\n","epoch: 29, time: 11706.097s, loss: 1.071, train accuracy: 0.617\n","epoch: 29, time: 11716.742s, loss: 0.955, train accuracy: 0.602\n","epoch: 29, time: 11727.417s, loss: 1.038, train accuracy: 0.609\n","epoch: 29, time: 11738.072s, loss: 0.999, train accuracy: 0.648\n","epoch: 29, time: 11748.758s, loss: 1.024, train accuracy: 0.625\n","epoch: 29, time: 11759.464s, loss: 0.965, train accuracy: 0.562\n","epoch: 29, time: 11770.122s, loss: 1.096, train accuracy: 0.578\n","epoch: 29, time: 11780.799s, loss: 1.001, train accuracy: 0.602\n","epoch: 29, time: 11791.479s, loss: 1.029, train accuracy: 0.617\n","epoch: 29, time: 11802.122s, loss: 1.143, train accuracy: 0.531\n","epoch: 29, validation loss: 0.7572596328599113\n","epoch: 30, time: 11815.516s, loss: 1.042, train accuracy: 0.594\n","epoch: 30, time: 11826.146s, loss: 1.125, train accuracy: 0.547\n","epoch: 30, time: 11836.815s, loss: 1.118, train accuracy: 0.570\n","epoch: 30, time: 11847.511s, loss: 1.146, train accuracy: 0.570\n","epoch: 30, time: 11858.180s, loss: 0.940, train accuracy: 0.641\n","epoch: 30, time: 11868.836s, loss: 1.097, train accuracy: 0.578\n","epoch: 30, time: 11879.499s, loss: 1.010, train accuracy: 0.578\n","epoch: 30, time: 11890.166s, loss: 1.068, train accuracy: 0.570\n","epoch: 30, time: 11900.797s, loss: 0.961, train accuracy: 0.641\n","epoch: 30, time: 11911.437s, loss: 1.004, train accuracy: 0.633\n","epoch: 30, time: 11922.077s, loss: 1.018, train accuracy: 0.609\n","epoch: 30, time: 11932.704s, loss: 0.922, train accuracy: 0.594\n","epoch: 30, time: 11943.339s, loss: 1.100, train accuracy: 0.523\n","epoch: 30, time: 11953.998s, loss: 0.967, train accuracy: 0.594\n","epoch: 30, time: 11964.638s, loss: 1.202, train accuracy: 0.531\n","epoch: 30, time: 11975.273s, loss: 0.943, train accuracy: 0.633\n","epoch: 30, time: 11985.905s, loss: 1.047, train accuracy: 0.578\n","epoch: 30, time: 11996.544s, loss: 0.990, train accuracy: 0.562\n","epoch: 30, time: 12007.178s, loss: 1.112, train accuracy: 0.555\n","epoch: 30, time: 12017.816s, loss: 1.124, train accuracy: 0.523\n","epoch: 30, time: 12028.461s, loss: 1.170, train accuracy: 0.555\n","epoch: 30, time: 12039.098s, loss: 1.024, train accuracy: 0.570\n","epoch: 30, time: 12049.749s, loss: 0.981, train accuracy: 0.547\n","epoch: 30, time: 12060.386s, loss: 1.218, train accuracy: 0.500\n","epoch: 30, time: 12071.043s, loss: 0.970, train accuracy: 0.633\n","epoch: 30, time: 12081.691s, loss: 1.047, train accuracy: 0.523\n","epoch: 30, time: 12092.355s, loss: 1.038, train accuracy: 0.617\n","epoch: 30, time: 12103.005s, loss: 1.048, train accuracy: 0.617\n","epoch: 30, time: 12113.629s, loss: 1.256, train accuracy: 0.539\n","epoch: 30, time: 12124.273s, loss: 1.144, train accuracy: 0.602\n","epoch: 30, time: 12134.910s, loss: 1.077, train accuracy: 0.547\n","epoch: 30, time: 12145.535s, loss: 1.119, train accuracy: 0.555\n","epoch: 30, time: 12156.180s, loss: 1.096, train accuracy: 0.523\n","epoch: 30, time: 12166.835s, loss: 1.102, train accuracy: 0.578\n","epoch: 30, time: 12177.476s, loss: 1.058, train accuracy: 0.586\n","epoch: 30, time: 12188.122s, loss: 1.015, train accuracy: 0.570\n","epoch: 30, time: 12198.781s, loss: 0.838, train accuracy: 0.711\n","epoch: 30, time: 12209.432s, loss: 0.952, train accuracy: 0.609\n","epoch: 30, validation loss: 0.7973500581692531\n","epoch: 31, time: 12222.220s, loss: 0.995, train accuracy: 0.586\n","epoch: 31, time: 12232.855s, loss: 1.094, train accuracy: 0.562\n","epoch: 31, time: 12243.497s, loss: 1.033, train accuracy: 0.594\n","epoch: 31, time: 12254.140s, loss: 0.995, train accuracy: 0.594\n","epoch: 31, time: 12264.825s, loss: 0.986, train accuracy: 0.578\n","epoch: 31, time: 12275.476s, loss: 1.049, train accuracy: 0.594\n","epoch: 31, time: 12286.105s, loss: 1.011, train accuracy: 0.547\n","epoch: 31, time: 12296.721s, loss: 0.853, train accuracy: 0.633\n","epoch: 31, time: 12307.342s, loss: 1.039, train accuracy: 0.586\n","epoch: 31, time: 12318.012s, loss: 1.133, train accuracy: 0.570\n","epoch: 31, time: 12328.670s, loss: 1.130, train accuracy: 0.570\n","epoch: 31, time: 12339.353s, loss: 1.061, train accuracy: 0.625\n","epoch: 31, time: 12350.016s, loss: 1.060, train accuracy: 0.555\n","epoch: 31, time: 12360.661s, loss: 1.070, train accuracy: 0.547\n","epoch: 31, time: 12371.315s, loss: 1.116, train accuracy: 0.570\n","epoch: 31, time: 12381.932s, loss: 0.956, train accuracy: 0.578\n","epoch: 31, time: 12392.568s, loss: 1.201, train accuracy: 0.555\n","epoch: 31, time: 12403.203s, loss: 1.115, train accuracy: 0.594\n","epoch: 31, time: 12413.819s, loss: 1.181, train accuracy: 0.578\n","epoch: 31, time: 12424.451s, loss: 1.029, train accuracy: 0.539\n","epoch: 31, time: 12435.095s, loss: 1.074, train accuracy: 0.586\n","epoch: 31, time: 12445.730s, loss: 0.967, train accuracy: 0.648\n","epoch: 31, time: 12456.355s, loss: 1.097, train accuracy: 0.562\n","epoch: 31, time: 12466.980s, loss: 1.014, train accuracy: 0.594\n","epoch: 31, time: 12477.605s, loss: 1.077, train accuracy: 0.609\n","epoch: 31, time: 12488.225s, loss: 0.918, train accuracy: 0.641\n","epoch: 31, time: 12498.884s, loss: 1.202, train accuracy: 0.562\n","epoch: 31, time: 12509.495s, loss: 1.337, train accuracy: 0.469\n","epoch: 31, time: 12520.126s, loss: 1.068, train accuracy: 0.594\n","epoch: 31, time: 12530.734s, loss: 1.059, train accuracy: 0.602\n","epoch: 31, time: 12541.343s, loss: 1.290, train accuracy: 0.539\n","epoch: 31, time: 12551.947s, loss: 1.161, train accuracy: 0.562\n","epoch: 31, time: 12562.559s, loss: 1.210, train accuracy: 0.578\n","epoch: 31, time: 12573.173s, loss: 1.124, train accuracy: 0.602\n","epoch: 31, time: 12583.795s, loss: 1.115, train accuracy: 0.531\n","epoch: 31, time: 12594.409s, loss: 0.969, train accuracy: 0.609\n","epoch: 31, time: 12605.034s, loss: 1.049, train accuracy: 0.641\n","epoch: 31, time: 12615.646s, loss: 1.181, train accuracy: 0.484\n","epoch: 31, validation loss: 0.7435883673777712\n","epoch: 32, time: 12628.493s, loss: 0.911, train accuracy: 0.609\n","epoch: 32, time: 12639.098s, loss: 1.073, train accuracy: 0.609\n","epoch: 32, time: 12649.710s, loss: 1.090, train accuracy: 0.547\n","epoch: 32, time: 12660.333s, loss: 0.919, train accuracy: 0.594\n","epoch: 32, time: 12670.957s, loss: 1.049, train accuracy: 0.656\n","epoch: 32, time: 12681.609s, loss: 0.866, train accuracy: 0.633\n","epoch: 32, time: 12692.248s, loss: 1.085, train accuracy: 0.609\n","epoch: 32, time: 12702.912s, loss: 1.083, train accuracy: 0.586\n","epoch: 32, time: 12713.541s, loss: 0.945, train accuracy: 0.641\n","epoch: 32, time: 12724.217s, loss: 1.073, train accuracy: 0.609\n","epoch: 32, time: 12734.866s, loss: 1.025, train accuracy: 0.602\n","epoch: 32, time: 12745.524s, loss: 0.887, train accuracy: 0.648\n","epoch: 32, time: 12756.155s, loss: 1.056, train accuracy: 0.562\n","epoch: 32, time: 12766.782s, loss: 1.077, train accuracy: 0.539\n","epoch: 32, time: 12777.424s, loss: 1.133, train accuracy: 0.578\n","epoch: 32, time: 12788.087s, loss: 1.044, train accuracy: 0.594\n","epoch: 32, time: 12798.730s, loss: 1.022, train accuracy: 0.594\n","epoch: 32, time: 12809.386s, loss: 0.936, train accuracy: 0.602\n","epoch: 32, time: 12820.056s, loss: 1.024, train accuracy: 0.586\n","epoch: 32, time: 12830.700s, loss: 0.971, train accuracy: 0.648\n","epoch: 32, time: 12841.348s, loss: 0.947, train accuracy: 0.594\n","epoch: 32, time: 12852.008s, loss: 1.090, train accuracy: 0.586\n","epoch: 32, time: 12862.659s, loss: 1.146, train accuracy: 0.547\n","epoch: 32, time: 12873.308s, loss: 1.146, train accuracy: 0.531\n","epoch: 32, time: 12883.976s, loss: 0.985, train accuracy: 0.617\n","epoch: 32, time: 12894.621s, loss: 0.949, train accuracy: 0.617\n","epoch: 32, time: 12905.265s, loss: 1.022, train accuracy: 0.602\n","epoch: 32, time: 12915.955s, loss: 1.265, train accuracy: 0.461\n","epoch: 32, time: 12926.611s, loss: 0.938, train accuracy: 0.648\n","epoch: 32, time: 12937.243s, loss: 1.079, train accuracy: 0.617\n","epoch: 32, time: 12947.901s, loss: 1.039, train accuracy: 0.562\n","epoch: 32, time: 12958.560s, loss: 1.062, train accuracy: 0.609\n","epoch: 32, time: 12969.200s, loss: 1.080, train accuracy: 0.562\n","epoch: 32, time: 12979.820s, loss: 0.951, train accuracy: 0.594\n","epoch: 32, time: 12990.481s, loss: 1.091, train accuracy: 0.578\n","epoch: 32, time: 13001.125s, loss: 1.033, train accuracy: 0.594\n","epoch: 32, time: 13011.761s, loss: 0.961, train accuracy: 0.555\n","epoch: 32, time: 13022.379s, loss: 1.017, train accuracy: 0.562\n","epoch: 32, validation loss: 0.7587292798038231\n","epoch: 33, time: 13035.465s, loss: 1.047, train accuracy: 0.547\n","epoch: 33, time: 13046.070s, loss: 1.056, train accuracy: 0.641\n","epoch: 33, time: 13056.719s, loss: 1.075, train accuracy: 0.586\n","epoch: 33, time: 13067.399s, loss: 1.007, train accuracy: 0.539\n","epoch: 33, time: 13078.089s, loss: 0.885, train accuracy: 0.672\n","epoch: 33, time: 13088.739s, loss: 1.179, train accuracy: 0.555\n","epoch: 33, time: 13099.391s, loss: 0.986, train accuracy: 0.617\n","epoch: 33, time: 13110.041s, loss: 1.015, train accuracy: 0.617\n","epoch: 33, time: 13120.672s, loss: 1.119, train accuracy: 0.516\n","epoch: 33, time: 13131.313s, loss: 1.106, train accuracy: 0.578\n","epoch: 33, time: 13141.923s, loss: 0.978, train accuracy: 0.602\n","epoch: 33, time: 13152.569s, loss: 1.110, train accuracy: 0.570\n","epoch: 33, time: 13163.192s, loss: 1.192, train accuracy: 0.547\n","epoch: 33, time: 13173.829s, loss: 1.163, train accuracy: 0.492\n","epoch: 33, time: 13184.472s, loss: 1.033, train accuracy: 0.617\n","epoch: 33, time: 13195.113s, loss: 0.980, train accuracy: 0.555\n","epoch: 33, time: 13205.769s, loss: 1.091, train accuracy: 0.602\n","epoch: 33, time: 13216.404s, loss: 0.993, train accuracy: 0.625\n","epoch: 33, time: 13227.042s, loss: 1.031, train accuracy: 0.578\n","epoch: 33, time: 13237.668s, loss: 0.816, train accuracy: 0.680\n","epoch: 33, time: 13248.305s, loss: 1.000, train accuracy: 0.594\n","epoch: 33, time: 13258.953s, loss: 0.907, train accuracy: 0.648\n","epoch: 33, time: 13269.597s, loss: 0.958, train accuracy: 0.625\n","epoch: 33, time: 13280.231s, loss: 1.017, train accuracy: 0.602\n","epoch: 33, time: 13290.871s, loss: 1.057, train accuracy: 0.547\n","epoch: 33, time: 13301.506s, loss: 0.954, train accuracy: 0.656\n","epoch: 33, time: 13312.163s, loss: 1.127, train accuracy: 0.539\n","epoch: 33, time: 13322.816s, loss: 1.031, train accuracy: 0.570\n","epoch: 33, time: 13333.479s, loss: 1.071, train accuracy: 0.547\n","epoch: 33, time: 13344.140s, loss: 0.935, train accuracy: 0.625\n","epoch: 33, time: 13354.788s, loss: 0.936, train accuracy: 0.617\n","epoch: 33, time: 13365.412s, loss: 1.041, train accuracy: 0.602\n","epoch: 33, time: 13376.045s, loss: 1.025, train accuracy: 0.617\n","epoch: 33, time: 13386.678s, loss: 1.273, train accuracy: 0.477\n","epoch: 33, time: 13397.309s, loss: 0.984, train accuracy: 0.602\n","epoch: 33, time: 13407.910s, loss: 1.074, train accuracy: 0.570\n","epoch: 33, time: 13418.532s, loss: 1.079, train accuracy: 0.547\n","epoch: 33, time: 13429.184s, loss: 1.155, train accuracy: 0.570\n","epoch: 33, validation loss: 0.7691883415555649\n","epoch: 34, time: 13442.450s, loss: 1.036, train accuracy: 0.602\n","epoch: 34, time: 13453.059s, loss: 0.903, train accuracy: 0.664\n","epoch: 34, time: 13463.694s, loss: 0.898, train accuracy: 0.672\n","epoch: 34, time: 13474.377s, loss: 1.006, train accuracy: 0.617\n","epoch: 34, time: 13485.032s, loss: 1.016, train accuracy: 0.523\n","epoch: 34, time: 13495.688s, loss: 1.056, train accuracy: 0.555\n","epoch: 34, time: 13506.342s, loss: 1.034, train accuracy: 0.617\n","epoch: 34, time: 13517.000s, loss: 1.112, train accuracy: 0.562\n","epoch: 34, time: 13527.636s, loss: 1.293, train accuracy: 0.523\n","epoch: 34, time: 13538.281s, loss: 0.864, train accuracy: 0.664\n","epoch: 34, time: 13548.930s, loss: 0.962, train accuracy: 0.594\n","epoch: 34, time: 13559.556s, loss: 1.144, train accuracy: 0.594\n","epoch: 34, time: 13570.187s, loss: 0.975, train accuracy: 0.555\n","epoch: 34, time: 13580.819s, loss: 0.930, train accuracy: 0.609\n","epoch: 34, time: 13591.460s, loss: 1.341, train accuracy: 0.484\n","epoch: 34, time: 13602.107s, loss: 0.978, train accuracy: 0.625\n","epoch: 34, time: 13612.746s, loss: 1.070, train accuracy: 0.586\n","epoch: 34, time: 13623.413s, loss: 1.050, train accuracy: 0.570\n","epoch: 34, time: 13634.087s, loss: 0.911, train accuracy: 0.695\n","epoch: 34, time: 13644.757s, loss: 1.051, train accuracy: 0.562\n","epoch: 34, time: 13655.434s, loss: 1.033, train accuracy: 0.633\n","epoch: 34, time: 13666.113s, loss: 0.916, train accuracy: 0.633\n","epoch: 34, time: 13676.780s, loss: 1.067, train accuracy: 0.586\n","epoch: 34, time: 13687.456s, loss: 0.969, train accuracy: 0.641\n","epoch: 34, time: 13698.124s, loss: 1.004, train accuracy: 0.586\n","epoch: 34, time: 13708.792s, loss: 1.069, train accuracy: 0.586\n","epoch: 34, time: 13719.430s, loss: 1.021, train accuracy: 0.641\n","epoch: 34, time: 13730.072s, loss: 1.175, train accuracy: 0.578\n","epoch: 34, time: 13740.721s, loss: 1.225, train accuracy: 0.508\n","epoch: 34, time: 13751.340s, loss: 0.910, train accuracy: 0.633\n","epoch: 34, time: 13761.995s, loss: 1.038, train accuracy: 0.602\n","epoch: 34, time: 13772.618s, loss: 1.145, train accuracy: 0.531\n","epoch: 34, time: 13783.240s, loss: 1.118, train accuracy: 0.586\n","epoch: 34, time: 13793.870s, loss: 1.056, train accuracy: 0.555\n","epoch: 34, time: 13804.507s, loss: 1.031, train accuracy: 0.609\n","epoch: 34, time: 13815.159s, loss: 0.940, train accuracy: 0.625\n","epoch: 34, time: 13825.802s, loss: 1.019, train accuracy: 0.586\n","epoch: 34, time: 13836.447s, loss: 1.222, train accuracy: 0.516\n","epoch: 34, validation loss: 0.8163078939482602\n","epoch: 35, time: 13849.689s, loss: 1.008, train accuracy: 0.578\n","epoch: 35, time: 13860.294s, loss: 1.122, train accuracy: 0.562\n","epoch: 35, time: 13870.950s, loss: 1.088, train accuracy: 0.586\n","epoch: 35, time: 13881.629s, loss: 1.071, train accuracy: 0.555\n","epoch: 35, time: 13892.306s, loss: 1.105, train accuracy: 0.555\n","epoch: 35, time: 13902.950s, loss: 1.002, train accuracy: 0.609\n","epoch: 35, time: 13913.564s, loss: 1.010, train accuracy: 0.594\n","epoch: 35, time: 13924.173s, loss: 1.039, train accuracy: 0.648\n","epoch: 35, time: 13934.813s, loss: 1.014, train accuracy: 0.602\n","epoch: 35, time: 13945.471s, loss: 1.067, train accuracy: 0.562\n","epoch: 35, time: 13956.131s, loss: 1.071, train accuracy: 0.594\n","epoch: 35, time: 13966.781s, loss: 1.051, train accuracy: 0.578\n","epoch: 35, time: 13977.423s, loss: 1.005, train accuracy: 0.617\n","epoch: 35, time: 13988.090s, loss: 1.109, train accuracy: 0.562\n","epoch: 35, time: 13998.764s, loss: 1.088, train accuracy: 0.602\n","epoch: 35, time: 14009.429s, loss: 1.098, train accuracy: 0.492\n","epoch: 35, time: 14020.093s, loss: 1.165, train accuracy: 0.531\n","epoch: 35, time: 14030.747s, loss: 0.942, train accuracy: 0.578\n","epoch: 35, time: 14041.412s, loss: 0.931, train accuracy: 0.586\n","epoch: 35, time: 14052.070s, loss: 1.116, train accuracy: 0.586\n","epoch: 35, time: 14062.740s, loss: 1.243, train accuracy: 0.484\n","epoch: 35, time: 14073.408s, loss: 0.954, train accuracy: 0.617\n","epoch: 35, time: 14084.059s, loss: 1.012, train accuracy: 0.586\n","epoch: 35, time: 14094.711s, loss: 1.134, train accuracy: 0.539\n","epoch: 35, time: 14105.373s, loss: 1.034, train accuracy: 0.609\n","epoch: 35, time: 14116.024s, loss: 1.220, train accuracy: 0.531\n","epoch: 35, time: 14126.661s, loss: 1.145, train accuracy: 0.516\n","epoch: 35, time: 14137.315s, loss: 1.002, train accuracy: 0.633\n","epoch: 35, time: 14147.969s, loss: 1.115, train accuracy: 0.523\n","epoch: 35, time: 14158.624s, loss: 1.117, train accuracy: 0.562\n","epoch: 35, time: 14169.253s, loss: 1.112, train accuracy: 0.523\n","epoch: 35, time: 14179.894s, loss: 1.015, train accuracy: 0.570\n","epoch: 35, time: 14190.549s, loss: 1.110, train accuracy: 0.547\n","epoch: 35, time: 14201.186s, loss: 0.968, train accuracy: 0.648\n","epoch: 35, time: 14211.851s, loss: 1.061, train accuracy: 0.547\n","epoch: 35, time: 14222.493s, loss: 0.877, train accuracy: 0.648\n","epoch: 35, time: 14233.154s, loss: 0.890, train accuracy: 0.664\n","epoch: 35, time: 14243.801s, loss: 1.074, train accuracy: 0.602\n","epoch: 35, validation loss: 0.7727319642679015\n","epoch: 36, time: 14256.986s, loss: 1.010, train accuracy: 0.531\n","epoch: 36, time: 14267.614s, loss: 1.175, train accuracy: 0.555\n","epoch: 36, time: 14278.265s, loss: 1.166, train accuracy: 0.539\n","epoch: 36, time: 14288.925s, loss: 1.018, train accuracy: 0.602\n","epoch: 36, time: 14299.592s, loss: 1.069, train accuracy: 0.555\n","epoch: 36, time: 14310.241s, loss: 0.976, train accuracy: 0.617\n","epoch: 36, time: 14320.908s, loss: 1.015, train accuracy: 0.633\n","epoch: 36, time: 14331.565s, loss: 1.105, train accuracy: 0.539\n","epoch: 36, time: 14342.237s, loss: 0.988, train accuracy: 0.570\n","epoch: 36, time: 14352.883s, loss: 0.905, train accuracy: 0.602\n","epoch: 36, time: 14363.528s, loss: 0.946, train accuracy: 0.633\n","epoch: 36, time: 14374.157s, loss: 1.111, train accuracy: 0.586\n","epoch: 36, time: 14384.800s, loss: 1.213, train accuracy: 0.555\n","epoch: 36, time: 14395.430s, loss: 1.008, train accuracy: 0.570\n","epoch: 36, time: 14406.059s, loss: 1.168, train accuracy: 0.578\n","epoch: 36, time: 14416.677s, loss: 1.001, train accuracy: 0.539\n","epoch: 36, time: 14427.296s, loss: 1.147, train accuracy: 0.562\n","epoch: 36, time: 14437.920s, loss: 1.012, train accuracy: 0.586\n","epoch: 36, time: 14448.546s, loss: 0.804, train accuracy: 0.664\n","epoch: 36, time: 14459.161s, loss: 1.113, train accuracy: 0.555\n","epoch: 36, time: 14469.802s, loss: 0.886, train accuracy: 0.570\n","epoch: 36, time: 14480.459s, loss: 1.260, train accuracy: 0.555\n","epoch: 36, time: 14491.108s, loss: 1.145, train accuracy: 0.492\n","epoch: 36, time: 14501.740s, loss: 1.209, train accuracy: 0.539\n","epoch: 36, time: 14512.377s, loss: 0.938, train accuracy: 0.609\n","epoch: 36, time: 14523.012s, loss: 1.049, train accuracy: 0.547\n","epoch: 36, time: 14533.682s, loss: 1.130, train accuracy: 0.516\n","epoch: 36, time: 14544.319s, loss: 1.136, train accuracy: 0.516\n","epoch: 36, time: 14554.971s, loss: 1.069, train accuracy: 0.562\n","epoch: 36, time: 14565.631s, loss: 0.980, train accuracy: 0.578\n","epoch: 36, time: 14576.284s, loss: 1.008, train accuracy: 0.609\n","epoch: 36, time: 14586.964s, loss: 0.929, train accuracy: 0.633\n","epoch: 36, time: 14597.600s, loss: 0.991, train accuracy: 0.633\n","epoch: 36, time: 14608.245s, loss: 0.909, train accuracy: 0.641\n","epoch: 36, time: 14618.878s, loss: 1.037, train accuracy: 0.586\n","epoch: 36, time: 14629.559s, loss: 1.083, train accuracy: 0.570\n","epoch: 36, time: 14640.250s, loss: 1.091, train accuracy: 0.562\n","epoch: 36, time: 14650.945s, loss: 1.010, train accuracy: 0.609\n","epoch: 36, validation loss: 0.744750532387162\n","epoch: 37, time: 14664.203s, loss: 1.073, train accuracy: 0.547\n","epoch: 37, time: 14674.840s, loss: 0.833, train accuracy: 0.672\n","epoch: 37, time: 14685.498s, loss: 1.013, train accuracy: 0.617\n","epoch: 37, time: 14696.182s, loss: 1.105, train accuracy: 0.555\n","epoch: 37, time: 14706.871s, loss: 1.139, train accuracy: 0.570\n","epoch: 37, time: 14717.540s, loss: 0.809, train accuracy: 0.664\n","epoch: 37, time: 14728.171s, loss: 1.002, train accuracy: 0.594\n","epoch: 37, time: 14738.809s, loss: 1.117, train accuracy: 0.578\n","epoch: 37, time: 14749.425s, loss: 1.025, train accuracy: 0.617\n","epoch: 37, time: 14760.066s, loss: 1.121, train accuracy: 0.516\n","epoch: 37, time: 14770.680s, loss: 1.054, train accuracy: 0.617\n","epoch: 37, time: 14781.298s, loss: 1.062, train accuracy: 0.594\n","epoch: 37, time: 14791.925s, loss: 1.031, train accuracy: 0.570\n","epoch: 37, time: 14802.560s, loss: 1.148, train accuracy: 0.539\n","epoch: 37, time: 14813.192s, loss: 1.109, train accuracy: 0.609\n","epoch: 37, time: 14823.829s, loss: 1.035, train accuracy: 0.602\n","epoch: 37, time: 14834.473s, loss: 1.295, train accuracy: 0.516\n","epoch: 37, time: 14845.122s, loss: 1.301, train accuracy: 0.508\n","epoch: 37, time: 14855.793s, loss: 0.962, train accuracy: 0.602\n","epoch: 37, time: 14866.422s, loss: 0.930, train accuracy: 0.641\n","epoch: 37, time: 14877.059s, loss: 1.074, train accuracy: 0.562\n","epoch: 37, time: 14887.722s, loss: 0.952, train accuracy: 0.625\n","epoch: 37, time: 14898.358s, loss: 1.073, train accuracy: 0.570\n","epoch: 37, time: 14908.992s, loss: 1.127, train accuracy: 0.539\n","epoch: 37, time: 14919.636s, loss: 0.903, train accuracy: 0.633\n","epoch: 37, time: 14930.267s, loss: 1.101, train accuracy: 0.594\n","epoch: 37, time: 14940.907s, loss: 0.964, train accuracy: 0.586\n","epoch: 37, time: 14951.536s, loss: 0.980, train accuracy: 0.594\n","epoch: 37, time: 14962.174s, loss: 1.018, train accuracy: 0.594\n","epoch: 37, time: 14972.813s, loss: 1.103, train accuracy: 0.516\n","epoch: 37, time: 14983.441s, loss: 0.957, train accuracy: 0.617\n","epoch: 37, time: 14994.090s, loss: 1.090, train accuracy: 0.578\n","epoch: 37, time: 15004.739s, loss: 1.220, train accuracy: 0.547\n","epoch: 37, time: 15015.369s, loss: 1.000, train accuracy: 0.617\n","epoch: 37, time: 15026.001s, loss: 1.042, train accuracy: 0.578\n","epoch: 37, time: 15036.663s, loss: 1.018, train accuracy: 0.555\n","epoch: 37, time: 15047.314s, loss: 1.017, train accuracy: 0.609\n","epoch: 37, time: 15057.959s, loss: 1.179, train accuracy: 0.508\n","epoch: 37, validation loss: 0.7662204739127332\n","epoch: 38, time: 15071.013s, loss: 0.946, train accuracy: 0.656\n","epoch: 38, time: 15081.637s, loss: 1.163, train accuracy: 0.562\n","epoch: 38, time: 15092.279s, loss: 0.982, train accuracy: 0.594\n","epoch: 38, time: 15102.920s, loss: 1.016, train accuracy: 0.602\n","epoch: 38, time: 15113.585s, loss: 1.077, train accuracy: 0.555\n","epoch: 38, time: 15124.268s, loss: 1.107, train accuracy: 0.586\n","epoch: 38, time: 15134.940s, loss: 0.919, train accuracy: 0.625\n","epoch: 38, time: 15145.607s, loss: 0.981, train accuracy: 0.609\n","epoch: 38, time: 15156.268s, loss: 1.159, train accuracy: 0.516\n","epoch: 38, time: 15166.934s, loss: 1.216, train accuracy: 0.523\n","epoch: 38, time: 15177.612s, loss: 0.999, train accuracy: 0.523\n","epoch: 38, time: 15188.276s, loss: 1.129, train accuracy: 0.570\n","epoch: 38, time: 15198.936s, loss: 1.058, train accuracy: 0.594\n","epoch: 38, time: 15209.604s, loss: 1.261, train accuracy: 0.516\n","epoch: 38, time: 15220.264s, loss: 1.088, train accuracy: 0.578\n","epoch: 38, time: 15230.908s, loss: 1.022, train accuracy: 0.609\n","epoch: 38, time: 15241.548s, loss: 1.012, train accuracy: 0.609\n","epoch: 38, time: 15252.190s, loss: 1.042, train accuracy: 0.594\n","epoch: 38, time: 15262.818s, loss: 1.076, train accuracy: 0.586\n","epoch: 38, time: 15273.430s, loss: 1.040, train accuracy: 0.617\n","epoch: 38, time: 15284.059s, loss: 1.043, train accuracy: 0.586\n","epoch: 38, time: 15294.707s, loss: 1.042, train accuracy: 0.531\n","epoch: 38, time: 15305.351s, loss: 1.271, train accuracy: 0.570\n","epoch: 38, time: 15315.982s, loss: 1.020, train accuracy: 0.547\n","epoch: 38, time: 15326.624s, loss: 1.101, train accuracy: 0.523\n","epoch: 38, time: 15337.267s, loss: 1.056, train accuracy: 0.617\n","epoch: 38, time: 15347.912s, loss: 1.027, train accuracy: 0.609\n","epoch: 38, time: 15358.537s, loss: 1.184, train accuracy: 0.484\n","epoch: 38, time: 15369.197s, loss: 0.884, train accuracy: 0.633\n","epoch: 38, time: 15379.847s, loss: 1.158, train accuracy: 0.609\n","epoch: 38, time: 15390.514s, loss: 1.125, train accuracy: 0.562\n","epoch: 38, time: 15401.167s, loss: 1.030, train accuracy: 0.547\n","epoch: 38, time: 15411.827s, loss: 1.074, train accuracy: 0.547\n","epoch: 38, time: 15422.447s, loss: 1.032, train accuracy: 0.562\n","epoch: 38, time: 15433.096s, loss: 1.070, train accuracy: 0.531\n","epoch: 38, time: 15443.731s, loss: 0.935, train accuracy: 0.617\n","epoch: 38, time: 15454.367s, loss: 0.960, train accuracy: 0.633\n","epoch: 38, time: 15465.013s, loss: 0.942, train accuracy: 0.641\n","epoch: 38, validation loss: 0.8209047715292811\n","epoch: 39, time: 15478.044s, loss: 1.051, train accuracy: 0.586\n","epoch: 39, time: 15488.645s, loss: 1.186, train accuracy: 0.539\n","epoch: 39, time: 15499.282s, loss: 0.959, train accuracy: 0.641\n","epoch: 39, time: 15509.940s, loss: 1.120, train accuracy: 0.555\n","epoch: 39, time: 15520.621s, loss: 0.940, train accuracy: 0.656\n","epoch: 39, time: 15531.295s, loss: 0.889, train accuracy: 0.695\n","epoch: 39, time: 15541.939s, loss: 1.046, train accuracy: 0.586\n","epoch: 39, time: 15552.579s, loss: 1.035, train accuracy: 0.586\n","epoch: 39, time: 15563.224s, loss: 0.956, train accuracy: 0.633\n","epoch: 39, time: 15573.855s, loss: 1.112, train accuracy: 0.578\n","epoch: 39, time: 15584.471s, loss: 1.025, train accuracy: 0.562\n","epoch: 39, time: 15595.116s, loss: 1.095, train accuracy: 0.547\n","epoch: 39, time: 15605.742s, loss: 0.999, train accuracy: 0.555\n","epoch: 39, time: 15616.367s, loss: 0.969, train accuracy: 0.594\n","epoch: 39, time: 15627.021s, loss: 1.090, train accuracy: 0.594\n","epoch: 39, time: 15637.661s, loss: 1.040, train accuracy: 0.578\n","epoch: 39, time: 15648.314s, loss: 1.119, train accuracy: 0.578\n","epoch: 39, time: 15658.966s, loss: 1.099, train accuracy: 0.609\n","epoch: 39, time: 15669.637s, loss: 1.016, train accuracy: 0.617\n","epoch: 39, time: 15680.282s, loss: 1.030, train accuracy: 0.555\n","epoch: 39, time: 15690.924s, loss: 0.987, train accuracy: 0.633\n","epoch: 39, time: 15701.561s, loss: 1.020, train accuracy: 0.516\n","epoch: 39, time: 15712.217s, loss: 1.125, train accuracy: 0.547\n","epoch: 39, time: 15722.869s, loss: 1.025, train accuracy: 0.578\n","epoch: 39, time: 15733.531s, loss: 1.193, train accuracy: 0.500\n","epoch: 39, time: 15744.185s, loss: 1.117, train accuracy: 0.555\n","epoch: 39, time: 15754.837s, loss: 1.083, train accuracy: 0.578\n","epoch: 39, time: 15765.488s, loss: 1.084, train accuracy: 0.547\n","epoch: 39, time: 15776.173s, loss: 0.997, train accuracy: 0.625\n","epoch: 39, time: 15786.819s, loss: 1.042, train accuracy: 0.633\n","epoch: 39, time: 15797.468s, loss: 1.075, train accuracy: 0.609\n","epoch: 39, time: 15808.138s, loss: 1.031, train accuracy: 0.609\n","epoch: 39, time: 15818.778s, loss: 1.012, train accuracy: 0.641\n","epoch: 39, time: 15829.425s, loss: 0.995, train accuracy: 0.648\n","epoch: 39, time: 15840.063s, loss: 0.881, train accuracy: 0.648\n","epoch: 39, time: 15850.710s, loss: 1.152, train accuracy: 0.523\n","epoch: 39, time: 15861.356s, loss: 0.993, train accuracy: 0.594\n","epoch: 39, time: 15872.009s, loss: 1.010, train accuracy: 0.609\n","epoch: 39, validation loss: 0.7666266471592348\n","epoch: 40, time: 15885.335s, loss: 0.922, train accuracy: 0.625\n","epoch: 40, time: 15895.936s, loss: 1.107, train accuracy: 0.594\n","epoch: 40, time: 15906.583s, loss: 1.056, train accuracy: 0.609\n","epoch: 40, time: 15917.267s, loss: 0.960, train accuracy: 0.594\n","epoch: 40, time: 15927.951s, loss: 0.859, train accuracy: 0.672\n","epoch: 40, time: 15938.630s, loss: 0.971, train accuracy: 0.609\n","epoch: 40, time: 15949.251s, loss: 1.016, train accuracy: 0.578\n","epoch: 40, time: 15959.896s, loss: 1.051, train accuracy: 0.617\n","epoch: 40, time: 15970.513s, loss: 0.928, train accuracy: 0.641\n","epoch: 40, time: 15981.137s, loss: 1.137, train accuracy: 0.531\n","epoch: 40, time: 15991.755s, loss: 1.061, train accuracy: 0.586\n","epoch: 40, time: 16002.413s, loss: 1.020, train accuracy: 0.633\n","epoch: 40, time: 16013.072s, loss: 1.155, train accuracy: 0.547\n","epoch: 40, time: 16023.695s, loss: 0.995, train accuracy: 0.625\n","epoch: 40, time: 16034.335s, loss: 1.054, train accuracy: 0.555\n","epoch: 40, time: 16044.988s, loss: 1.060, train accuracy: 0.578\n","epoch: 40, time: 16055.656s, loss: 1.058, train accuracy: 0.562\n","epoch: 40, time: 16066.314s, loss: 1.237, train accuracy: 0.492\n","epoch: 40, time: 16076.972s, loss: 1.114, train accuracy: 0.586\n","epoch: 40, time: 16087.626s, loss: 1.024, train accuracy: 0.633\n","epoch: 40, time: 16098.278s, loss: 1.029, train accuracy: 0.570\n","epoch: 40, time: 16108.921s, loss: 1.050, train accuracy: 0.578\n","epoch: 40, time: 16119.554s, loss: 1.029, train accuracy: 0.531\n","epoch: 40, time: 16130.180s, loss: 0.829, train accuracy: 0.719\n","epoch: 40, time: 16140.798s, loss: 0.949, train accuracy: 0.680\n","epoch: 40, time: 16151.445s, loss: 0.984, train accuracy: 0.602\n","epoch: 40, time: 16162.089s, loss: 0.854, train accuracy: 0.734\n","epoch: 40, time: 16172.721s, loss: 1.087, train accuracy: 0.539\n","epoch: 40, time: 16183.342s, loss: 0.988, train accuracy: 0.625\n","epoch: 40, time: 16193.975s, loss: 1.037, train accuracy: 0.602\n","epoch: 40, time: 16204.597s, loss: 1.002, train accuracy: 0.625\n","epoch: 40, time: 16215.237s, loss: 1.154, train accuracy: 0.500\n","epoch: 40, time: 16225.889s, loss: 0.879, train accuracy: 0.648\n","epoch: 40, time: 16236.530s, loss: 0.986, train accuracy: 0.555\n","epoch: 40, time: 16247.167s, loss: 1.029, train accuracy: 0.594\n","epoch: 40, time: 16257.831s, loss: 1.122, train accuracy: 0.508\n","epoch: 40, time: 16268.494s, loss: 0.894, train accuracy: 0.656\n","epoch: 40, time: 16279.135s, loss: 1.023, train accuracy: 0.602\n","epoch: 40, validation loss: 0.7732462304741589\n","epoch: 41, time: 16292.159s, loss: 0.955, train accuracy: 0.648\n","epoch: 41, time: 16302.773s, loss: 1.109, train accuracy: 0.594\n","epoch: 41, time: 16313.409s, loss: 0.957, train accuracy: 0.617\n","epoch: 41, time: 16324.081s, loss: 0.934, train accuracy: 0.609\n","epoch: 41, time: 16334.755s, loss: 1.093, train accuracy: 0.531\n","epoch: 41, time: 16345.405s, loss: 1.038, train accuracy: 0.594\n","epoch: 41, time: 16356.065s, loss: 0.973, train accuracy: 0.578\n","epoch: 41, time: 16366.718s, loss: 1.138, train accuracy: 0.562\n","epoch: 41, time: 16377.371s, loss: 1.035, train accuracy: 0.633\n","epoch: 41, time: 16388.009s, loss: 0.859, train accuracy: 0.688\n","epoch: 41, time: 16398.638s, loss: 1.066, train accuracy: 0.602\n","epoch: 41, time: 16409.294s, loss: 1.184, train accuracy: 0.547\n","epoch: 41, time: 16419.953s, loss: 1.068, train accuracy: 0.523\n","epoch: 41, time: 16430.598s, loss: 0.988, train accuracy: 0.656\n","epoch: 41, time: 16441.245s, loss: 1.192, train accuracy: 0.531\n","epoch: 41, time: 16451.894s, loss: 1.100, train accuracy: 0.609\n","epoch: 41, time: 16462.520s, loss: 1.182, train accuracy: 0.516\n","epoch: 41, time: 16473.166s, loss: 1.017, train accuracy: 0.617\n","epoch: 41, time: 16483.812s, loss: 0.952, train accuracy: 0.570\n","epoch: 41, time: 16494.438s, loss: 1.020, train accuracy: 0.602\n","epoch: 41, time: 16505.074s, loss: 1.204, train accuracy: 0.586\n","epoch: 41, time: 16515.744s, loss: 1.119, train accuracy: 0.578\n","epoch: 41, time: 16526.381s, loss: 1.219, train accuracy: 0.555\n","epoch: 41, time: 16537.023s, loss: 0.989, train accuracy: 0.570\n","epoch: 41, time: 16547.671s, loss: 1.100, train accuracy: 0.578\n","epoch: 41, time: 16558.286s, loss: 0.884, train accuracy: 0.648\n","epoch: 41, time: 16568.934s, loss: 1.081, train accuracy: 0.594\n","epoch: 41, time: 16579.585s, loss: 0.998, train accuracy: 0.578\n","epoch: 41, time: 16590.229s, loss: 1.085, train accuracy: 0.578\n","epoch: 41, time: 16600.888s, loss: 1.080, train accuracy: 0.570\n","epoch: 41, time: 16611.512s, loss: 0.896, train accuracy: 0.609\n","epoch: 41, time: 16622.141s, loss: 1.075, train accuracy: 0.578\n","epoch: 41, time: 16632.779s, loss: 0.939, train accuracy: 0.656\n","epoch: 41, time: 16643.415s, loss: 1.002, train accuracy: 0.578\n","epoch: 41, time: 16654.040s, loss: 1.088, train accuracy: 0.570\n","epoch: 41, time: 16664.670s, loss: 1.068, train accuracy: 0.602\n","epoch: 41, time: 16675.289s, loss: 1.242, train accuracy: 0.500\n","epoch: 41, time: 16685.898s, loss: 1.039, train accuracy: 0.578\n","epoch: 41, validation loss: 0.7681242394040643\n","epoch: 42, time: 16698.867s, loss: 1.128, train accuracy: 0.570\n","epoch: 42, time: 16709.475s, loss: 1.050, train accuracy: 0.625\n","epoch: 42, time: 16720.097s, loss: 0.943, train accuracy: 0.656\n","epoch: 42, time: 16730.737s, loss: 1.036, train accuracy: 0.609\n","epoch: 42, time: 16741.366s, loss: 0.875, train accuracy: 0.680\n","epoch: 42, time: 16752.025s, loss: 1.024, train accuracy: 0.648\n","epoch: 42, time: 16762.656s, loss: 1.065, train accuracy: 0.602\n","epoch: 42, time: 16773.293s, loss: 1.119, train accuracy: 0.547\n","epoch: 42, time: 16783.932s, loss: 1.030, train accuracy: 0.633\n","epoch: 42, time: 16794.577s, loss: 0.938, train accuracy: 0.602\n","epoch: 42, time: 16805.195s, loss: 0.967, train accuracy: 0.633\n","epoch: 42, time: 16815.822s, loss: 1.141, train accuracy: 0.555\n","epoch: 42, time: 16826.463s, loss: 0.920, train accuracy: 0.633\n","epoch: 42, time: 16837.082s, loss: 1.007, train accuracy: 0.555\n","epoch: 42, time: 16847.713s, loss: 1.124, train accuracy: 0.586\n","epoch: 42, time: 16858.346s, loss: 0.882, train accuracy: 0.641\n","epoch: 42, time: 16868.984s, loss: 1.108, train accuracy: 0.500\n","epoch: 42, time: 16879.618s, loss: 1.118, train accuracy: 0.562\n","epoch: 42, time: 16890.261s, loss: 1.028, train accuracy: 0.562\n","epoch: 42, time: 16900.915s, loss: 0.895, train accuracy: 0.648\n","epoch: 42, time: 16911.541s, loss: 1.052, train accuracy: 0.625\n","epoch: 42, time: 16922.185s, loss: 0.956, train accuracy: 0.633\n","epoch: 42, time: 16932.836s, loss: 1.115, train accuracy: 0.594\n","epoch: 42, time: 16943.470s, loss: 0.938, train accuracy: 0.625\n","epoch: 42, time: 16954.109s, loss: 0.955, train accuracy: 0.664\n","epoch: 42, time: 16964.762s, loss: 1.081, train accuracy: 0.523\n","epoch: 42, time: 16975.428s, loss: 1.008, train accuracy: 0.625\n","epoch: 42, time: 16986.072s, loss: 1.043, train accuracy: 0.562\n","epoch: 42, time: 16996.737s, loss: 1.107, train accuracy: 0.531\n","epoch: 42, time: 17007.393s, loss: 1.104, train accuracy: 0.602\n","epoch: 42, time: 17018.049s, loss: 1.056, train accuracy: 0.586\n","epoch: 42, time: 17028.696s, loss: 1.054, train accuracy: 0.602\n","epoch: 42, time: 17039.331s, loss: 1.020, train accuracy: 0.570\n","epoch: 42, time: 17049.992s, loss: 1.013, train accuracy: 0.578\n","epoch: 42, time: 17060.630s, loss: 1.061, train accuracy: 0.531\n","epoch: 42, time: 17071.285s, loss: 0.958, train accuracy: 0.664\n","epoch: 42, time: 17081.916s, loss: 1.002, train accuracy: 0.594\n","epoch: 42, time: 17092.537s, loss: 0.939, train accuracy: 0.625\n","epoch: 42, validation loss: 0.7681474854697042\n","epoch: 43, time: 17105.397s, loss: 1.090, train accuracy: 0.555\n","epoch: 43, time: 17115.998s, loss: 1.011, train accuracy: 0.594\n","epoch: 43, time: 17126.624s, loss: 0.986, train accuracy: 0.594\n","epoch: 43, time: 17137.264s, loss: 0.899, train accuracy: 0.688\n","epoch: 43, time: 17147.934s, loss: 0.873, train accuracy: 0.680\n","epoch: 43, time: 17158.584s, loss: 1.032, train accuracy: 0.633\n","epoch: 43, time: 17169.260s, loss: 0.994, train accuracy: 0.625\n","epoch: 43, time: 17179.937s, loss: 1.082, train accuracy: 0.531\n","epoch: 43, time: 17190.588s, loss: 1.118, train accuracy: 0.586\n","epoch: 43, time: 17201.248s, loss: 1.090, train accuracy: 0.562\n","epoch: 43, time: 17211.928s, loss: 0.975, train accuracy: 0.625\n","epoch: 43, time: 17222.592s, loss: 1.092, train accuracy: 0.555\n","epoch: 43, time: 17233.229s, loss: 1.170, train accuracy: 0.516\n","epoch: 43, time: 17243.884s, loss: 1.147, train accuracy: 0.594\n","epoch: 43, time: 17254.523s, loss: 1.066, train accuracy: 0.586\n","epoch: 43, time: 17265.176s, loss: 0.928, train accuracy: 0.602\n","epoch: 43, time: 17275.837s, loss: 0.993, train accuracy: 0.609\n","epoch: 43, time: 17286.504s, loss: 0.988, train accuracy: 0.648\n","epoch: 43, time: 17297.151s, loss: 1.108, train accuracy: 0.523\n","epoch: 43, time: 17307.810s, loss: 1.066, train accuracy: 0.656\n","epoch: 43, time: 17318.451s, loss: 0.964, train accuracy: 0.633\n","epoch: 43, time: 17329.084s, loss: 1.115, train accuracy: 0.531\n","epoch: 43, time: 17339.736s, loss: 1.005, train accuracy: 0.578\n","epoch: 43, time: 17350.407s, loss: 1.012, train accuracy: 0.648\n","epoch: 43, time: 17361.058s, loss: 1.095, train accuracy: 0.539\n","epoch: 43, time: 17371.716s, loss: 0.992, train accuracy: 0.570\n","epoch: 43, time: 17382.361s, loss: 0.984, train accuracy: 0.641\n","epoch: 43, time: 17393.012s, loss: 1.056, train accuracy: 0.602\n","epoch: 43, time: 17403.671s, loss: 1.023, train accuracy: 0.578\n","epoch: 43, time: 17414.337s, loss: 0.916, train accuracy: 0.688\n","epoch: 43, time: 17424.987s, loss: 0.998, train accuracy: 0.578\n","epoch: 43, time: 17435.635s, loss: 1.015, train accuracy: 0.602\n","epoch: 43, time: 17446.302s, loss: 1.090, train accuracy: 0.594\n","epoch: 43, time: 17456.975s, loss: 1.063, train accuracy: 0.594\n","epoch: 43, time: 17467.680s, loss: 1.074, train accuracy: 0.617\n","epoch: 43, time: 17478.348s, loss: 1.100, train accuracy: 0.555\n","epoch: 43, time: 17489.023s, loss: 0.992, train accuracy: 0.625\n","epoch: 43, time: 17499.674s, loss: 1.048, train accuracy: 0.547\n","epoch: 43, validation loss: 0.7807909308720246\n","epoch: 44, time: 17512.446s, loss: 1.030, train accuracy: 0.617\n","epoch: 44, time: 17523.088s, loss: 1.112, train accuracy: 0.547\n","epoch: 44, time: 17533.705s, loss: 1.025, train accuracy: 0.570\n","epoch: 44, time: 17544.347s, loss: 1.080, train accuracy: 0.594\n","epoch: 44, time: 17554.992s, loss: 0.983, train accuracy: 0.625\n","epoch: 44, time: 17565.640s, loss: 1.024, train accuracy: 0.633\n","epoch: 44, time: 17576.286s, loss: 0.971, train accuracy: 0.586\n","epoch: 44, time: 17586.937s, loss: 1.170, train accuracy: 0.523\n","epoch: 44, time: 17597.618s, loss: 0.973, train accuracy: 0.648\n","epoch: 44, time: 17608.256s, loss: 1.144, train accuracy: 0.523\n","epoch: 44, time: 17618.911s, loss: 1.088, train accuracy: 0.578\n","epoch: 44, time: 17629.548s, loss: 1.105, train accuracy: 0.602\n","epoch: 44, time: 17640.185s, loss: 1.040, train accuracy: 0.570\n","epoch: 44, time: 17650.814s, loss: 0.994, train accuracy: 0.609\n","epoch: 44, time: 17661.439s, loss: 1.060, train accuracy: 0.555\n","epoch: 44, time: 17672.060s, loss: 0.951, train accuracy: 0.586\n","epoch: 44, time: 17682.694s, loss: 1.136, train accuracy: 0.562\n","epoch: 44, time: 17693.292s, loss: 0.882, train accuracy: 0.664\n","epoch: 44, time: 17703.925s, loss: 1.033, train accuracy: 0.609\n","epoch: 44, time: 17714.546s, loss: 1.059, train accuracy: 0.516\n","epoch: 44, time: 17725.192s, loss: 0.859, train accuracy: 0.633\n","epoch: 44, time: 17735.835s, loss: 1.146, train accuracy: 0.500\n","epoch: 44, time: 17746.467s, loss: 1.119, train accuracy: 0.492\n","epoch: 44, time: 17757.101s, loss: 1.132, train accuracy: 0.578\n","epoch: 44, time: 17767.737s, loss: 1.010, train accuracy: 0.625\n","epoch: 44, time: 17778.418s, loss: 1.110, train accuracy: 0.594\n","epoch: 44, time: 17789.074s, loss: 0.870, train accuracy: 0.703\n","epoch: 44, time: 17799.725s, loss: 0.972, train accuracy: 0.602\n","epoch: 44, time: 17810.370s, loss: 1.079, train accuracy: 0.594\n","epoch: 44, time: 17821.019s, loss: 1.099, train accuracy: 0.562\n","epoch: 44, time: 17831.670s, loss: 1.052, train accuracy: 0.602\n","epoch: 44, time: 17842.318s, loss: 1.170, train accuracy: 0.586\n","epoch: 44, time: 17852.962s, loss: 0.951, train accuracy: 0.625\n","epoch: 44, time: 17863.608s, loss: 0.947, train accuracy: 0.602\n","epoch: 44, time: 17874.249s, loss: 1.144, train accuracy: 0.547\n","epoch: 44, time: 17884.880s, loss: 0.969, train accuracy: 0.648\n","epoch: 44, time: 17895.528s, loss: 1.028, train accuracy: 0.602\n","epoch: 44, time: 17906.171s, loss: 0.901, train accuracy: 0.656\n","epoch: 44, validation loss: 0.7737452831349647\n","epoch: 45, time: 17919.432s, loss: 1.061, train accuracy: 0.617\n","epoch: 45, time: 17930.039s, loss: 1.172, train accuracy: 0.570\n","epoch: 45, time: 17940.676s, loss: 1.041, train accuracy: 0.609\n","epoch: 45, time: 17951.340s, loss: 1.191, train accuracy: 0.477\n","epoch: 45, time: 17962.025s, loss: 0.967, train accuracy: 0.594\n","epoch: 45, time: 17972.676s, loss: 1.107, train accuracy: 0.586\n","epoch: 45, time: 17983.305s, loss: 0.951, train accuracy: 0.594\n","epoch: 45, time: 17993.924s, loss: 1.031, train accuracy: 0.547\n","epoch: 45, time: 18004.555s, loss: 1.086, train accuracy: 0.578\n","epoch: 45, time: 18015.193s, loss: 1.000, train accuracy: 0.625\n","epoch: 45, time: 18025.807s, loss: 1.075, train accuracy: 0.617\n","epoch: 45, time: 18036.444s, loss: 1.077, train accuracy: 0.523\n","epoch: 45, time: 18047.066s, loss: 1.008, train accuracy: 0.555\n","epoch: 45, time: 18057.715s, loss: 1.059, train accuracy: 0.641\n","epoch: 45, time: 18068.344s, loss: 1.059, train accuracy: 0.539\n","epoch: 45, time: 18079.002s, loss: 1.001, train accuracy: 0.617\n","epoch: 45, time: 18089.645s, loss: 0.959, train accuracy: 0.641\n","epoch: 45, time: 18100.268s, loss: 0.979, train accuracy: 0.594\n","epoch: 45, time: 18110.904s, loss: 0.785, train accuracy: 0.727\n","epoch: 45, time: 18121.560s, loss: 1.194, train accuracy: 0.516\n","epoch: 45, time: 18132.218s, loss: 1.056, train accuracy: 0.617\n","epoch: 45, time: 18142.855s, loss: 1.012, train accuracy: 0.625\n","epoch: 45, time: 18153.515s, loss: 1.042, train accuracy: 0.633\n","epoch: 45, time: 18164.155s, loss: 1.000, train accuracy: 0.625\n","epoch: 45, time: 18174.811s, loss: 0.884, train accuracy: 0.656\n","epoch: 45, time: 18185.471s, loss: 1.068, train accuracy: 0.594\n","epoch: 45, time: 18196.118s, loss: 1.014, train accuracy: 0.625\n","epoch: 45, time: 18206.789s, loss: 0.993, train accuracy: 0.562\n","epoch: 45, time: 18217.415s, loss: 1.111, train accuracy: 0.484\n","epoch: 45, time: 18228.044s, loss: 1.053, train accuracy: 0.578\n","epoch: 45, time: 18238.681s, loss: 1.129, train accuracy: 0.586\n","epoch: 45, time: 18249.324s, loss: 0.951, train accuracy: 0.586\n","epoch: 45, time: 18259.944s, loss: 1.094, train accuracy: 0.484\n","epoch: 45, time: 18270.590s, loss: 1.063, train accuracy: 0.531\n","epoch: 45, time: 18281.216s, loss: 1.224, train accuracy: 0.539\n","epoch: 45, time: 18291.839s, loss: 1.113, train accuracy: 0.562\n","epoch: 45, time: 18302.450s, loss: 0.948, train accuracy: 0.578\n","epoch: 45, time: 18313.071s, loss: 1.230, train accuracy: 0.492\n","epoch: 45, validation loss: 0.7584221997240713\n","epoch: 46, time: 18326.122s, loss: 1.069, train accuracy: 0.562\n","epoch: 46, time: 18336.715s, loss: 1.092, train accuracy: 0.531\n","epoch: 46, time: 18347.375s, loss: 1.233, train accuracy: 0.539\n","epoch: 46, time: 18358.034s, loss: 1.041, train accuracy: 0.570\n","epoch: 46, time: 18368.694s, loss: 0.988, train accuracy: 0.539\n","epoch: 46, time: 18379.339s, loss: 0.960, train accuracy: 0.617\n","epoch: 46, time: 18390.000s, loss: 1.014, train accuracy: 0.633\n","epoch: 46, time: 18400.619s, loss: 0.931, train accuracy: 0.609\n","epoch: 46, time: 18411.252s, loss: 1.063, train accuracy: 0.570\n","epoch: 46, time: 18421.876s, loss: 1.233, train accuracy: 0.461\n","epoch: 46, time: 18432.493s, loss: 1.088, train accuracy: 0.570\n","epoch: 46, time: 18443.126s, loss: 0.930, train accuracy: 0.672\n","epoch: 46, time: 18453.748s, loss: 1.111, train accuracy: 0.617\n","epoch: 46, time: 18464.382s, loss: 0.987, train accuracy: 0.555\n","epoch: 46, time: 18475.030s, loss: 1.251, train accuracy: 0.477\n","epoch: 46, time: 18485.661s, loss: 1.046, train accuracy: 0.570\n","epoch: 46, time: 18496.306s, loss: 1.010, train accuracy: 0.547\n","epoch: 46, time: 18506.954s, loss: 1.239, train accuracy: 0.484\n","epoch: 46, time: 18517.579s, loss: 1.132, train accuracy: 0.508\n","epoch: 46, time: 18528.208s, loss: 1.130, train accuracy: 0.562\n","epoch: 46, time: 18538.838s, loss: 0.940, train accuracy: 0.625\n","epoch: 46, time: 18549.462s, loss: 0.900, train accuracy: 0.617\n","epoch: 46, time: 18560.094s, loss: 0.986, train accuracy: 0.633\n","epoch: 46, time: 18570.730s, loss: 1.054, train accuracy: 0.586\n","epoch: 46, time: 18581.362s, loss: 1.072, train accuracy: 0.570\n","epoch: 46, time: 18592.004s, loss: 1.098, train accuracy: 0.531\n","epoch: 46, time: 18602.635s, loss: 1.034, train accuracy: 0.570\n","epoch: 46, time: 18613.274s, loss: 1.096, train accuracy: 0.602\n","epoch: 46, time: 18623.896s, loss: 1.256, train accuracy: 0.492\n","epoch: 46, time: 18634.546s, loss: 1.036, train accuracy: 0.586\n","epoch: 46, time: 18645.201s, loss: 1.171, train accuracy: 0.555\n","epoch: 46, time: 18655.863s, loss: 0.804, train accuracy: 0.719\n","epoch: 46, time: 18666.508s, loss: 0.980, train accuracy: 0.578\n","epoch: 46, time: 18677.156s, loss: 1.148, train accuracy: 0.555\n","epoch: 46, time: 18687.792s, loss: 1.049, train accuracy: 0.516\n","epoch: 46, time: 18698.439s, loss: 0.952, train accuracy: 0.648\n","epoch: 46, time: 18709.090s, loss: 1.043, train accuracy: 0.594\n","epoch: 46, time: 18719.746s, loss: 1.033, train accuracy: 0.602\n","epoch: 46, validation loss: 0.7636788388305127\n","epoch: 47, time: 18732.752s, loss: 0.963, train accuracy: 0.625\n","epoch: 47, time: 18743.385s, loss: 1.166, train accuracy: 0.594\n","epoch: 47, time: 18754.026s, loss: 1.061, train accuracy: 0.625\n","epoch: 47, time: 18764.657s, loss: 1.034, train accuracy: 0.625\n","epoch: 47, time: 18775.291s, loss: 1.040, train accuracy: 0.578\n","epoch: 47, time: 18785.915s, loss: 1.339, train accuracy: 0.453\n","epoch: 47, time: 18796.574s, loss: 1.055, train accuracy: 0.594\n","epoch: 47, time: 18807.233s, loss: 0.888, train accuracy: 0.633\n","epoch: 47, time: 18817.905s, loss: 1.083, train accuracy: 0.562\n","epoch: 47, time: 18828.552s, loss: 1.043, train accuracy: 0.609\n","epoch: 47, time: 18839.203s, loss: 1.330, train accuracy: 0.539\n","epoch: 47, time: 18849.859s, loss: 1.065, train accuracy: 0.578\n","epoch: 47, time: 18860.523s, loss: 0.905, train accuracy: 0.680\n","epoch: 47, time: 18871.182s, loss: 0.986, train accuracy: 0.664\n","epoch: 47, time: 18881.822s, loss: 1.049, train accuracy: 0.586\n","epoch: 47, time: 18892.458s, loss: 1.108, train accuracy: 0.602\n","epoch: 47, time: 18903.109s, loss: 1.001, train accuracy: 0.578\n","epoch: 47, time: 18913.763s, loss: 1.168, train accuracy: 0.547\n","epoch: 47, time: 18924.414s, loss: 0.929, train accuracy: 0.625\n","epoch: 47, time: 18935.071s, loss: 0.957, train accuracy: 0.656\n","epoch: 47, time: 18945.729s, loss: 1.033, train accuracy: 0.633\n","epoch: 47, time: 18956.386s, loss: 0.980, train accuracy: 0.625\n","epoch: 47, time: 18967.044s, loss: 1.097, train accuracy: 0.555\n","epoch: 47, time: 18977.690s, loss: 1.143, train accuracy: 0.555\n","epoch: 47, time: 18988.348s, loss: 1.065, train accuracy: 0.562\n","epoch: 47, time: 18999.022s, loss: 1.103, train accuracy: 0.562\n","epoch: 47, time: 19009.669s, loss: 1.027, train accuracy: 0.609\n","epoch: 47, time: 19020.315s, loss: 1.113, train accuracy: 0.570\n","epoch: 47, time: 19030.930s, loss: 1.132, train accuracy: 0.547\n","epoch: 47, time: 19041.543s, loss: 0.978, train accuracy: 0.648\n","epoch: 47, time: 19052.179s, loss: 0.857, train accuracy: 0.680\n","epoch: 47, time: 19062.835s, loss: 1.072, train accuracy: 0.586\n","epoch: 47, time: 19073.485s, loss: 1.147, train accuracy: 0.586\n","epoch: 47, time: 19084.139s, loss: 0.985, train accuracy: 0.586\n","epoch: 47, time: 19094.779s, loss: 0.979, train accuracy: 0.586\n","epoch: 47, time: 19105.430s, loss: 0.966, train accuracy: 0.617\n","epoch: 47, time: 19116.067s, loss: 0.996, train accuracy: 0.594\n","epoch: 47, time: 19126.692s, loss: 1.160, train accuracy: 0.570\n","epoch: 47, validation loss: 0.761882306161974\n","epoch: 48, time: 19139.776s, loss: 0.993, train accuracy: 0.609\n","epoch: 48, time: 19150.403s, loss: 1.066, train accuracy: 0.625\n","epoch: 48, time: 19161.039s, loss: 0.907, train accuracy: 0.594\n","epoch: 48, time: 19171.712s, loss: 1.150, train accuracy: 0.531\n","epoch: 48, time: 19182.404s, loss: 0.935, train accuracy: 0.625\n","epoch: 48, time: 19193.054s, loss: 0.933, train accuracy: 0.625\n","epoch: 48, time: 19203.688s, loss: 0.968, train accuracy: 0.594\n","epoch: 48, time: 19214.314s, loss: 0.927, train accuracy: 0.617\n","epoch: 48, time: 19224.957s, loss: 1.062, train accuracy: 0.547\n","epoch: 48, time: 19235.580s, loss: 0.884, train accuracy: 0.641\n","epoch: 48, time: 19246.227s, loss: 0.999, train accuracy: 0.586\n","epoch: 48, time: 19256.869s, loss: 1.083, train accuracy: 0.609\n","epoch: 48, time: 19267.514s, loss: 1.020, train accuracy: 0.609\n","epoch: 48, time: 19278.148s, loss: 1.081, train accuracy: 0.578\n","epoch: 48, time: 19288.797s, loss: 1.063, train accuracy: 0.586\n","epoch: 48, time: 19299.450s, loss: 1.247, train accuracy: 0.523\n","epoch: 48, time: 19310.100s, loss: 1.110, train accuracy: 0.617\n","epoch: 48, time: 19320.761s, loss: 0.998, train accuracy: 0.641\n","epoch: 48, time: 19331.436s, loss: 0.995, train accuracy: 0.609\n","epoch: 48, time: 19342.094s, loss: 1.109, train accuracy: 0.562\n","epoch: 48, time: 19352.733s, loss: 1.075, train accuracy: 0.570\n","epoch: 48, time: 19363.392s, loss: 1.046, train accuracy: 0.562\n","epoch: 48, time: 19374.057s, loss: 1.106, train accuracy: 0.609\n","epoch: 48, time: 19384.698s, loss: 1.056, train accuracy: 0.578\n","epoch: 48, time: 19395.330s, loss: 1.085, train accuracy: 0.570\n","epoch: 48, time: 19405.990s, loss: 0.846, train accuracy: 0.688\n","epoch: 48, time: 19416.646s, loss: 0.977, train accuracy: 0.586\n","epoch: 48, time: 19427.291s, loss: 1.009, train accuracy: 0.609\n","epoch: 48, time: 19437.950s, loss: 1.012, train accuracy: 0.617\n","epoch: 48, time: 19448.616s, loss: 0.932, train accuracy: 0.609\n","epoch: 48, time: 19459.278s, loss: 0.938, train accuracy: 0.617\n","epoch: 48, time: 19469.921s, loss: 1.165, train accuracy: 0.555\n","epoch: 48, time: 19480.576s, loss: 0.855, train accuracy: 0.664\n","epoch: 48, time: 19491.231s, loss: 0.995, train accuracy: 0.633\n","epoch: 48, time: 19501.886s, loss: 1.002, train accuracy: 0.594\n","epoch: 48, time: 19512.554s, loss: 1.141, train accuracy: 0.531\n","epoch: 48, time: 19523.195s, loss: 1.136, train accuracy: 0.570\n","epoch: 48, time: 19533.844s, loss: 0.981, train accuracy: 0.633\n","epoch: 48, validation loss: 0.7521693504441267\n","epoch: 49, time: 19547.065s, loss: 1.081, train accuracy: 0.578\n","epoch: 49, time: 19557.684s, loss: 1.068, train accuracy: 0.570\n","epoch: 49, time: 19568.313s, loss: 1.066, train accuracy: 0.555\n","epoch: 49, time: 19578.937s, loss: 0.973, train accuracy: 0.594\n","epoch: 49, time: 19589.596s, loss: 1.010, train accuracy: 0.609\n","epoch: 49, time: 19600.231s, loss: 0.971, train accuracy: 0.617\n","epoch: 49, time: 19610.896s, loss: 1.069, train accuracy: 0.594\n","epoch: 49, time: 19621.567s, loss: 1.106, train accuracy: 0.562\n","epoch: 49, time: 19632.216s, loss: 0.994, train accuracy: 0.602\n","epoch: 49, time: 19642.844s, loss: 1.218, train accuracy: 0.602\n","epoch: 49, time: 19653.469s, loss: 1.033, train accuracy: 0.586\n","epoch: 49, time: 19664.115s, loss: 0.987, train accuracy: 0.648\n","epoch: 49, time: 19674.775s, loss: 1.083, train accuracy: 0.586\n","epoch: 49, time: 19685.454s, loss: 0.896, train accuracy: 0.633\n","epoch: 49, time: 19696.110s, loss: 1.054, train accuracy: 0.562\n","epoch: 49, time: 19706.776s, loss: 1.074, train accuracy: 0.570\n","epoch: 49, time: 19717.432s, loss: 1.156, train accuracy: 0.500\n","epoch: 49, time: 19728.088s, loss: 1.137, train accuracy: 0.555\n","epoch: 49, time: 19738.735s, loss: 0.931, train accuracy: 0.617\n","epoch: 49, time: 19749.380s, loss: 0.906, train accuracy: 0.617\n","epoch: 49, time: 19760.012s, loss: 1.171, train accuracy: 0.500\n","epoch: 49, time: 19770.636s, loss: 1.059, train accuracy: 0.578\n","epoch: 49, time: 19781.270s, loss: 1.119, train accuracy: 0.570\n","epoch: 49, time: 19791.890s, loss: 1.160, train accuracy: 0.500\n","epoch: 49, time: 19802.536s, loss: 1.069, train accuracy: 0.570\n","epoch: 49, time: 19813.196s, loss: 1.009, train accuracy: 0.625\n","epoch: 49, time: 19823.829s, loss: 1.180, train accuracy: 0.586\n","epoch: 49, time: 19834.481s, loss: 1.126, train accuracy: 0.562\n","epoch: 49, time: 19845.136s, loss: 1.092, train accuracy: 0.625\n","epoch: 49, time: 19855.773s, loss: 1.168, train accuracy: 0.562\n","epoch: 49, time: 19866.421s, loss: 0.968, train accuracy: 0.555\n","epoch: 49, time: 19877.095s, loss: 0.938, train accuracy: 0.578\n","epoch: 49, time: 19887.786s, loss: 1.004, train accuracy: 0.609\n","epoch: 49, time: 19898.468s, loss: 1.001, train accuracy: 0.578\n","epoch: 49, time: 19909.150s, loss: 0.986, train accuracy: 0.625\n","epoch: 49, time: 19919.828s, loss: 0.971, train accuracy: 0.539\n","epoch: 49, time: 19930.518s, loss: 1.091, train accuracy: 0.594\n","epoch: 49, time: 19941.209s, loss: 1.118, train accuracy: 0.617\n","epoch: 49, validation loss: 0.7532403967273769\n","epoch: 50, time: 19954.011s, loss: 1.058, train accuracy: 0.578\n","epoch: 50, time: 19964.638s, loss: 1.043, train accuracy: 0.562\n","epoch: 50, time: 19975.254s, loss: 1.072, train accuracy: 0.578\n","epoch: 50, time: 19985.888s, loss: 0.932, train accuracy: 0.625\n","epoch: 50, time: 19996.522s, loss: 1.003, train accuracy: 0.602\n","epoch: 50, time: 20007.155s, loss: 0.995, train accuracy: 0.602\n","epoch: 50, time: 20017.791s, loss: 0.981, train accuracy: 0.617\n","epoch: 50, time: 20028.430s, loss: 1.058, train accuracy: 0.625\n","epoch: 50, time: 20039.082s, loss: 1.256, train accuracy: 0.594\n","epoch: 50, time: 20049.720s, loss: 1.045, train accuracy: 0.617\n","epoch: 50, time: 20060.377s, loss: 1.000, train accuracy: 0.648\n","epoch: 50, time: 20071.026s, loss: 1.179, train accuracy: 0.547\n","epoch: 50, time: 20081.651s, loss: 0.936, train accuracy: 0.594\n","epoch: 50, time: 20092.308s, loss: 0.965, train accuracy: 0.648\n","epoch: 50, time: 20102.963s, loss: 1.141, train accuracy: 0.562\n","epoch: 50, time: 20113.610s, loss: 0.772, train accuracy: 0.695\n","epoch: 50, time: 20124.271s, loss: 1.150, train accuracy: 0.562\n","epoch: 50, time: 20134.914s, loss: 1.016, train accuracy: 0.641\n","epoch: 50, time: 20145.545s, loss: 1.157, train accuracy: 0.625\n","epoch: 50, time: 20156.183s, loss: 0.972, train accuracy: 0.602\n","epoch: 50, time: 20166.826s, loss: 1.009, train accuracy: 0.594\n","epoch: 50, time: 20177.448s, loss: 1.103, train accuracy: 0.570\n","epoch: 50, time: 20188.077s, loss: 1.078, train accuracy: 0.547\n","epoch: 50, time: 20198.709s, loss: 0.941, train accuracy: 0.625\n","epoch: 50, time: 20209.339s, loss: 0.970, train accuracy: 0.625\n","epoch: 50, time: 20219.974s, loss: 1.003, train accuracy: 0.586\n","epoch: 50, time: 20230.650s, loss: 0.871, train accuracy: 0.617\n","epoch: 50, time: 20241.330s, loss: 1.195, train accuracy: 0.562\n","epoch: 50, time: 20251.982s, loss: 1.094, train accuracy: 0.500\n","epoch: 50, time: 20262.626s, loss: 1.098, train accuracy: 0.547\n","epoch: 50, time: 20273.299s, loss: 0.990, train accuracy: 0.594\n","epoch: 50, time: 20283.948s, loss: 1.058, train accuracy: 0.555\n","epoch: 50, time: 20294.605s, loss: 1.063, train accuracy: 0.586\n","epoch: 50, time: 20305.260s, loss: 0.947, train accuracy: 0.625\n","epoch: 50, time: 20315.920s, loss: 0.981, train accuracy: 0.625\n","epoch: 50, time: 20326.590s, loss: 1.098, train accuracy: 0.578\n","epoch: 50, time: 20337.283s, loss: 1.123, train accuracy: 0.562\n","epoch: 50, time: 20347.975s, loss: 1.044, train accuracy: 0.625\n","epoch: 50, validation loss: 0.767391152346312\n","epoch: 51, time: 20360.784s, loss: 1.029, train accuracy: 0.633\n","epoch: 51, time: 20371.415s, loss: 0.997, train accuracy: 0.570\n","epoch: 51, time: 20382.047s, loss: 0.992, train accuracy: 0.633\n","epoch: 51, time: 20392.732s, loss: 1.224, train accuracy: 0.516\n","epoch: 51, time: 20403.361s, loss: 0.957, train accuracy: 0.594\n","epoch: 51, time: 20414.008s, loss: 1.080, train accuracy: 0.555\n","epoch: 51, time: 20424.645s, loss: 1.021, train accuracy: 0.594\n","epoch: 51, time: 20435.269s, loss: 0.987, train accuracy: 0.562\n","epoch: 51, time: 20445.909s, loss: 1.009, train accuracy: 0.594\n","epoch: 51, time: 20456.546s, loss: 0.940, train accuracy: 0.625\n","epoch: 51, time: 20467.169s, loss: 1.030, train accuracy: 0.586\n","epoch: 51, time: 20477.816s, loss: 1.037, train accuracy: 0.617\n","epoch: 51, time: 20488.450s, loss: 1.042, train accuracy: 0.609\n","epoch: 51, time: 20499.137s, loss: 1.076, train accuracy: 0.586\n","epoch: 51, time: 20509.797s, loss: 1.173, train accuracy: 0.523\n","epoch: 51, time: 20520.465s, loss: 1.105, train accuracy: 0.555\n","epoch: 51, time: 20531.125s, loss: 1.071, train accuracy: 0.602\n","epoch: 51, time: 20541.781s, loss: 0.997, train accuracy: 0.602\n","epoch: 51, time: 20552.424s, loss: 1.054, train accuracy: 0.578\n","epoch: 51, time: 20563.068s, loss: 1.014, train accuracy: 0.586\n","epoch: 51, time: 20573.702s, loss: 0.961, train accuracy: 0.586\n","epoch: 51, time: 20584.334s, loss: 1.104, train accuracy: 0.609\n","epoch: 51, time: 20594.991s, loss: 0.967, train accuracy: 0.609\n","epoch: 51, time: 20605.617s, loss: 1.088, train accuracy: 0.523\n","epoch: 51, time: 20616.239s, loss: 1.049, train accuracy: 0.594\n","epoch: 51, time: 20626.854s, loss: 1.035, train accuracy: 0.586\n","epoch: 51, time: 20637.508s, loss: 0.968, train accuracy: 0.570\n","epoch: 51, time: 20648.144s, loss: 1.113, train accuracy: 0.594\n","epoch: 51, time: 20658.787s, loss: 1.159, train accuracy: 0.570\n","epoch: 51, time: 20669.438s, loss: 1.016, train accuracy: 0.547\n","epoch: 51, time: 20680.054s, loss: 1.132, train accuracy: 0.562\n","epoch: 51, time: 20690.691s, loss: 0.977, train accuracy: 0.648\n","epoch: 51, time: 20701.327s, loss: 1.061, train accuracy: 0.578\n","epoch: 51, time: 20711.960s, loss: 1.018, train accuracy: 0.609\n","epoch: 51, time: 20722.588s, loss: 1.160, train accuracy: 0.516\n","epoch: 51, time: 20733.239s, loss: 1.073, train accuracy: 0.539\n","epoch: 51, time: 20743.867s, loss: 1.068, train accuracy: 0.578\n","epoch: 51, time: 20754.489s, loss: 1.160, train accuracy: 0.609\n","epoch: 51, validation loss: 0.8045352458445503\n","Early Stopping!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3BimAuva1Cif"},"source":["## Show validation loss"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"7LMw1LPECAvW","executionInfo":{"status":"ok","timestamp":1611859642922,"user_tz":-60,"elapsed":20789158,"user":{"displayName":"Thi Que-Lam Elisa Nguyen","photoUrl":"","userId":"14516834551380015257"}},"outputId":"2a1bf7a9-e222-496b-d68d-8b1f43cbc5fb"},"source":["import pandas as pd\r\n","\r\n","df_plot = pd.DataFrame(data = plot_valloss, columns=['Validation Loss', 'Epoch'])\r\n","df_plot.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Validation Loss</th>\n","      <th>Epoch</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.798635</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.772971</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.765280</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.780865</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.756084</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Validation Loss  Epoch\n","0         0.798635      1\n","1         0.772971      2\n","2         0.765280      3\n","3         0.780865      4\n","4         0.756084      5"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"RGpBeJP6CD7g","executionInfo":{"status":"ok","timestamp":1611859644847,"user_tz":-60,"elapsed":20791070,"user":{"displayName":"Thi Que-Lam Elisa Nguyen","photoUrl":"","userId":"14516834551380015257"}},"outputId":"6634cd86-5e85-4183-d103-fafcbc99004a"},"source":["import plotly.express as px\r\n","\r\n","fig = px.line(df_plot, x=\"Epoch\", y=\"Validation Loss\", title='Validation Loss FAT')\r\n","fig.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>\n","            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n","                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n","            <div id=\"074bc729-2f66-463e-822e-4ef8b6cecbde\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n","            <script type=\"text/javascript\">\n","                \n","                    window.PLOTLYENV=window.PLOTLYENV || {};\n","                    \n","                if (document.getElementById(\"074bc729-2f66-463e-822e-4ef8b6cecbde\")) {\n","                    Plotly.newPlot(\n","                        '074bc729-2f66-463e-822e-4ef8b6cecbde',\n","                        [{\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"Epoch=%{x}<br>Validation Loss=%{y}\", \"legendgroup\": \"\", \"line\": {\"color\": \"#636efa\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51], \"xaxis\": \"x\", \"y\": [0.7986345774075115, 0.7729705448852164, 0.7652800460614121, 0.7808647901772945, 0.7560840110534798, 0.7675409611862606, 0.7542840495292567, 0.7536456071491688, 0.7658484185428254, 0.7685696748273967, 0.7703659552246777, 0.7720126643109677, 0.766272341010413, 0.7830232899072074, 0.7891853388184423, 0.8170422920540198, 0.7524909706258062, 0.7791710470531032, 0.7654518649013821, 0.7981414958866421, 0.8127564860305299, 0.7646085378457742, 0.7511502869093596, 0.7820170156991304, 0.7798298654525773, 0.7658200839689291, 0.7832760832457146, 0.7704328083788662, 0.7572596328599113, 0.7973500581692531, 0.7435883673777712, 0.7587292798038231, 0.7691883415555649, 0.8163078939482602, 0.7727319642679015, 0.744750532387162, 0.7662204739127332, 0.8209047715292811, 0.7666266471592348, 0.7732462304741589, 0.7681242394040643, 0.7681474854697042, 0.7807909308720246, 0.7737452831349647, 0.7584221997240713, 0.7636788388305127, 0.761882306161974, 0.7521693504441267, 0.7532403967273769, 0.767391152346312, 0.8045352458445503], \"yaxis\": \"y\"}],\n","                        {\"legend\": {\"tracegroupgap\": 0}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Validation Loss FAT\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Epoch\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Validation Loss\"}}},\n","                        {\"responsive\": true}\n","                    ).then(function(){\n","                            \n","var gd = document.getElementById('074bc729-2f66-463e-822e-4ef8b6cecbde');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })\n","                };\n","                \n","            </script>\n","        </div>\n","</body>\n","</html>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"v3KPal47CGGp"},"source":["df_plot.to_csv(\"/content/drive/MyDrive/Deep Learning/Project/FATDA_valloss.csv\", index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0QFSDbpK1G2W"},"source":["# Testing"]},{"cell_type":"markdown","metadata":{"id":"wwnfqz-j1IXE"},"source":["## Test on clean data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OwExvF2hmDNT","executionInfo":{"status":"ok","timestamp":1611859744137,"user_tz":-60,"elapsed":1774,"user":{"displayName":"Thi Que-Lam Elisa Nguyen","photoUrl":"","userId":"14516834551380015257"}},"outputId":"8ff3baf8-fcfb-4579-c074-b5b5b7a1102b"},"source":["correct_total = 0\r\n","\r\n","for i, (x_batch, y_batch) in enumerate(testloader):\r\n","  x_batch, y_batch = x_batch.to(device), y_batch.to(device)  # Move the data to the device that is used\r\n","\r\n","  y_pred = model_fatda(x_batch)\r\n","  y_pred_max = torch.argmax(y_pred, dim=1)\r\n","\r\n","  correct_total += torch.sum(torch.eq(y_pred_max, y_batch)).item()\r\n","\r\n","print(f'Accuracy on the test set: {correct_total / len(testset):.3f}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy on the test set: 0.760\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iFlyqmilU9dW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611859757971,"user_tz":-60,"elapsed":562,"user":{"displayName":"Thi Que-Lam Elisa Nguyen","photoUrl":"","userId":"14516834551380015257"}},"outputId":"b00865eb-df75-47f6-bc45-57ec3d36f219"},"source":["accuracy = correct_total / len(testset)\r\n","z = 1.96 #for 95% CI\r\n","n = len(testset)\r\n","\r\n","interval = z * np.sqrt( (accuracy * (1 - accuracy)) / n)\r\n","interval"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.008370829349592547"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"markdown","metadata":{"id":"V7mUPLjMnIP7"},"source":["## Test on perturbed data"]},{"cell_type":"code","metadata":{"id":"YdcWcFrQozXp"},"source":["import pandas as pd\r\n","import seaborn as sn\r\n","from advertorch.utils import predict_from_logits"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"egqg9rVDgh5p","executionInfo":{"status":"ok","timestamp":1611859662224,"user_tz":-60,"elapsed":20808389,"user":{"displayName":"Thi Que-Lam Elisa Nguyen","photoUrl":"","userId":"14516834551380015257"}},"outputId":"ba980cd4-eb0e-4ef0-fade-d10f74d488c2"},"source":["\r\n","correct_total = 0\r\n","all_preds = []\r\n","y_true = []\r\n","\r\n","for i, (x_batch, y_batch) in enumerate(testloader):\r\n","  x_batch, y_batch = x_batch.to(device), y_batch.to(device)  # Move the data to the device that is used\r\n","  y_true.extend(y_batch)\r\n","\r\n","  adv = adversary.perturb(x_batch, y_batch)\r\n","\r\n","  y_adv_pred = predict_from_logits(model_fatda(adv))\r\n","\r\n","  all_preds.extend(y_adv_pred)\r\n","  correct_total += torch.sum(torch.eq(y_adv_pred, y_batch)).item()\r\n","\r\n","print(f'Accuracy on the test set: {correct_total / len(testset):.3f}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy on the test set: 0.683\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UtyxFDXpoNsS","executionInfo":{"status":"ok","timestamp":1611859662227,"user_tz":-60,"elapsed":20808376,"user":{"displayName":"Thi Que-Lam Elisa Nguyen","photoUrl":"","userId":"14516834551380015257"}},"outputId":"b27d5bad-b1c5-43f7-df8f-b2e9c296cc82"},"source":["accuracy = correct_total / len(testset)\r\n","z = 1.96 #for 95% CI\r\n","n = len(all_preds)\r\n","\r\n","interval = z * np.sqrt( (accuracy * (1 - accuracy)) / n)\r\n","interval"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.009125013743491582"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"P8g6qU0W1P7u"},"source":["## Visualise results"]},{"cell_type":"code","metadata":{"id":"XDEt7CDjswjq"},"source":["y_true_int = [int(x.cpu()) for x in y_true]\r\n","y_pred_int = [int(x.cpu()) for x in all_preds]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"VrN3yMS5pzFY","executionInfo":{"status":"ok","timestamp":1611859662660,"user_tz":-60,"elapsed":20808772,"user":{"displayName":"Thi Que-Lam Elisa Nguyen","photoUrl":"","userId":"14516834551380015257"}},"outputId":"29a37307-1dfe-4eca-8fda-219ed1968371"},"source":["data = {'y_Actual':    y_true_int,\r\n","        'y_Predicted': y_pred_int\r\n","        }\r\n","cm_df = pd.DataFrame(data, columns=['y_Actual', 'y_Predicted'])\r\n","\r\n","cm_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>y_Actual</th>\n","      <th>y_Predicted</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   y_Actual  y_Predicted\n","0         4            2\n","1         2            2\n","2         2            2\n","3         2            2\n","4         5            5"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IYApaz82qOkF","executionInfo":{"status":"ok","timestamp":1611859662661,"user_tz":-60,"elapsed":20808755,"user":{"displayName":"Thi Que-Lam Elisa Nguyen","photoUrl":"","userId":"14516834551380015257"}},"outputId":"f314179a-4bb0-4ea5-d994-532e0d096db0"},"source":["confusion_matrix = pd.crosstab(cm_df['y_Actual'], cm_df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\r\n","print(confusion_matrix)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Predicted    0    1    2    3    4    5   6    7    8    9\n","Actual                                                    \n","0          765   15   55   62   15   27  35    4   15    3\n","1           24  880   15   68    4    1   2    1    2    0\n","2           45    5  593   12  270    3  26    1   42    3\n","3           89   80   41  674   78    9  19    1    9    0\n","4           20    5  343   58  541    5  16    0    9    0\n","5            0    1    0    2    0  782   2  163    9   40\n","6          268   13  314   44  256   15  36    0   54    0\n","7            0    4    0    0    0   94   0  826    0   76\n","8            7    1   48   11   12    9   2    7  899    2\n","9            2    0    0    0    0   49   0  108    1  837\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"id":"0bfPKtYNqQLo","executionInfo":{"status":"ok","timestamp":1611859662935,"user_tz":-60,"elapsed":20809016,"user":{"displayName":"Thi Que-Lam Elisa Nguyen","photoUrl":"","userId":"14516834551380015257"}},"outputId":"229cfc41-920e-418c-958d-7245d1511f2e"},"source":["sn.heatmap(confusion_matrix, annot=False)\r\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"PGmaMzr2tajb"},"source":[""],"execution_count":null,"outputs":[]}]}