{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"MAT_DA.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"ba29f2113693421589fd8fb525b2956d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_33353dfe82ce4c568ac82268464be716","IPY_MODEL_739906010c2e40f1ad06db7771341f21"],"layout":"IPY_MODEL_ee251dd909b74e87831460bc6555bdcd"}},"33353dfe82ce4c568ac82268464be716":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cbce17452d8d4ede9e59d6a1730e9657","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_be008917798a4761855c5c58a0e35ca2","value":1}},"739906010c2e40f1ad06db7771341f21":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_086bfcc00b5b46d9bf60f75713820fb5","placeholder":"​","style":"IPY_MODEL_b002a2639d93485da717ab89fd2673b2","value":" 26427392/? [00:05&lt;00:00, 4794402.14it/s]"}},"ee251dd909b74e87831460bc6555bdcd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbce17452d8d4ede9e59d6a1730e9657":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be008917798a4761855c5c58a0e35ca2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"086bfcc00b5b46d9bf60f75713820fb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b002a2639d93485da717ab89fd2673b2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"068e0bd894bd4c56a6839f6469861cbb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0fefe6fef8ff4411863d8327e831ac79","IPY_MODEL_1240d46136b140aabccc59acf33f2cc2"],"layout":"IPY_MODEL_52691e6ef25b4527a74b10ee2ed626dd"}},"0fefe6fef8ff4411863d8327e831ac79":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bed14944e8f14a609655859684091e04","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_16acdf7aeebb40f89522c08b1c9b4f82","value":1}},"1240d46136b140aabccc59acf33f2cc2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c7347c7a0d243a381ba5f36cc566a6c","placeholder":"​","style":"IPY_MODEL_cef16be513a841c18b685cb0a326d1ee","value":" 32768/? [00:01&lt;00:00, 24927.93it/s]"}},"52691e6ef25b4527a74b10ee2ed626dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bed14944e8f14a609655859684091e04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16acdf7aeebb40f89522c08b1c9b4f82":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"3c7347c7a0d243a381ba5f36cc566a6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cef16be513a841c18b685cb0a326d1ee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"72d13edab819487686f04c7aa8a2b168":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f5d5e016fba744f3a489aac0b6078a17","IPY_MODEL_6efee6c563ea4126b029716240473950"],"layout":"IPY_MODEL_d48749af601847e48fd2e0fbf6ab4de9"}},"f5d5e016fba744f3a489aac0b6078a17":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2fe1a0b9a07a49898357b7af1949d482","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ae6501cf0be643b2b274e125b0393fc3","value":1}},"6efee6c563ea4126b029716240473950":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b3dfa81a78f493e8cf45310c6694a1a","placeholder":"​","style":"IPY_MODEL_78337e3d0c354dcba2ffa8e997852d72","value":" 4423680/? [00:01&lt;00:00, 4366090.10it/s]"}},"d48749af601847e48fd2e0fbf6ab4de9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2fe1a0b9a07a49898357b7af1949d482":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae6501cf0be643b2b274e125b0393fc3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"8b3dfa81a78f493e8cf45310c6694a1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78337e3d0c354dcba2ffa8e997852d72":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5d2dfa3b3a0a4cada3309c83b64601cf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_50e45cf1a3f7416abc880b60214f82fa","IPY_MODEL_62412f06234545a38bf961559ddc33ba"],"layout":"IPY_MODEL_a60c769fa09a4713a25a6b0f2f708e58"}},"50e45cf1a3f7416abc880b60214f82fa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_39e76e9ff2f14c4085bafbf26e1f21c3","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d6c100a9d5ee419180647ed997239370","value":1}},"62412f06234545a38bf961559ddc33ba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_67c4e3f611774b2b92b2307e917c132c","placeholder":"​","style":"IPY_MODEL_b5f2c7abb12e462ba9d5501096153d72","value":" 8192/? [00:02&lt;00:00, 3711.51it/s]"}},"a60c769fa09a4713a25a6b0f2f708e58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39e76e9ff2f14c4085bafbf26e1f21c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6c100a9d5ee419180647ed997239370":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":"initial"}},"67c4e3f611774b2b92b2307e917c132c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5f2c7abb12e462ba9d5501096153d72":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"UiuP7Z3-bvGO"},"source":["# Setup"]},{"cell_type":"markdown","metadata":{"id":"zZBDFBRCv0Mo"},"source":["## Import libraries"]},{"cell_type":"code","metadata":{"id":"9rUAnl_Ma0xC"},"source":["import torch\r\n","import torch.nn as nn\r\n","import torch.nn.functional as F\r\n","import torch.optim as optim\r\n","import torchvision\r\n","from torchvision import transforms\r\n","from torchvision import datasets\r\n","from torch.utils.data import DataLoader\r\n","import random\r\n","random.seed(123)\r\n","\r\n","import time\r\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GBiHNZuWyEGM","executionInfo":{"elapsed":24229,"status":"ok","timestamp":1611782392170,"user":{"displayName":"Kevin Folkertsma","photoUrl":"","userId":"17677813951231302708"},"user_tz":-60},"outputId":"c1136fa1-7711-435d-d471-455aee0b2346"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KP9kn4LIwBZj"},"source":["## Check CUDA version"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CJeUYjy8bWfk","executionInfo":{"elapsed":24220,"status":"ok","timestamp":1611782392172,"user":{"displayName":"Kevin Folkertsma","photoUrl":"","userId":"17677813951231302708"},"user_tz":-60},"outputId":"ca690b78-ee05-4775-94d6-9a2b67308862"},"source":["\r\n","use_cuda = True\r\n","\r\n","if use_cuda and torch.cuda.is_available():\r\n","  device = torch.device('cuda')\r\n","else:\r\n","  device = torch.device('cpu')\r\n","\r\n","device"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"QYASDKf9wDo6"},"source":["## Visualisation functions"]},{"cell_type":"code","metadata":{"id":"DrRTDEo_bZu0"},"source":["\r\n","%matplotlib inline\r\n","\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","\r\n","# Function to show an image tensor\r\n","def show(X):\r\n","    if X.dim() == 3 and X.size(2) == 3:\r\n","        plt.imshow(X.numpy())\r\n","        #plt.show()\r\n","    elif X.dim() == 2:\r\n","        plt.imshow(   X.numpy() , cmap='gray'  )\r\n","        #plt.show()\r\n","    else:\r\n","        print('WRONG TENSOR SIZE')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lRwlpAu3wGs0"},"source":["## Download dataset"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":403,"referenced_widgets":["ba29f2113693421589fd8fb525b2956d","33353dfe82ce4c568ac82268464be716","739906010c2e40f1ad06db7771341f21","ee251dd909b74e87831460bc6555bdcd","cbce17452d8d4ede9e59d6a1730e9657","be008917798a4761855c5c58a0e35ca2","086bfcc00b5b46d9bf60f75713820fb5","b002a2639d93485da717ab89fd2673b2","068e0bd894bd4c56a6839f6469861cbb","0fefe6fef8ff4411863d8327e831ac79","1240d46136b140aabccc59acf33f2cc2","52691e6ef25b4527a74b10ee2ed626dd","bed14944e8f14a609655859684091e04","16acdf7aeebb40f89522c08b1c9b4f82","3c7347c7a0d243a381ba5f36cc566a6c","cef16be513a841c18b685cb0a326d1ee","72d13edab819487686f04c7aa8a2b168","f5d5e016fba744f3a489aac0b6078a17","6efee6c563ea4126b029716240473950","d48749af601847e48fd2e0fbf6ab4de9","2fe1a0b9a07a49898357b7af1949d482","ae6501cf0be643b2b274e125b0393fc3","8b3dfa81a78f493e8cf45310c6694a1a","78337e3d0c354dcba2ffa8e997852d72","5d2dfa3b3a0a4cada3309c83b64601cf","50e45cf1a3f7416abc880b60214f82fa","62412f06234545a38bf961559ddc33ba","a60c769fa09a4713a25a6b0f2f708e58","39e76e9ff2f14c4085bafbf26e1f21c3","d6c100a9d5ee419180647ed997239370","67c4e3f611774b2b92b2307e917c132c","b5f2c7abb12e462ba9d5501096153d72"]},"id":"cxOP14uSc_7E","executionInfo":{"elapsed":27846,"status":"ok","timestamp":1611782395803,"user":{"displayName":"Kevin Folkertsma","photoUrl":"","userId":"17677813951231302708"},"user_tz":-60},"outputId":"788b4d82-26ce-454b-ac5d-58eeb910f079"},"source":["transform = transforms.Compose([transforms.ToTensor(),\r\n","                                transforms.Lambda(lambda x: x.squeeze()),  # Squeeze the data to remove the redundant channel dimension\r\n","                                ])\r\n","\r\n","trainset = torchvision.datasets.FashionMNIST(root='./data_FashionMNIST',\r\n","                                      train=True,\r\n","                                      download=True,\r\n","                                      transform=transform\r\n","                                      )\r\n","\r\n","testset = torchvision.datasets.FashionMNIST(root='./data_FashionMNIST',\r\n","                                     train=False,\r\n","                                     download=True,\r\n","                                     transform=transform\r\n","                                     )\r\n","\r\n","classes = (\r\n","    'T-shirt/top',\r\n","    'Trouser',\r\n","    'Pullover',\r\n","    'Dress',\r\n","    'Coat',\r\n","    'Sandal',\r\n","    'Shirt',\r\n","    'Sneaker',\r\n","    'Bag',\r\n","    'Ankle boot',\r\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data_FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ba29f2113693421589fd8fb525b2956d","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ./data_FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data_FashionMNIST/FashionMNIST/raw\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data_FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"068e0bd894bd4c56a6839f6469861cbb","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ./data_FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data_FashionMNIST/FashionMNIST/raw\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data_FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"72d13edab819487686f04c7aa8a2b168","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ./data_FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data_FashionMNIST/FashionMNIST/raw\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data_FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n","\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5d2dfa3b3a0a4cada3309c83b64601cf","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Extracting ./data_FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data_FashionMNIST/FashionMNIST/raw\n","Processing...\n","Done!\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n","  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"kvQWmwEtwT2w"},"source":["# Data preprocessing"]},{"cell_type":"markdown","metadata":{"id":"06TvjxaMwWaZ"},"source":["## Augment data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LNNmJyX4uwh9","executionInfo":{"elapsed":42374,"status":"ok","timestamp":1611782410333,"user":{"displayName":"Kevin Folkertsma","photoUrl":"","userId":"17677813951231302708"},"user_tz":-60},"outputId":"c138d270-0428-4dd6-a6fc-bda1c373bdde"},"source":["train_hflip = transforms.functional.hflip(trainset.data)\r\n","\r\n","train_brightness = [transforms.functional.adjust_brightness(x, brightness_factor=random.choice([0.5, 0.75, 1.25, 1.5])) for x in trainset.data]\r\n","train_brightness = torch.stack(train_brightness)\r\n","\r\n","train_blur = transforms.functional.gaussian_blur(trainset.data, kernel_size=3)\r\n","\r\n","train_rotate = [transforms.functional.rotate(torch.unsqueeze(x, dim=0), angle=random.randrange(30,330,5)).squeeze() for x in trainset.data]\r\n","train_rotate = torch.stack(train_rotate)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"h63WXPxDw0iq"},"source":["## Split training data into train and validation set"]},{"cell_type":"code","metadata":{"id":"diuqdGuYu1_r"},"source":["trainset.data = torch.cat((trainset.data, train_hflip, train_brightness, train_blur, train_rotate),dim=0)\r\n","trainset.targets = torch.cat((trainset.targets, trainset.targets, trainset.targets, trainset.targets, trainset.targets))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bIc6MGQ_dES8"},"source":["from sklearn.model_selection import train_test_split\r\n","targets = trainset.targets\r\n","train_idx, val_idx= train_test_split(np.arange(len(targets)),test_size=0.2,shuffle=True, stratify=targets, random_state=123)\r\n","\r\n","train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\r\n","val_sampler = torch.utils.data.SubsetRandomSampler(val_idx)\r\n","\r\n","batch_size=128\r\n","\r\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=train_sampler)\r\n","valloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=val_sampler)\r\n","testloader = torch.utils.data.DataLoader(testset,\r\n","                                         batch_size=batch_size,\r\n","                                         shuffle=True,\r\n","                                         drop_last=True\r\n","                                         )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j8TjJ1Yzw6fa"},"source":["# Model architecture"]},{"cell_type":"markdown","metadata":{"id":"cx8qydhGw9lm"},"source":["## Create the model"]},{"cell_type":"code","metadata":{"id":"kEqjg3jobdBX"},"source":["class Net(nn.Module):\r\n","\r\n","    def __init__(self, kernel_size, pool_function, nfilters_conv1, nfilters_conv2):\r\n","\r\n","        super(Net, self).__init__()\r\n","        self.nfilters_conv2 = nfilters_conv2\r\n","\r\n","        # CL1:   1 x 28 x 28 (grayscale) -->    nfilters_conv1 x 28 x 28 \r\n","        self.conv1 = nn.Conv2d(1, nfilters_conv1,  kernel_size=kernel_size,  padding=kernel_size//2)\r\n","\r\n","        # MP1: nfilters_conv1 x 28 x 28  -->    nfilters_conv1 x 14 x 14\r\n","        self.pool1  = pool_function(2,2)\r\n","        \r\n","        # CL2:   nfilters_conv1 x 14 x 14  -->    nfilters_conv2 x 14 x 14\r\n","        self.conv2 = nn.Conv2d(nfilters_conv1,  nfilters_conv2,  kernel_size=kernel_size,  padding=kernel_size//2)\r\n","        \r\n","        # MP2:  nfilters_conv2 x 14 x 14 -->    nfilters_conv2 x 7 x 7\r\n","        self.pool2 = pool_function(2,2)\r\n","        \r\n","        # LL1:   nfilters_conv2 x 7 x 7 -->  100 \r\n","        self.linear1 = nn.Linear((nfilters_conv2*7*7), 100)\r\n","        \r\n","        # LL2:   100  -->  10 \r\n","        self.linear2 = nn.Linear(100,10)\r\n","\r\n","\r\n","    def forward(self, x):\r\n","        x = x.unsqueeze(1)\r\n","\r\n","        # CL1:   \r\n","        x = self.conv1(x)\r\n","        x = F.relu(x)\r\n","        \r\n","        # MP1: \r\n","        x = self.pool1(x)\r\n","        \r\n","        # CL2:   \r\n","        x = self.conv2(x)\r\n","        x = F.relu(x)\r\n","        \r\n","        # MP2: \r\n","        x = self.pool2(x)\r\n","\r\n","        # LL1:   \r\n","        x = x.view(-1, self.nfilters_conv2*7*7)\r\n","        x = self.linear1(x)\r\n","        x = F.relu(x)\r\n","        \r\n","        # LL2:  \r\n","        x = self.linear2(x)\r\n","    \r\n","        return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V_Be5wuG0D_N"},"source":["# best results from hyperparameter tuning\n","kernel_size= 5\n","pool_function = nn.AvgPool2d\n","nfilters_conv1 = 128\n","nfilters_conv2 = 128\n","\n","model_matda = Net(kernel_size=kernel_size,pool_function=pool_function,nfilters_conv1=nfilters_conv1,nfilters_conv2=nfilters_conv2).to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","my_lr=0.01\n","\n","optimizer=torch.optim.Adam(model_matda.parameters(), lr=my_lr) # change here"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kvbvwMpZbGuC"},"source":["# model = torch.load(\"/content/drive/MyDrive/Deep Learning/Project/model.pckl\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"A845uDmTrZBi"},"source":["# COPY\r\n","plot_valloss = []"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OFMuWfPbbLGS","executionInfo":{"elapsed":53131,"status":"ok","timestamp":1611782421115,"user":{"displayName":"Kevin Folkertsma","photoUrl":"","userId":"17677813951231302708"},"user_tz":-60},"outputId":"a4da4648-5f51-4d75-f734-8411ff91dbaa"},"source":["print(model_matda)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["LeNet(\n","  (conv1): Conv2d(1, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","  (conv2): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","  (pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","  (linear1): Linear(in_features=6272, out_features=100, bias=True)\n","  (linear2): Linear(in_features=100, out_features=10, bias=True)\n",")\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7TjdOEDdb36K"},"source":["# Attack!"]},{"cell_type":"markdown","metadata":{"id":"stRy0VJcxA57"},"source":["## Import libraries"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YLsi9F6Nbpqq","executionInfo":{"elapsed":58001,"status":"ok","timestamp":1611782425994,"user":{"displayName":"Kevin Folkertsma","photoUrl":"","userId":"17677813951231302708"},"user_tz":-60},"outputId":"0e1915df-d003-48ca-b6ca-93534ffa74e3"},"source":["!pip install advertorch"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting advertorch\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2f/b1/84602596294c32f49396bac9c36f1f72b00577bbcb26ebbe776e64791cac/advertorch-0.2.3.tar.gz (5.7MB)\n","\u001b[K     |████████████████████████████████| 5.7MB 13.9MB/s \n","\u001b[?25hBuilding wheels for collected packages: advertorch\n","  Building wheel for advertorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for advertorch: filename=advertorch-0.2.3-cp36-none-any.whl size=5696220 sha256=91d16caa5c376c0ffb71c1c692dbfeecee393677a921585ecccbc6c5f0c632c8\n","  Stored in directory: /root/.cache/pip/wheels/9b/53/6e/6b2509701b0da68443fa3d4499733f5455d6d583afa8c46676\n","Successfully built advertorch\n","Installing collected packages: advertorch\n","Successfully installed advertorch-0.2.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hNhbmqREb_ON"},"source":["from advertorch.attacks import PGDAttack"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LY-xJiSBxDFE"},"source":["## Create adversary"]},{"cell_type":"code","metadata":{"id":"w08vXgmfcE3g"},"source":["# prepare your pytorch model as \"model\"\r\n","# prepare a batch of data and label as \"cln_data\" and \"true_label\"\r\n","# prepare attack instance\r\n","\r\n","adversary = PGDAttack(\r\n","    model_matda, loss_fn=nn.CrossEntropyLoss(), eps=0.3,\r\n","    nb_iter=10, eps_iter=0.01, rand_init=True, clip_min=0.0, clip_max=1.0,\r\n","    targeted=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4xYZycVaxFcZ"},"source":["## Train the model"]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"UaYh5LW-zMIB","outputId":"84302d59-14e0-440c-fbb4-e73bd6217384"},"source":["start=time.time()\n","\n","min_loss = 20 #initial loss to be overwritten\n","\n","epochs_no_improve = 0\n","patience = 20 # high patience to overcome local minima\n","\n","for epoch in range(1,200):\n","\n","  model_matda.train()\n","  for i, (x_batch, y_batch) in enumerate(trainloader):\n","    x_batch, y_batch = x_batch.to(device), y_batch.to(device)  # Move the data to the device that is used\n","\n","    optimizer.zero_grad()  # Set all currenly stored gradients to zero \n","\n","    # randomly choose either perturbed data or clean data\n","    y_pred = model_matda(random.choice([adversary.perturb(x_batch, y_batch), x_batch]))\n","\n","    loss = criterion(y_pred, y_batch)\n","\n","    loss.backward()\n","\n","    optimizer.step()\n","\n","    # Compute relevant metrics\n","    \n","    y_pred_max = torch.argmax(y_pred, dim=1)  # Get the labels with highest output probability\n","\n","    correct = torch.sum(torch.eq(y_pred_max, y_batch)).item()  # Count how many are equal to the true labels\n","\n","    elapsed = time.time() - start  # Keep track of how much time has elapsed\n","\n","    # Show progress every 50 batches \n","    if not i % 50:\n","      print(f'epoch: {epoch}, time: {elapsed:.3f}s, loss: {loss.item():.3f}, train accuracy: {correct / batch_size:.3f}')\n","\n","  model_matda.eval()\n","  val_loss = 0\n","  counter = 0\n","  for i, (x_batch, y_batch) in enumerate(valloader):\n","    counter += 1\n","    x_batch, y_batch = x_batch.to(device), y_batch.to(device)  # Move the data to the device that is used\n","\n","    y_pred = model_matda(x_batch)\n","    val_loss += criterion(y_pred, y_batch).item()\n","\n","  val_loss = val_loss/counter\n","  print(f'epoch: {epoch}, validation loss: {val_loss}')\n","  plot_valloss.append([val_loss, epoch]) #COPY HERE\n","  # save the model\n","  if val_loss < min_loss:\n","    torch.save(model_matda, \"/content/drive/MyDrive/Deep Learning/Project/model_matda.pckl\")\n","    epochs_no_improve = 0\n","    min_loss = val_loss\n","  else:\n","    epochs_no_improve += 1\n","    if epochs_no_improve == patience and epoch > 5:\n","      print(\"Early Stopping!\")\n","      break\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["epoch: 1, time: 1.080s, loss: 2.307, train accuracy: 0.078\n","epoch: 1, time: 11.210s, loss: 1.062, train accuracy: 0.680\n","epoch: 1, time: 21.364s, loss: 1.721, train accuracy: 0.328\n","epoch: 1, time: 31.607s, loss: 1.469, train accuracy: 0.422\n","epoch: 1, time: 41.915s, loss: 1.450, train accuracy: 0.414\n","epoch: 1, time: 52.288s, loss: 0.641, train accuracy: 0.711\n","epoch: 1, time: 62.727s, loss: 0.734, train accuracy: 0.742\n","epoch: 1, time: 73.252s, loss: 1.346, train accuracy: 0.547\n","epoch: 1, time: 83.845s, loss: 1.538, train accuracy: 0.344\n","epoch: 1, time: 94.488s, loss: 0.459, train accuracy: 0.852\n","epoch: 1, time: 105.175s, loss: 1.253, train accuracy: 0.492\n","epoch: 1, time: 115.830s, loss: 0.581, train accuracy: 0.773\n","epoch: 1, time: 126.443s, loss: 1.401, train accuracy: 0.508\n","epoch: 1, time: 137.039s, loss: 0.756, train accuracy: 0.719\n","epoch: 1, time: 147.615s, loss: 0.572, train accuracy: 0.766\n","epoch: 1, time: 158.191s, loss: 0.555, train accuracy: 0.828\n","epoch: 1, time: 168.802s, loss: 1.405, train accuracy: 0.531\n","epoch: 1, time: 179.412s, loss: 1.374, train accuracy: 0.469\n","epoch: 1, time: 190.033s, loss: 0.440, train accuracy: 0.859\n","epoch: 1, time: 200.647s, loss: 1.380, train accuracy: 0.492\n","epoch: 1, time: 211.263s, loss: 1.263, train accuracy: 0.516\n","epoch: 1, time: 221.866s, loss: 1.012, train accuracy: 0.547\n","epoch: 1, time: 232.469s, loss: 0.461, train accuracy: 0.852\n","epoch: 1, time: 243.072s, loss: 1.341, train accuracy: 0.453\n","epoch: 1, time: 253.663s, loss: 0.521, train accuracy: 0.773\n","epoch: 1, time: 264.257s, loss: 0.581, train accuracy: 0.789\n","epoch: 1, time: 274.847s, loss: 1.246, train accuracy: 0.516\n","epoch: 1, time: 285.432s, loss: 0.466, train accuracy: 0.844\n","epoch: 1, time: 296.004s, loss: 0.515, train accuracy: 0.844\n","epoch: 1, time: 306.593s, loss: 1.499, train accuracy: 0.422\n","epoch: 1, time: 317.185s, loss: 0.620, train accuracy: 0.781\n","epoch: 1, time: 327.790s, loss: 1.374, train accuracy: 0.453\n","epoch: 1, time: 338.397s, loss: 1.313, train accuracy: 0.508\n","epoch: 1, time: 349.000s, loss: 0.630, train accuracy: 0.781\n","epoch: 1, time: 359.597s, loss: 0.498, train accuracy: 0.828\n","epoch: 1, time: 370.196s, loss: 0.583, train accuracy: 0.742\n","epoch: 1, time: 380.778s, loss: 0.413, train accuracy: 0.852\n","epoch: 1, time: 391.369s, loss: 0.559, train accuracy: 0.789\n","epoch: 1, validation loss: 0.545349524346496\n","epoch: 2, time: 406.068s, loss: 0.573, train accuracy: 0.758\n","epoch: 2, time: 416.615s, loss: 0.740, train accuracy: 0.766\n","epoch: 2, time: 427.204s, loss: 1.322, train accuracy: 0.453\n","epoch: 2, time: 437.822s, loss: 1.278, train accuracy: 0.516\n","epoch: 2, time: 448.441s, loss: 0.604, train accuracy: 0.773\n","epoch: 2, time: 459.034s, loss: 0.579, train accuracy: 0.789\n","epoch: 2, time: 469.623s, loss: 1.283, train accuracy: 0.500\n","epoch: 2, time: 480.189s, loss: 0.504, train accuracy: 0.781\n","epoch: 2, time: 490.748s, loss: 1.192, train accuracy: 0.523\n","epoch: 2, time: 501.320s, loss: 0.492, train accuracy: 0.805\n","epoch: 2, time: 511.890s, loss: 1.220, train accuracy: 0.500\n","epoch: 2, time: 522.465s, loss: 0.732, train accuracy: 0.742\n","epoch: 2, time: 533.040s, loss: 1.444, train accuracy: 0.445\n","epoch: 2, time: 543.660s, loss: 1.309, train accuracy: 0.500\n","epoch: 2, time: 554.267s, loss: 0.531, train accuracy: 0.820\n","epoch: 2, time: 564.875s, loss: 1.262, train accuracy: 0.547\n","epoch: 2, time: 575.489s, loss: 1.132, train accuracy: 0.617\n","epoch: 2, time: 586.068s, loss: 0.436, train accuracy: 0.852\n","epoch: 2, time: 596.629s, loss: 1.408, train accuracy: 0.453\n","epoch: 2, time: 607.184s, loss: 0.646, train accuracy: 0.734\n","epoch: 2, time: 617.743s, loss: 0.458, train accuracy: 0.852\n","epoch: 2, time: 628.295s, loss: 0.546, train accuracy: 0.789\n","epoch: 2, time: 638.849s, loss: 1.306, train accuracy: 0.484\n","epoch: 2, time: 649.401s, loss: 1.360, train accuracy: 0.484\n","epoch: 2, time: 659.952s, loss: 1.254, train accuracy: 0.484\n","epoch: 2, time: 670.502s, loss: 0.487, train accuracy: 0.805\n","epoch: 2, time: 681.062s, loss: 0.565, train accuracy: 0.766\n","epoch: 2, time: 691.634s, loss: 0.544, train accuracy: 0.789\n","epoch: 2, time: 702.194s, loss: 1.272, train accuracy: 0.516\n","epoch: 2, time: 712.747s, loss: 1.202, train accuracy: 0.508\n","epoch: 2, time: 723.291s, loss: 0.457, train accuracy: 0.820\n","epoch: 2, time: 733.842s, loss: 1.285, train accuracy: 0.492\n","epoch: 2, time: 744.390s, loss: 0.457, train accuracy: 0.828\n","epoch: 2, time: 754.927s, loss: 1.246, train accuracy: 0.539\n","epoch: 2, time: 765.478s, loss: 0.604, train accuracy: 0.781\n","epoch: 2, time: 776.013s, loss: 0.520, train accuracy: 0.859\n","epoch: 2, time: 786.566s, loss: 1.226, train accuracy: 0.523\n","epoch: 2, time: 797.099s, loss: 1.103, train accuracy: 0.578\n","epoch: 2, validation loss: 0.5249454680917613\n","epoch: 3, time: 809.979s, loss: 0.503, train accuracy: 0.812\n","epoch: 3, time: 820.512s, loss: 1.118, train accuracy: 0.531\n","epoch: 3, time: 831.063s, loss: 0.466, train accuracy: 0.867\n","epoch: 3, time: 841.642s, loss: 1.192, train accuracy: 0.492\n","epoch: 3, time: 852.217s, loss: 0.462, train accuracy: 0.844\n","epoch: 3, time: 862.785s, loss: 1.134, train accuracy: 0.562\n","epoch: 3, time: 873.354s, loss: 0.560, train accuracy: 0.828\n","epoch: 3, time: 883.917s, loss: 0.491, train accuracy: 0.820\n","epoch: 3, time: 894.479s, loss: 1.031, train accuracy: 0.586\n","epoch: 3, time: 905.026s, loss: 0.490, train accuracy: 0.836\n","epoch: 3, time: 915.585s, loss: 1.207, train accuracy: 0.523\n","epoch: 3, time: 926.138s, loss: 0.522, train accuracy: 0.781\n","epoch: 3, time: 936.687s, loss: 1.023, train accuracy: 0.594\n","epoch: 3, time: 947.239s, loss: 0.601, train accuracy: 0.781\n","epoch: 3, time: 957.781s, loss: 0.413, train accuracy: 0.812\n","epoch: 3, time: 968.330s, loss: 0.486, train accuracy: 0.844\n","epoch: 3, time: 978.885s, loss: 0.444, train accuracy: 0.828\n","epoch: 3, time: 989.428s, loss: 1.270, train accuracy: 0.484\n","epoch: 3, time: 999.970s, loss: 0.368, train accuracy: 0.852\n","epoch: 3, time: 1010.516s, loss: 1.137, train accuracy: 0.586\n","epoch: 3, time: 1021.051s, loss: 1.170, train accuracy: 0.562\n","epoch: 3, time: 1031.586s, loss: 1.423, train accuracy: 0.484\n","epoch: 3, time: 1042.114s, loss: 0.554, train accuracy: 0.828\n","epoch: 3, time: 1052.644s, loss: 0.333, train accuracy: 0.875\n","epoch: 3, time: 1063.178s, loss: 1.100, train accuracy: 0.539\n","epoch: 3, time: 1073.724s, loss: 0.440, train accuracy: 0.844\n","epoch: 3, time: 1084.283s, loss: 1.341, train accuracy: 0.469\n","epoch: 3, time: 1094.823s, loss: 0.485, train accuracy: 0.812\n","epoch: 3, time: 1105.363s, loss: 1.222, train accuracy: 0.523\n","epoch: 3, time: 1115.890s, loss: 1.087, train accuracy: 0.500\n","epoch: 3, time: 1126.405s, loss: 0.479, train accuracy: 0.836\n","epoch: 3, time: 1136.930s, loss: 1.245, train accuracy: 0.547\n","epoch: 3, time: 1147.455s, loss: 0.345, train accuracy: 0.852\n","epoch: 3, time: 1157.978s, loss: 1.151, train accuracy: 0.578\n","epoch: 3, time: 1168.507s, loss: 0.626, train accuracy: 0.766\n","epoch: 3, time: 1179.025s, loss: 1.131, train accuracy: 0.516\n","epoch: 3, time: 1189.540s, loss: 1.131, train accuracy: 0.523\n","epoch: 3, time: 1200.073s, loss: 1.013, train accuracy: 0.586\n","epoch: 3, validation loss: 0.48871745102441133\n","epoch: 4, time: 1212.957s, loss: 1.318, train accuracy: 0.570\n","epoch: 4, time: 1223.509s, loss: 0.557, train accuracy: 0.766\n","epoch: 4, time: 1234.063s, loss: 0.445, train accuracy: 0.836\n","epoch: 4, time: 1244.615s, loss: 1.390, train accuracy: 0.461\n","epoch: 4, time: 1255.148s, loss: 1.146, train accuracy: 0.547\n","epoch: 4, time: 1265.657s, loss: 0.639, train accuracy: 0.734\n","epoch: 4, time: 1276.167s, loss: 1.152, train accuracy: 0.477\n","epoch: 4, time: 1286.690s, loss: 1.251, train accuracy: 0.461\n","epoch: 4, time: 1297.224s, loss: 0.525, train accuracy: 0.789\n","epoch: 4, time: 1307.758s, loss: 0.343, train accuracy: 0.867\n","epoch: 4, time: 1318.294s, loss: 0.473, train accuracy: 0.844\n","epoch: 4, time: 1328.840s, loss: 0.591, train accuracy: 0.766\n","epoch: 4, time: 1339.383s, loss: 0.444, train accuracy: 0.828\n","epoch: 4, time: 1349.927s, loss: 0.509, train accuracy: 0.789\n","epoch: 4, time: 1360.472s, loss: 0.494, train accuracy: 0.828\n","epoch: 4, time: 1371.023s, loss: 0.545, train accuracy: 0.828\n","epoch: 4, time: 1381.577s, loss: 1.234, train accuracy: 0.516\n","epoch: 4, time: 1392.121s, loss: 0.652, train accuracy: 0.766\n","epoch: 4, time: 1402.650s, loss: 0.352, train accuracy: 0.836\n","epoch: 4, time: 1413.194s, loss: 0.513, train accuracy: 0.789\n","epoch: 4, time: 1423.724s, loss: 1.181, train accuracy: 0.500\n","epoch: 4, time: 1434.259s, loss: 0.555, train accuracy: 0.773\n","epoch: 4, time: 1444.789s, loss: 1.187, train accuracy: 0.492\n","epoch: 4, time: 1455.327s, loss: 1.092, train accuracy: 0.555\n","epoch: 4, time: 1465.864s, loss: 1.102, train accuracy: 0.547\n","epoch: 4, time: 1476.403s, loss: 0.566, train accuracy: 0.773\n","epoch: 4, time: 1486.946s, loss: 1.295, train accuracy: 0.570\n","epoch: 4, time: 1497.482s, loss: 0.390, train accuracy: 0.844\n","epoch: 4, time: 1508.012s, loss: 0.441, train accuracy: 0.844\n","epoch: 4, time: 1518.536s, loss: 0.512, train accuracy: 0.773\n","epoch: 4, time: 1529.059s, loss: 0.509, train accuracy: 0.812\n","epoch: 4, time: 1539.601s, loss: 1.172, train accuracy: 0.531\n","epoch: 4, time: 1550.137s, loss: 1.150, train accuracy: 0.578\n","epoch: 4, time: 1560.669s, loss: 0.511, train accuracy: 0.812\n","epoch: 4, time: 1571.194s, loss: 0.984, train accuracy: 0.641\n","epoch: 4, time: 1581.722s, loss: 1.234, train accuracy: 0.500\n","epoch: 4, time: 1592.245s, loss: 0.470, train accuracy: 0.820\n","epoch: 4, time: 1602.766s, loss: 1.553, train accuracy: 0.383\n","epoch: 4, validation loss: 0.5150291472355694\n","epoch: 5, time: 1615.627s, loss: 0.479, train accuracy: 0.820\n","epoch: 5, time: 1626.123s, loss: 0.513, train accuracy: 0.812\n","epoch: 5, time: 1636.654s, loss: 1.341, train accuracy: 0.539\n","epoch: 5, time: 1647.204s, loss: 0.455, train accuracy: 0.820\n","epoch: 5, time: 1657.758s, loss: 0.374, train accuracy: 0.836\n","epoch: 5, time: 1668.286s, loss: 1.143, train accuracy: 0.578\n","epoch: 5, time: 1678.819s, loss: 1.214, train accuracy: 0.523\n","epoch: 5, time: 1689.339s, loss: 1.270, train accuracy: 0.539\n","epoch: 5, time: 1699.868s, loss: 0.434, train accuracy: 0.828\n","epoch: 5, time: 1710.373s, loss: 0.357, train accuracy: 0.852\n","epoch: 5, time: 1720.897s, loss: 0.440, train accuracy: 0.859\n","epoch: 5, time: 1731.420s, loss: 1.343, train accuracy: 0.508\n","epoch: 5, time: 1741.940s, loss: 1.344, train accuracy: 0.539\n","epoch: 5, time: 1752.464s, loss: 0.511, train accuracy: 0.812\n","epoch: 5, time: 1762.981s, loss: 0.384, train accuracy: 0.844\n","epoch: 5, time: 1773.512s, loss: 0.478, train accuracy: 0.828\n","epoch: 5, time: 1784.033s, loss: 0.572, train accuracy: 0.773\n","epoch: 5, time: 1794.564s, loss: 1.400, train accuracy: 0.414\n","epoch: 5, time: 1805.079s, loss: 1.285, train accuracy: 0.562\n","epoch: 5, time: 1815.589s, loss: 0.438, train accuracy: 0.852\n","epoch: 5, time: 1826.110s, loss: 1.294, train accuracy: 0.484\n","epoch: 5, time: 1836.614s, loss: 0.475, train accuracy: 0.812\n","epoch: 5, time: 1847.134s, loss: 1.180, train accuracy: 0.547\n","epoch: 5, time: 1857.650s, loss: 1.082, train accuracy: 0.578\n","epoch: 5, time: 1868.171s, loss: 0.448, train accuracy: 0.867\n","epoch: 5, time: 1878.684s, loss: 0.637, train accuracy: 0.781\n","epoch: 5, time: 1889.206s, loss: 0.466, train accuracy: 0.852\n","epoch: 5, time: 1899.731s, loss: 1.296, train accuracy: 0.516\n","epoch: 5, time: 1910.257s, loss: 0.596, train accuracy: 0.820\n","epoch: 5, time: 1920.781s, loss: 0.986, train accuracy: 0.633\n","epoch: 5, time: 1931.306s, loss: 0.470, train accuracy: 0.812\n","epoch: 5, time: 1941.838s, loss: 1.209, train accuracy: 0.531\n","epoch: 5, time: 1952.362s, loss: 1.053, train accuracy: 0.570\n","epoch: 5, time: 1962.886s, loss: 0.550, train accuracy: 0.812\n","epoch: 5, time: 1973.414s, loss: 0.394, train accuracy: 0.852\n","epoch: 5, time: 1983.945s, loss: 1.210, train accuracy: 0.500\n","epoch: 5, time: 1994.480s, loss: 1.236, train accuracy: 0.547\n","epoch: 5, time: 2005.025s, loss: 0.541, train accuracy: 0.766\n","epoch: 5, validation loss: 0.476606734589473\n","epoch: 6, time: 2017.809s, loss: 1.133, train accuracy: 0.516\n","epoch: 6, time: 2028.316s, loss: 0.567, train accuracy: 0.805\n","epoch: 6, time: 2038.833s, loss: 1.074, train accuracy: 0.586\n","epoch: 6, time: 2049.353s, loss: 0.458, train accuracy: 0.812\n","epoch: 6, time: 2059.868s, loss: 1.175, train accuracy: 0.539\n","epoch: 6, time: 2070.386s, loss: 1.255, train accuracy: 0.508\n","epoch: 6, time: 2080.911s, loss: 0.599, train accuracy: 0.773\n","epoch: 6, time: 2091.447s, loss: 0.479, train accuracy: 0.773\n","epoch: 6, time: 2101.987s, loss: 0.432, train accuracy: 0.805\n","epoch: 6, time: 2112.534s, loss: 1.374, train accuracy: 0.453\n","epoch: 6, time: 2123.068s, loss: 1.171, train accuracy: 0.562\n","epoch: 6, time: 2133.600s, loss: 0.467, train accuracy: 0.805\n","epoch: 6, time: 2144.131s, loss: 1.268, train accuracy: 0.469\n","epoch: 6, time: 2154.651s, loss: 0.483, train accuracy: 0.797\n","epoch: 6, time: 2165.178s, loss: 1.024, train accuracy: 0.578\n","epoch: 6, time: 2175.710s, loss: 0.378, train accuracy: 0.883\n","epoch: 6, time: 2186.238s, loss: 1.211, train accuracy: 0.594\n","epoch: 6, time: 2196.774s, loss: 0.454, train accuracy: 0.781\n","epoch: 6, time: 2207.307s, loss: 1.318, train accuracy: 0.516\n","epoch: 6, time: 2217.843s, loss: 1.193, train accuracy: 0.500\n","epoch: 6, time: 2228.375s, loss: 0.424, train accuracy: 0.828\n","epoch: 6, time: 2238.902s, loss: 1.110, train accuracy: 0.555\n","epoch: 6, time: 2249.419s, loss: 0.584, train accuracy: 0.750\n","epoch: 6, time: 2259.948s, loss: 1.388, train accuracy: 0.438\n","epoch: 6, time: 2270.472s, loss: 0.503, train accuracy: 0.820\n","epoch: 6, time: 2280.984s, loss: 1.313, train accuracy: 0.445\n","epoch: 6, time: 2291.498s, loss: 0.538, train accuracy: 0.742\n","epoch: 6, time: 2302.007s, loss: 1.259, train accuracy: 0.609\n","epoch: 6, time: 2312.519s, loss: 1.257, train accuracy: 0.555\n","epoch: 6, time: 2323.038s, loss: 1.202, train accuracy: 0.492\n","epoch: 6, time: 2333.557s, loss: 0.386, train accuracy: 0.852\n","epoch: 6, time: 2344.090s, loss: 1.322, train accuracy: 0.484\n","epoch: 6, time: 2354.619s, loss: 0.440, train accuracy: 0.836\n","epoch: 6, time: 2365.158s, loss: 1.129, train accuracy: 0.539\n","epoch: 6, time: 2375.706s, loss: 0.447, train accuracy: 0.828\n","epoch: 6, time: 2386.251s, loss: 1.258, train accuracy: 0.461\n","epoch: 6, time: 2396.797s, loss: 0.414, train accuracy: 0.883\n","epoch: 6, time: 2407.344s, loss: 1.474, train accuracy: 0.469\n","epoch: 6, validation loss: 0.47659739311824223\n","epoch: 7, time: 2420.211s, loss: 0.483, train accuracy: 0.812\n","epoch: 7, time: 2430.725s, loss: 1.081, train accuracy: 0.586\n","epoch: 7, time: 2441.245s, loss: 1.017, train accuracy: 0.617\n","epoch: 7, time: 2451.772s, loss: 1.046, train accuracy: 0.555\n","epoch: 7, time: 2462.319s, loss: 1.359, train accuracy: 0.508\n","epoch: 7, time: 2472.851s, loss: 1.043, train accuracy: 0.617\n","epoch: 7, time: 2483.385s, loss: 1.121, train accuracy: 0.539\n","epoch: 7, time: 2493.934s, loss: 1.119, train accuracy: 0.578\n","epoch: 7, time: 2504.465s, loss: 0.526, train accuracy: 0.805\n","epoch: 7, time: 2515.001s, loss: 1.430, train accuracy: 0.430\n","epoch: 7, time: 2525.530s, loss: 1.267, train accuracy: 0.500\n","epoch: 7, time: 2536.048s, loss: 1.151, train accuracy: 0.562\n","epoch: 7, time: 2546.569s, loss: 1.153, train accuracy: 0.562\n","epoch: 7, time: 2557.087s, loss: 1.165, train accuracy: 0.531\n","epoch: 7, time: 2567.593s, loss: 0.498, train accuracy: 0.797\n","epoch: 7, time: 2578.109s, loss: 1.293, train accuracy: 0.508\n","epoch: 7, time: 2588.624s, loss: 0.547, train accuracy: 0.766\n","epoch: 7, time: 2599.144s, loss: 1.345, train accuracy: 0.555\n","epoch: 7, time: 2609.677s, loss: 1.166, train accuracy: 0.531\n","epoch: 7, time: 2620.211s, loss: 1.252, train accuracy: 0.539\n","epoch: 7, time: 2630.751s, loss: 0.475, train accuracy: 0.812\n","epoch: 7, time: 2641.282s, loss: 1.217, train accuracy: 0.492\n","epoch: 7, time: 2651.830s, loss: 1.278, train accuracy: 0.555\n","epoch: 7, time: 2662.364s, loss: 1.105, train accuracy: 0.570\n","epoch: 7, time: 2672.896s, loss: 1.174, train accuracy: 0.547\n","epoch: 7, time: 2683.432s, loss: 0.479, train accuracy: 0.844\n","epoch: 7, time: 2693.945s, loss: 0.339, train accuracy: 0.875\n","epoch: 7, time: 2704.474s, loss: 1.204, train accuracy: 0.469\n","epoch: 7, time: 2714.993s, loss: 0.451, train accuracy: 0.812\n","epoch: 7, time: 2725.518s, loss: 1.253, train accuracy: 0.562\n","epoch: 7, time: 2736.058s, loss: 0.428, train accuracy: 0.828\n","epoch: 7, time: 2746.578s, loss: 1.298, train accuracy: 0.477\n","epoch: 7, time: 2757.113s, loss: 0.312, train accuracy: 0.891\n","epoch: 7, time: 2767.652s, loss: 0.545, train accuracy: 0.820\n","epoch: 7, time: 2778.180s, loss: 0.416, train accuracy: 0.867\n","epoch: 7, time: 2788.683s, loss: 0.416, train accuracy: 0.820\n","epoch: 7, time: 2799.174s, loss: 1.233, train accuracy: 0.555\n","epoch: 7, time: 2809.685s, loss: 0.562, train accuracy: 0.797\n","epoch: 7, validation loss: 0.4626345515632426\n","epoch: 8, time: 2822.408s, loss: 0.446, train accuracy: 0.828\n","epoch: 8, time: 2832.919s, loss: 1.203, train accuracy: 0.531\n","epoch: 8, time: 2843.455s, loss: 0.439, train accuracy: 0.836\n","epoch: 8, time: 2853.985s, loss: 1.125, train accuracy: 0.578\n","epoch: 8, time: 2864.513s, loss: 1.229, train accuracy: 0.562\n","epoch: 8, time: 2875.034s, loss: 0.571, train accuracy: 0.797\n","epoch: 8, time: 2885.535s, loss: 0.469, train accuracy: 0.805\n","epoch: 8, time: 2896.036s, loss: 0.564, train accuracy: 0.758\n","epoch: 8, time: 2906.554s, loss: 1.095, train accuracy: 0.570\n","epoch: 8, time: 2917.069s, loss: 0.384, train accuracy: 0.836\n","epoch: 8, time: 2927.588s, loss: 1.343, train accuracy: 0.477\n","epoch: 8, time: 2938.112s, loss: 1.235, train accuracy: 0.555\n","epoch: 8, time: 2948.626s, loss: 1.121, train accuracy: 0.523\n","epoch: 8, time: 2959.145s, loss: 0.357, train accuracy: 0.852\n","epoch: 8, time: 2969.679s, loss: 1.333, train accuracy: 0.500\n","epoch: 8, time: 2980.199s, loss: 1.164, train accuracy: 0.508\n","epoch: 8, time: 2990.730s, loss: 1.246, train accuracy: 0.500\n","epoch: 8, time: 3001.265s, loss: 0.457, train accuracy: 0.828\n","epoch: 8, time: 3011.790s, loss: 1.003, train accuracy: 0.641\n","epoch: 8, time: 3022.313s, loss: 1.087, train accuracy: 0.586\n","epoch: 8, time: 3032.846s, loss: 1.152, train accuracy: 0.539\n","epoch: 8, time: 3043.377s, loss: 0.396, train accuracy: 0.812\n","epoch: 8, time: 3053.901s, loss: 0.509, train accuracy: 0.812\n","epoch: 8, time: 3064.422s, loss: 0.359, train accuracy: 0.883\n","epoch: 8, time: 3074.950s, loss: 0.397, train accuracy: 0.836\n","epoch: 8, time: 3085.471s, loss: 1.270, train accuracy: 0.539\n","epoch: 8, time: 3095.999s, loss: 0.542, train accuracy: 0.820\n","epoch: 8, time: 3106.506s, loss: 0.454, train accuracy: 0.844\n","epoch: 8, time: 3117.028s, loss: 0.538, train accuracy: 0.797\n","epoch: 8, time: 3127.545s, loss: 0.559, train accuracy: 0.758\n","epoch: 8, time: 3138.058s, loss: 1.350, train accuracy: 0.508\n","epoch: 8, time: 3148.575s, loss: 1.494, train accuracy: 0.492\n","epoch: 8, time: 3159.081s, loss: 1.110, train accuracy: 0.516\n","epoch: 8, time: 3169.589s, loss: 1.207, train accuracy: 0.500\n","epoch: 8, time: 3180.105s, loss: 0.402, train accuracy: 0.805\n","epoch: 8, time: 3190.623s, loss: 0.463, train accuracy: 0.797\n","epoch: 8, time: 3201.137s, loss: 1.257, train accuracy: 0.539\n","epoch: 8, time: 3211.648s, loss: 1.326, train accuracy: 0.469\n","epoch: 8, validation loss: 0.4433440107907822\n","epoch: 9, time: 3224.367s, loss: 1.155, train accuracy: 0.523\n","epoch: 9, time: 3234.867s, loss: 0.418, train accuracy: 0.852\n","epoch: 9, time: 3245.388s, loss: 1.194, train accuracy: 0.539\n","epoch: 9, time: 3255.911s, loss: 1.222, train accuracy: 0.531\n","epoch: 9, time: 3266.440s, loss: 0.992, train accuracy: 0.570\n","epoch: 9, time: 3276.968s, loss: 1.339, train accuracy: 0.516\n","epoch: 9, time: 3287.486s, loss: 0.987, train accuracy: 0.602\n","epoch: 9, time: 3298.007s, loss: 0.446, train accuracy: 0.836\n","epoch: 9, time: 3308.527s, loss: 0.381, train accuracy: 0.820\n","epoch: 9, time: 3319.034s, loss: 0.474, train accuracy: 0.805\n","epoch: 9, time: 3329.537s, loss: 1.157, train accuracy: 0.594\n","epoch: 9, time: 3340.044s, loss: 0.472, train accuracy: 0.828\n","epoch: 9, time: 3350.573s, loss: 1.436, train accuracy: 0.461\n","epoch: 9, time: 3361.096s, loss: 1.268, train accuracy: 0.539\n","epoch: 9, time: 3371.616s, loss: 1.557, train accuracy: 0.461\n","epoch: 9, time: 3382.156s, loss: 0.423, train accuracy: 0.875\n","epoch: 9, time: 3392.697s, loss: 1.061, train accuracy: 0.570\n","epoch: 9, time: 3403.226s, loss: 1.141, train accuracy: 0.539\n","epoch: 9, time: 3413.763s, loss: 0.435, train accuracy: 0.820\n","epoch: 9, time: 3424.275s, loss: 1.321, train accuracy: 0.523\n","epoch: 9, time: 3434.805s, loss: 0.424, train accuracy: 0.828\n","epoch: 9, time: 3445.337s, loss: 1.069, train accuracy: 0.570\n","epoch: 9, time: 3455.857s, loss: 0.385, train accuracy: 0.836\n","epoch: 9, time: 3466.385s, loss: 1.115, train accuracy: 0.570\n","epoch: 9, time: 3476.908s, loss: 0.342, train accuracy: 0.867\n","epoch: 9, time: 3487.420s, loss: 0.440, train accuracy: 0.828\n","epoch: 9, time: 3497.943s, loss: 1.120, train accuracy: 0.562\n","epoch: 9, time: 3508.465s, loss: 0.526, train accuracy: 0.781\n","epoch: 9, time: 3518.976s, loss: 0.406, train accuracy: 0.828\n","epoch: 9, time: 3529.489s, loss: 0.399, train accuracy: 0.844\n","epoch: 9, time: 3540.009s, loss: 1.144, train accuracy: 0.562\n","epoch: 9, time: 3550.522s, loss: 1.336, train accuracy: 0.461\n","epoch: 9, time: 3561.036s, loss: 1.108, train accuracy: 0.523\n","epoch: 9, time: 3571.555s, loss: 0.513, train accuracy: 0.805\n","epoch: 9, time: 3582.053s, loss: 0.475, train accuracy: 0.828\n","epoch: 9, time: 3592.558s, loss: 0.489, train accuracy: 0.828\n","epoch: 9, time: 3603.060s, loss: 1.185, train accuracy: 0.539\n","epoch: 9, time: 3613.559s, loss: 0.343, train accuracy: 0.898\n","epoch: 9, validation loss: 0.4514259930485601\n","epoch: 10, time: 3626.266s, loss: 0.412, train accuracy: 0.828\n","epoch: 10, time: 3636.770s, loss: 0.428, train accuracy: 0.836\n","epoch: 10, time: 3647.288s, loss: 1.145, train accuracy: 0.562\n","epoch: 10, time: 3657.830s, loss: 1.238, train accuracy: 0.570\n","epoch: 10, time: 3668.353s, loss: 1.336, train accuracy: 0.484\n","epoch: 10, time: 3678.869s, loss: 1.111, train accuracy: 0.492\n","epoch: 10, time: 3689.383s, loss: 1.190, train accuracy: 0.539\n","epoch: 10, time: 3699.879s, loss: 1.111, train accuracy: 0.539\n","epoch: 10, time: 3710.386s, loss: 1.112, train accuracy: 0.555\n","epoch: 10, time: 3720.878s, loss: 0.500, train accuracy: 0.820\n","epoch: 10, time: 3731.375s, loss: 1.259, train accuracy: 0.461\n","epoch: 10, time: 3741.867s, loss: 0.611, train accuracy: 0.781\n","epoch: 10, time: 3752.375s, loss: 0.444, train accuracy: 0.828\n","epoch: 10, time: 3762.879s, loss: 0.622, train accuracy: 0.750\n","epoch: 10, time: 3773.393s, loss: 0.399, train accuracy: 0.883\n","epoch: 10, time: 3783.918s, loss: 1.047, train accuracy: 0.539\n","epoch: 10, time: 3794.437s, loss: 0.365, train accuracy: 0.844\n","epoch: 10, time: 3804.955s, loss: 0.454, train accuracy: 0.820\n","epoch: 10, time: 3815.480s, loss: 1.096, train accuracy: 0.648\n","epoch: 10, time: 3826.006s, loss: 1.051, train accuracy: 0.594\n","epoch: 10, time: 3836.535s, loss: 1.336, train accuracy: 0.477\n","epoch: 10, time: 3847.063s, loss: 1.245, train accuracy: 0.523\n","epoch: 10, time: 3857.583s, loss: 0.523, train accuracy: 0.781\n","epoch: 10, time: 3868.098s, loss: 0.487, train accuracy: 0.828\n","epoch: 10, time: 3878.620s, loss: 1.537, train accuracy: 0.453\n","epoch: 10, time: 3889.136s, loss: 0.431, train accuracy: 0.812\n","epoch: 10, time: 3899.656s, loss: 1.294, train accuracy: 0.492\n","epoch: 10, time: 3910.166s, loss: 0.451, train accuracy: 0.828\n","epoch: 10, time: 3920.667s, loss: 1.161, train accuracy: 0.523\n","epoch: 10, time: 3931.170s, loss: 0.490, train accuracy: 0.797\n","epoch: 10, time: 3941.679s, loss: 0.423, train accuracy: 0.867\n","epoch: 10, time: 3952.195s, loss: 1.194, train accuracy: 0.578\n","epoch: 10, time: 3962.706s, loss: 0.382, train accuracy: 0.867\n","epoch: 10, time: 3973.218s, loss: 0.502, train accuracy: 0.836\n","epoch: 10, time: 3983.737s, loss: 0.471, train accuracy: 0.828\n","epoch: 10, time: 3994.247s, loss: 1.252, train accuracy: 0.523\n","epoch: 10, time: 4004.776s, loss: 1.124, train accuracy: 0.562\n","epoch: 10, time: 4015.286s, loss: 0.375, train accuracy: 0.852\n","epoch: 10, validation loss: 0.4777448209109845\n","epoch: 11, time: 4028.021s, loss: 0.645, train accuracy: 0.766\n","epoch: 11, time: 4038.533s, loss: 0.432, train accuracy: 0.836\n","epoch: 11, time: 4049.044s, loss: 0.480, train accuracy: 0.812\n","epoch: 11, time: 4059.575s, loss: 1.398, train accuracy: 0.469\n","epoch: 11, time: 4070.104s, loss: 0.976, train accuracy: 0.578\n","epoch: 11, time: 4080.627s, loss: 0.476, train accuracy: 0.797\n","epoch: 11, time: 4091.135s, loss: 0.383, train accuracy: 0.828\n","epoch: 11, time: 4101.650s, loss: 1.068, train accuracy: 0.562\n","epoch: 11, time: 4112.166s, loss: 1.210, train accuracy: 0.531\n","epoch: 11, time: 4122.671s, loss: 1.285, train accuracy: 0.523\n","epoch: 11, time: 4133.179s, loss: 1.150, train accuracy: 0.531\n","epoch: 11, time: 4143.693s, loss: 0.514, train accuracy: 0.797\n","epoch: 11, time: 4154.201s, loss: 1.021, train accuracy: 0.625\n","epoch: 11, time: 4164.728s, loss: 1.102, train accuracy: 0.523\n","epoch: 11, time: 4175.244s, loss: 1.245, train accuracy: 0.523\n","epoch: 11, time: 4185.752s, loss: 1.135, train accuracy: 0.539\n","epoch: 11, time: 4196.268s, loss: 1.068, train accuracy: 0.570\n","epoch: 11, time: 4206.787s, loss: 0.366, train accuracy: 0.867\n","epoch: 11, time: 4217.298s, loss: 1.286, train accuracy: 0.477\n","epoch: 11, time: 4227.811s, loss: 0.379, train accuracy: 0.828\n","epoch: 11, time: 4238.323s, loss: 1.026, train accuracy: 0.547\n","epoch: 11, time: 4248.837s, loss: 0.526, train accuracy: 0.766\n","epoch: 11, time: 4259.353s, loss: 0.295, train accuracy: 0.883\n","epoch: 11, time: 4269.869s, loss: 1.135, train accuracy: 0.570\n","epoch: 11, time: 4280.389s, loss: 0.437, train accuracy: 0.852\n","epoch: 11, time: 4290.909s, loss: 1.197, train accuracy: 0.578\n","epoch: 11, time: 4301.425s, loss: 1.296, train accuracy: 0.492\n","epoch: 11, time: 4311.939s, loss: 0.490, train accuracy: 0.812\n","epoch: 11, time: 4322.460s, loss: 0.389, train accuracy: 0.828\n","epoch: 11, time: 4332.985s, loss: 1.197, train accuracy: 0.547\n","epoch: 11, time: 4343.524s, loss: 1.245, train accuracy: 0.484\n","epoch: 11, time: 4354.043s, loss: 1.260, train accuracy: 0.477\n","epoch: 11, time: 4364.565s, loss: 0.969, train accuracy: 0.570\n","epoch: 11, time: 4375.092s, loss: 1.035, train accuracy: 0.594\n","epoch: 11, time: 4385.615s, loss: 1.187, train accuracy: 0.602\n","epoch: 11, time: 4396.132s, loss: 0.506, train accuracy: 0.789\n","epoch: 11, time: 4406.663s, loss: 0.390, train accuracy: 0.828\n","epoch: 11, time: 4417.176s, loss: 0.477, train accuracy: 0.812\n","epoch: 11, validation loss: 0.4542912372520992\n","epoch: 12, time: 4429.831s, loss: 1.214, train accuracy: 0.531\n","epoch: 12, time: 4440.344s, loss: 0.380, train accuracy: 0.852\n","epoch: 12, time: 4450.849s, loss: 0.369, train accuracy: 0.836\n","epoch: 12, time: 4461.362s, loss: 0.589, train accuracy: 0.773\n","epoch: 12, time: 4471.869s, loss: 0.335, train accuracy: 0.859\n","epoch: 12, time: 4482.386s, loss: 0.385, train accuracy: 0.852\n","epoch: 12, time: 4492.892s, loss: 1.105, train accuracy: 0.531\n","epoch: 12, time: 4503.411s, loss: 1.117, train accuracy: 0.609\n","epoch: 12, time: 4513.932s, loss: 1.293, train accuracy: 0.516\n","epoch: 12, time: 4524.453s, loss: 1.249, train accuracy: 0.477\n","epoch: 12, time: 4534.974s, loss: 1.409, train accuracy: 0.445\n","epoch: 12, time: 4545.518s, loss: 0.380, train accuracy: 0.875\n","epoch: 12, time: 4556.056s, loss: 1.237, train accuracy: 0.516\n","epoch: 12, time: 4566.590s, loss: 0.504, train accuracy: 0.852\n","epoch: 12, time: 4577.120s, loss: 1.049, train accuracy: 0.562\n","epoch: 12, time: 4587.659s, loss: 1.287, train accuracy: 0.562\n","epoch: 12, time: 4598.214s, loss: 1.059, train accuracy: 0.586\n","epoch: 12, time: 4608.775s, loss: 0.396, train accuracy: 0.828\n","epoch: 12, time: 4619.314s, loss: 1.228, train accuracy: 0.547\n","epoch: 12, time: 4629.845s, loss: 1.159, train accuracy: 0.555\n","epoch: 12, time: 4640.371s, loss: 1.063, train accuracy: 0.625\n","epoch: 12, time: 4650.882s, loss: 0.456, train accuracy: 0.852\n","epoch: 12, time: 4661.397s, loss: 1.381, train accuracy: 0.484\n","epoch: 12, time: 4671.921s, loss: 1.170, train accuracy: 0.539\n","epoch: 12, time: 4682.446s, loss: 0.395, train accuracy: 0.844\n","epoch: 12, time: 4692.968s, loss: 1.268, train accuracy: 0.484\n","epoch: 12, time: 4703.492s, loss: 0.406, train accuracy: 0.867\n","epoch: 12, time: 4714.026s, loss: 1.270, train accuracy: 0.547\n","epoch: 12, time: 4724.559s, loss: 1.361, train accuracy: 0.469\n","epoch: 12, time: 4735.082s, loss: 1.122, train accuracy: 0.586\n","epoch: 12, time: 4745.625s, loss: 1.366, train accuracy: 0.453\n","epoch: 12, time: 4756.166s, loss: 1.320, train accuracy: 0.492\n","epoch: 12, time: 4766.710s, loss: 0.423, train accuracy: 0.875\n","epoch: 12, time: 4777.247s, loss: 0.492, train accuracy: 0.828\n","epoch: 12, time: 4787.790s, loss: 0.463, train accuracy: 0.805\n","epoch: 12, time: 4798.325s, loss: 0.317, train accuracy: 0.844\n","epoch: 12, time: 4808.876s, loss: 0.375, train accuracy: 0.859\n","epoch: 12, time: 4819.417s, loss: 0.371, train accuracy: 0.844\n","epoch: 12, validation loss: 0.45891947596312077\n","epoch: 13, time: 4832.144s, loss: 0.388, train accuracy: 0.852\n","epoch: 13, time: 4842.672s, loss: 0.435, train accuracy: 0.805\n","epoch: 13, time: 4853.200s, loss: 0.430, train accuracy: 0.812\n","epoch: 13, time: 4863.730s, loss: 0.435, train accuracy: 0.852\n","epoch: 13, time: 4874.255s, loss: 1.410, train accuracy: 0.477\n","epoch: 13, time: 4884.805s, loss: 0.512, train accuracy: 0.797\n","epoch: 13, time: 4895.349s, loss: 0.442, train accuracy: 0.820\n","epoch: 13, time: 4905.906s, loss: 0.443, train accuracy: 0.844\n","epoch: 13, time: 4916.448s, loss: 0.537, train accuracy: 0.805\n","epoch: 13, time: 4926.996s, loss: 0.422, train accuracy: 0.836\n","epoch: 13, time: 4937.535s, loss: 0.401, train accuracy: 0.859\n","epoch: 13, time: 4948.077s, loss: 0.506, train accuracy: 0.828\n","epoch: 13, time: 4958.616s, loss: 0.427, train accuracy: 0.859\n","epoch: 13, time: 4969.152s, loss: 0.422, train accuracy: 0.828\n","epoch: 13, time: 4979.696s, loss: 0.365, train accuracy: 0.852\n","epoch: 13, time: 4990.230s, loss: 0.468, train accuracy: 0.820\n","epoch: 13, time: 5000.778s, loss: 1.114, train accuracy: 0.594\n","epoch: 13, time: 5011.324s, loss: 1.215, train accuracy: 0.547\n","epoch: 13, time: 5021.851s, loss: 1.406, train accuracy: 0.492\n","epoch: 13, time: 5032.355s, loss: 1.254, train accuracy: 0.500\n","epoch: 13, time: 5042.875s, loss: 0.394, train accuracy: 0.867\n","epoch: 13, time: 5053.412s, loss: 0.347, train accuracy: 0.844\n","epoch: 13, time: 5063.949s, loss: 1.447, train accuracy: 0.484\n","epoch: 13, time: 5074.510s, loss: 1.084, train accuracy: 0.602\n","epoch: 13, time: 5085.068s, loss: 1.372, train accuracy: 0.492\n","epoch: 13, time: 5095.595s, loss: 1.121, train accuracy: 0.500\n","epoch: 13, time: 5106.121s, loss: 0.385, train accuracy: 0.875\n","epoch: 13, time: 5116.630s, loss: 1.038, train accuracy: 0.625\n","epoch: 13, time: 5127.140s, loss: 0.446, train accuracy: 0.828\n","epoch: 13, time: 5137.646s, loss: 1.062, train accuracy: 0.547\n","epoch: 13, time: 5148.155s, loss: 0.464, train accuracy: 0.805\n","epoch: 13, time: 5158.683s, loss: 0.335, train accuracy: 0.852\n","epoch: 13, time: 5169.206s, loss: 1.162, train accuracy: 0.578\n","epoch: 13, time: 5179.726s, loss: 1.137, train accuracy: 0.508\n","epoch: 13, time: 5190.243s, loss: 0.388, train accuracy: 0.875\n","epoch: 13, time: 5200.764s, loss: 0.373, train accuracy: 0.898\n","epoch: 13, time: 5211.296s, loss: 0.511, train accuracy: 0.844\n","epoch: 13, time: 5221.820s, loss: 0.427, train accuracy: 0.836\n","epoch: 13, validation loss: 0.44656741117109366\n","epoch: 14, time: 5234.517s, loss: 1.241, train accuracy: 0.539\n","epoch: 14, time: 5245.038s, loss: 0.398, train accuracy: 0.852\n","epoch: 14, time: 5255.556s, loss: 1.163, train accuracy: 0.594\n","epoch: 14, time: 5266.076s, loss: 0.375, train accuracy: 0.891\n","epoch: 14, time: 5276.597s, loss: 1.334, train accuracy: 0.492\n","epoch: 14, time: 5287.132s, loss: 1.123, train accuracy: 0.562\n","epoch: 14, time: 5297.668s, loss: 0.465, train accuracy: 0.789\n","epoch: 14, time: 5308.184s, loss: 1.192, train accuracy: 0.555\n","epoch: 14, time: 5318.732s, loss: 0.451, train accuracy: 0.844\n","epoch: 14, time: 5329.260s, loss: 0.384, train accuracy: 0.859\n","epoch: 14, time: 5339.782s, loss: 1.157, train accuracy: 0.531\n","epoch: 14, time: 5350.308s, loss: 0.434, train accuracy: 0.828\n","epoch: 14, time: 5360.831s, loss: 0.485, train accuracy: 0.797\n","epoch: 14, time: 5371.356s, loss: 1.191, train accuracy: 0.555\n","epoch: 14, time: 5381.886s, loss: 0.920, train accuracy: 0.625\n","epoch: 14, time: 5392.410s, loss: 0.994, train accuracy: 0.570\n","epoch: 14, time: 5402.935s, loss: 0.461, train accuracy: 0.812\n","epoch: 14, time: 5413.454s, loss: 0.981, train accuracy: 0.625\n","epoch: 14, time: 5423.977s, loss: 1.148, train accuracy: 0.523\n","epoch: 14, time: 5434.503s, loss: 0.390, train accuracy: 0.875\n","epoch: 14, time: 5445.020s, loss: 0.552, train accuracy: 0.789\n","epoch: 14, time: 5455.545s, loss: 0.383, train accuracy: 0.867\n","epoch: 14, time: 5466.071s, loss: 0.427, train accuracy: 0.820\n","epoch: 14, time: 5476.593s, loss: 1.183, train accuracy: 0.562\n","epoch: 14, time: 5487.136s, loss: 0.452, train accuracy: 0.828\n","epoch: 14, time: 5497.650s, loss: 1.295, train accuracy: 0.453\n","epoch: 14, time: 5508.177s, loss: 0.413, train accuracy: 0.836\n","epoch: 14, time: 5518.706s, loss: 0.397, train accuracy: 0.867\n","epoch: 14, time: 5529.239s, loss: 1.327, train accuracy: 0.500\n","epoch: 14, time: 5539.762s, loss: 1.230, train accuracy: 0.516\n","epoch: 14, time: 5550.291s, loss: 1.320, train accuracy: 0.516\n","epoch: 14, time: 5560.808s, loss: 1.120, train accuracy: 0.562\n","epoch: 14, time: 5571.340s, loss: 1.275, train accuracy: 0.461\n","epoch: 14, time: 5581.856s, loss: 1.309, train accuracy: 0.523\n","epoch: 14, time: 5592.389s, loss: 0.413, train accuracy: 0.844\n","epoch: 14, time: 5602.904s, loss: 1.230, train accuracy: 0.508\n","epoch: 14, time: 5613.433s, loss: 1.060, train accuracy: 0.586\n","epoch: 14, time: 5623.964s, loss: 0.291, train accuracy: 0.914\n","epoch: 14, validation loss: 0.44494383485078304\n","epoch: 15, time: 5636.632s, loss: 1.115, train accuracy: 0.547\n","epoch: 15, time: 5647.153s, loss: 1.257, train accuracy: 0.547\n","epoch: 15, time: 5657.669s, loss: 0.465, train accuracy: 0.844\n","epoch: 15, time: 5668.194s, loss: 1.075, train accuracy: 0.547\n","epoch: 15, time: 5678.708s, loss: 1.416, train accuracy: 0.516\n","epoch: 15, time: 5689.240s, loss: 1.074, train accuracy: 0.547\n","epoch: 15, time: 5699.765s, loss: 1.092, train accuracy: 0.562\n","epoch: 15, time: 5710.291s, loss: 1.243, train accuracy: 0.562\n","epoch: 15, time: 5720.818s, loss: 1.212, train accuracy: 0.523\n","epoch: 15, time: 5731.345s, loss: 1.316, train accuracy: 0.461\n","epoch: 15, time: 5741.869s, loss: 0.854, train accuracy: 0.602\n","epoch: 15, time: 5752.400s, loss: 1.021, train accuracy: 0.578\n","epoch: 15, time: 5762.921s, loss: 0.468, train accuracy: 0.812\n","epoch: 15, time: 5773.437s, loss: 0.459, train accuracy: 0.812\n","epoch: 15, time: 5783.961s, loss: 1.032, train accuracy: 0.586\n","epoch: 15, time: 5794.475s, loss: 0.301, train accuracy: 0.891\n","epoch: 15, time: 5805.006s, loss: 1.206, train accuracy: 0.547\n","epoch: 15, time: 5815.517s, loss: 0.419, train accuracy: 0.820\n","epoch: 15, time: 5826.026s, loss: 1.115, train accuracy: 0.562\n","epoch: 15, time: 5836.540s, loss: 0.496, train accuracy: 0.758\n","epoch: 15, time: 5847.054s, loss: 1.279, train accuracy: 0.547\n","epoch: 15, time: 5857.578s, loss: 1.353, train accuracy: 0.508\n","epoch: 15, time: 5868.093s, loss: 1.384, train accuracy: 0.461\n","epoch: 15, time: 5878.616s, loss: 0.413, train accuracy: 0.859\n","epoch: 15, time: 5889.130s, loss: 0.380, train accuracy: 0.867\n","epoch: 15, time: 5899.645s, loss: 0.454, train accuracy: 0.812\n","epoch: 15, time: 5910.154s, loss: 0.415, train accuracy: 0.812\n","epoch: 15, time: 5920.652s, loss: 0.429, train accuracy: 0.852\n","epoch: 15, time: 5931.156s, loss: 0.522, train accuracy: 0.766\n","epoch: 15, time: 5941.662s, loss: 1.072, train accuracy: 0.578\n","epoch: 15, time: 5952.171s, loss: 0.483, train accuracy: 0.859\n","epoch: 15, time: 5962.693s, loss: 0.350, train accuracy: 0.844\n","epoch: 15, time: 5973.197s, loss: 1.122, train accuracy: 0.523\n","epoch: 15, time: 5983.700s, loss: 0.301, train accuracy: 0.883\n","epoch: 15, time: 5994.207s, loss: 1.141, train accuracy: 0.555\n","epoch: 15, time: 6004.712s, loss: 0.541, train accuracy: 0.789\n","epoch: 15, time: 6015.218s, loss: 0.951, train accuracy: 0.578\n","epoch: 15, time: 6025.735s, loss: 1.160, train accuracy: 0.547\n","epoch: 15, validation loss: 0.4372128698109055\n","epoch: 16, time: 6038.413s, loss: 0.492, train accuracy: 0.820\n","epoch: 16, time: 6048.930s, loss: 1.407, train accuracy: 0.484\n","epoch: 16, time: 6059.439s, loss: 0.473, train accuracy: 0.820\n","epoch: 16, time: 6069.946s, loss: 1.143, train accuracy: 0.555\n","epoch: 16, time: 6080.461s, loss: 0.450, train accuracy: 0.820\n","epoch: 16, time: 6090.972s, loss: 1.075, train accuracy: 0.625\n","epoch: 16, time: 6101.493s, loss: 1.168, train accuracy: 0.555\n","epoch: 16, time: 6112.020s, loss: 1.094, train accuracy: 0.547\n","epoch: 16, time: 6122.548s, loss: 0.499, train accuracy: 0.797\n","epoch: 16, time: 6133.062s, loss: 0.461, train accuracy: 0.781\n","epoch: 16, time: 6143.582s, loss: 0.424, train accuracy: 0.883\n","epoch: 16, time: 6154.088s, loss: 0.369, train accuracy: 0.867\n","epoch: 16, time: 6164.588s, loss: 1.079, train accuracy: 0.547\n","epoch: 16, time: 6175.096s, loss: 1.022, train accuracy: 0.594\n","epoch: 16, time: 6185.605s, loss: 1.082, train accuracy: 0.523\n","epoch: 16, time: 6196.115s, loss: 1.218, train accuracy: 0.547\n","epoch: 16, time: 6206.625s, loss: 0.332, train accuracy: 0.883\n","epoch: 16, time: 6217.130s, loss: 0.451, train accuracy: 0.852\n","epoch: 16, time: 6227.642s, loss: 1.122, train accuracy: 0.570\n","epoch: 16, time: 6238.155s, loss: 1.309, train accuracy: 0.477\n","epoch: 16, time: 6248.670s, loss: 1.172, train accuracy: 0.492\n","epoch: 16, time: 6259.182s, loss: 1.202, train accuracy: 0.555\n","epoch: 16, time: 6269.679s, loss: 1.028, train accuracy: 0.562\n","epoch: 16, time: 6280.177s, loss: 1.408, train accuracy: 0.492\n","epoch: 16, time: 6290.686s, loss: 0.490, train accuracy: 0.812\n","epoch: 16, time: 6301.205s, loss: 1.187, train accuracy: 0.516\n","epoch: 16, time: 6311.727s, loss: 1.235, train accuracy: 0.531\n","epoch: 16, time: 6322.262s, loss: 1.302, train accuracy: 0.539\n","epoch: 16, time: 6332.806s, loss: 1.128, train accuracy: 0.570\n","epoch: 16, time: 6343.340s, loss: 1.100, train accuracy: 0.547\n","epoch: 16, time: 6353.859s, loss: 1.139, train accuracy: 0.578\n","epoch: 16, time: 6364.360s, loss: 0.424, train accuracy: 0.812\n","epoch: 16, time: 6374.865s, loss: 1.262, train accuracy: 0.539\n","epoch: 16, time: 6385.365s, loss: 0.501, train accuracy: 0.789\n","epoch: 16, time: 6395.886s, loss: 0.371, train accuracy: 0.852\n","epoch: 16, time: 6406.423s, loss: 0.416, train accuracy: 0.852\n","epoch: 16, time: 6416.940s, loss: 0.946, train accuracy: 0.578\n","epoch: 16, time: 6427.474s, loss: 0.384, train accuracy: 0.836\n","epoch: 16, validation loss: 0.45686698372938483\n","epoch: 17, time: 6440.153s, loss: 1.269, train accuracy: 0.594\n","epoch: 17, time: 6450.683s, loss: 1.379, train accuracy: 0.523\n","epoch: 17, time: 6461.220s, loss: 0.418, train accuracy: 0.812\n","epoch: 17, time: 6471.744s, loss: 1.261, train accuracy: 0.539\n","epoch: 17, time: 6482.275s, loss: 0.536, train accuracy: 0.797\n","epoch: 17, time: 6492.813s, loss: 0.413, train accuracy: 0.859\n","epoch: 17, time: 6503.333s, loss: 0.466, train accuracy: 0.828\n","epoch: 17, time: 6513.856s, loss: 1.007, train accuracy: 0.609\n","epoch: 17, time: 6524.378s, loss: 0.429, train accuracy: 0.859\n","epoch: 17, time: 6534.905s, loss: 0.434, train accuracy: 0.820\n","epoch: 17, time: 6545.438s, loss: 0.400, train accuracy: 0.828\n","epoch: 17, time: 6555.956s, loss: 0.422, train accuracy: 0.859\n","epoch: 17, time: 6566.469s, loss: 1.256, train accuracy: 0.430\n","epoch: 17, time: 6576.999s, loss: 0.343, train accuracy: 0.867\n","epoch: 17, time: 6587.544s, loss: 1.140, train accuracy: 0.586\n","epoch: 17, time: 6598.087s, loss: 1.237, train accuracy: 0.523\n","epoch: 17, time: 6608.610s, loss: 1.243, train accuracy: 0.562\n","epoch: 17, time: 6619.122s, loss: 0.536, train accuracy: 0.789\n","epoch: 17, time: 6629.644s, loss: 1.241, train accuracy: 0.516\n","epoch: 17, time: 6640.174s, loss: 0.472, train accuracy: 0.812\n","epoch: 17, time: 6650.712s, loss: 0.345, train accuracy: 0.875\n","epoch: 17, time: 6661.253s, loss: 1.162, train accuracy: 0.531\n","epoch: 17, time: 6671.811s, loss: 0.389, train accuracy: 0.852\n","epoch: 17, time: 6682.359s, loss: 0.373, train accuracy: 0.875\n","epoch: 17, time: 6692.917s, loss: 1.132, train accuracy: 0.570\n","epoch: 17, time: 6703.458s, loss: 0.595, train accuracy: 0.766\n","epoch: 17, time: 6713.993s, loss: 0.432, train accuracy: 0.820\n","epoch: 17, time: 6724.526s, loss: 1.267, train accuracy: 0.523\n","epoch: 17, time: 6735.064s, loss: 0.376, train accuracy: 0.875\n","epoch: 17, time: 6745.612s, loss: 1.256, train accuracy: 0.500\n","epoch: 17, time: 6756.153s, loss: 1.379, train accuracy: 0.531\n","epoch: 17, time: 6766.703s, loss: 1.284, train accuracy: 0.508\n","epoch: 17, time: 6777.245s, loss: 0.561, train accuracy: 0.773\n","epoch: 17, time: 6787.782s, loss: 0.488, train accuracy: 0.828\n","epoch: 17, time: 6798.324s, loss: 0.438, train accuracy: 0.828\n","epoch: 17, time: 6808.850s, loss: 1.236, train accuracy: 0.531\n","epoch: 17, time: 6819.392s, loss: 0.380, train accuracy: 0.844\n","epoch: 17, time: 6829.930s, loss: 0.689, train accuracy: 0.750\n","epoch: 17, validation loss: 0.43834432578290194\n","epoch: 18, time: 6842.597s, loss: 1.026, train accuracy: 0.617\n","epoch: 18, time: 6853.131s, loss: 1.222, train accuracy: 0.516\n","epoch: 18, time: 6863.668s, loss: 1.170, train accuracy: 0.555\n","epoch: 18, time: 6874.197s, loss: 1.284, train accuracy: 0.469\n","epoch: 18, time: 6884.718s, loss: 0.402, train accuracy: 0.828\n","epoch: 18, time: 6895.242s, loss: 1.238, train accuracy: 0.531\n","epoch: 18, time: 6905.778s, loss: 0.286, train accuracy: 0.898\n","epoch: 18, time: 6916.306s, loss: 1.128, train accuracy: 0.602\n","epoch: 18, time: 6926.842s, loss: 1.282, train accuracy: 0.531\n","epoch: 18, time: 6937.371s, loss: 0.617, train accuracy: 0.758\n","epoch: 18, time: 6947.902s, loss: 0.422, train accuracy: 0.867\n","epoch: 18, time: 6958.444s, loss: 0.376, train accuracy: 0.891\n","epoch: 18, time: 6968.986s, loss: 0.381, train accuracy: 0.852\n","epoch: 18, time: 6979.521s, loss: 1.437, train accuracy: 0.492\n","epoch: 18, time: 6990.065s, loss: 1.315, train accuracy: 0.477\n","epoch: 18, time: 7000.607s, loss: 0.453, train accuracy: 0.852\n","epoch: 18, time: 7011.146s, loss: 0.376, train accuracy: 0.859\n","epoch: 18, time: 7021.675s, loss: 1.171, train accuracy: 0.562\n","epoch: 18, time: 7032.214s, loss: 0.441, train accuracy: 0.789\n","epoch: 18, time: 7042.753s, loss: 0.402, train accuracy: 0.836\n","epoch: 18, time: 7053.302s, loss: 0.307, train accuracy: 0.859\n","epoch: 18, time: 7063.851s, loss: 1.372, train accuracy: 0.484\n","epoch: 18, time: 7074.405s, loss: 0.437, train accuracy: 0.812\n","epoch: 18, time: 7084.949s, loss: 0.496, train accuracy: 0.820\n","epoch: 18, time: 7095.493s, loss: 0.353, train accuracy: 0.859\n","epoch: 18, time: 7106.036s, loss: 0.443, train accuracy: 0.805\n","epoch: 18, time: 7116.591s, loss: 0.467, train accuracy: 0.820\n","epoch: 18, time: 7127.135s, loss: 0.478, train accuracy: 0.805\n","epoch: 18, time: 7137.671s, loss: 0.470, train accuracy: 0.797\n","epoch: 18, time: 7148.212s, loss: 0.342, train accuracy: 0.867\n","epoch: 18, time: 7158.755s, loss: 1.353, train accuracy: 0.523\n","epoch: 18, time: 7169.304s, loss: 0.974, train accuracy: 0.609\n","epoch: 18, time: 7179.843s, loss: 0.504, train accuracy: 0.805\n","epoch: 18, time: 7190.379s, loss: 0.370, train accuracy: 0.852\n","epoch: 18, time: 7200.906s, loss: 1.118, train accuracy: 0.570\n","epoch: 18, time: 7211.446s, loss: 0.522, train accuracy: 0.828\n","epoch: 18, time: 7221.996s, loss: 1.069, train accuracy: 0.602\n","epoch: 18, time: 7232.544s, loss: 1.230, train accuracy: 0.508\n","epoch: 18, validation loss: 0.4418970976811228\n","epoch: 19, time: 7245.219s, loss: 1.208, train accuracy: 0.562\n","epoch: 19, time: 7255.754s, loss: 1.075, train accuracy: 0.555\n","epoch: 19, time: 7266.283s, loss: 0.486, train accuracy: 0.805\n","epoch: 19, time: 7276.811s, loss: 0.572, train accuracy: 0.758\n","epoch: 19, time: 7287.345s, loss: 1.233, train accuracy: 0.492\n","epoch: 19, time: 7297.889s, loss: 1.223, train accuracy: 0.508\n","epoch: 19, time: 7308.426s, loss: 0.511, train accuracy: 0.789\n","epoch: 19, time: 7318.970s, loss: 1.070, train accuracy: 0.594\n","epoch: 19, time: 7329.523s, loss: 1.250, train accuracy: 0.453\n","epoch: 19, time: 7340.052s, loss: 0.409, train accuracy: 0.867\n","epoch: 19, time: 7350.589s, loss: 1.180, train accuracy: 0.562\n","epoch: 19, time: 7361.121s, loss: 1.224, train accuracy: 0.547\n","epoch: 19, time: 7371.653s, loss: 0.352, train accuracy: 0.852\n","epoch: 19, time: 7382.189s, loss: 0.365, train accuracy: 0.859\n","epoch: 19, time: 7392.724s, loss: 0.956, train accuracy: 0.617\n","epoch: 19, time: 7403.249s, loss: 1.255, train accuracy: 0.547\n","epoch: 19, time: 7413.783s, loss: 1.125, train accuracy: 0.562\n","epoch: 19, time: 7424.306s, loss: 0.303, train accuracy: 0.922\n","epoch: 19, time: 7434.836s, loss: 1.211, train accuracy: 0.562\n","epoch: 19, time: 7445.357s, loss: 0.394, train accuracy: 0.828\n","epoch: 19, time: 7455.883s, loss: 0.518, train accuracy: 0.789\n","epoch: 19, time: 7466.414s, loss: 0.325, train accuracy: 0.883\n","epoch: 19, time: 7476.954s, loss: 0.462, train accuracy: 0.867\n","epoch: 19, time: 7487.480s, loss: 0.466, train accuracy: 0.812\n","epoch: 19, time: 7498.006s, loss: 1.136, train accuracy: 0.562\n","epoch: 19, time: 7508.527s, loss: 1.312, train accuracy: 0.516\n","epoch: 19, time: 7519.071s, loss: 1.313, train accuracy: 0.555\n","epoch: 19, time: 7529.609s, loss: 0.398, train accuracy: 0.867\n","epoch: 19, time: 7540.136s, loss: 1.134, train accuracy: 0.516\n","epoch: 19, time: 7550.655s, loss: 0.521, train accuracy: 0.789\n","epoch: 19, time: 7561.183s, loss: 0.489, train accuracy: 0.805\n","epoch: 19, time: 7571.710s, loss: 1.172, train accuracy: 0.516\n","epoch: 19, time: 7582.234s, loss: 1.196, train accuracy: 0.555\n","epoch: 19, time: 7592.751s, loss: 1.152, train accuracy: 0.516\n","epoch: 19, time: 7603.279s, loss: 0.369, train accuracy: 0.875\n","epoch: 19, time: 7613.805s, loss: 0.434, train accuracy: 0.836\n","epoch: 19, time: 7624.344s, loss: 0.996, train accuracy: 0.578\n","epoch: 19, time: 7634.871s, loss: 0.319, train accuracy: 0.883\n","epoch: 19, validation loss: 0.4352051061607881\n","epoch: 20, time: 7647.573s, loss: 1.060, train accuracy: 0.570\n","epoch: 20, time: 7658.090s, loss: 0.486, train accuracy: 0.812\n","epoch: 20, time: 7668.610s, loss: 1.221, train accuracy: 0.547\n","epoch: 20, time: 7679.149s, loss: 0.463, train accuracy: 0.797\n","epoch: 20, time: 7689.702s, loss: 1.040, train accuracy: 0.578\n","epoch: 20, time: 7700.260s, loss: 0.471, train accuracy: 0.812\n","epoch: 20, time: 7710.814s, loss: 1.243, train accuracy: 0.500\n","epoch: 20, time: 7721.370s, loss: 0.478, train accuracy: 0.812\n","epoch: 20, time: 7731.921s, loss: 1.168, train accuracy: 0.570\n","epoch: 20, time: 7742.462s, loss: 0.398, train accuracy: 0.859\n","epoch: 20, time: 7753.006s, loss: 0.429, train accuracy: 0.852\n","epoch: 20, time: 7763.543s, loss: 0.262, train accuracy: 0.914\n","epoch: 20, time: 7774.078s, loss: 0.319, train accuracy: 0.875\n","epoch: 20, time: 7784.605s, loss: 0.429, train accuracy: 0.828\n","epoch: 20, time: 7795.131s, loss: 1.194, train accuracy: 0.555\n","epoch: 20, time: 7805.657s, loss: 1.258, train accuracy: 0.570\n","epoch: 20, time: 7816.184s, loss: 0.392, train accuracy: 0.875\n","epoch: 20, time: 7826.721s, loss: 1.273, train accuracy: 0.492\n","epoch: 20, time: 7837.244s, loss: 1.201, train accuracy: 0.555\n","epoch: 20, time: 7847.769s, loss: 0.513, train accuracy: 0.812\n","epoch: 20, time: 7858.300s, loss: 0.347, train accuracy: 0.852\n","epoch: 20, time: 7868.825s, loss: 1.297, train accuracy: 0.547\n","epoch: 20, time: 7879.363s, loss: 0.392, train accuracy: 0.812\n","epoch: 20, time: 7889.910s, loss: 0.306, train accuracy: 0.891\n","epoch: 20, time: 7900.433s, loss: 1.013, train accuracy: 0.602\n","epoch: 20, time: 7910.971s, loss: 0.475, train accuracy: 0.852\n","epoch: 20, time: 7921.512s, loss: 1.276, train accuracy: 0.523\n","epoch: 20, time: 7932.041s, loss: 0.497, train accuracy: 0.812\n","epoch: 20, time: 7942.572s, loss: 0.307, train accuracy: 0.875\n","epoch: 20, time: 7953.112s, loss: 1.111, train accuracy: 0.594\n","epoch: 20, time: 7963.643s, loss: 0.423, train accuracy: 0.852\n","epoch: 20, time: 7974.181s, loss: 1.313, train accuracy: 0.516\n","epoch: 20, time: 7984.717s, loss: 0.407, train accuracy: 0.898\n","epoch: 20, time: 7995.251s, loss: 1.386, train accuracy: 0.484\n","epoch: 20, time: 8005.782s, loss: 0.413, train accuracy: 0.828\n","epoch: 20, time: 8016.315s, loss: 0.410, train accuracy: 0.828\n","epoch: 20, time: 8026.846s, loss: 0.298, train accuracy: 0.906\n","epoch: 20, time: 8037.378s, loss: 1.072, train accuracy: 0.594\n","epoch: 20, validation loss: 0.42898487898586657\n","epoch: 21, time: 8050.075s, loss: 1.013, train accuracy: 0.594\n","epoch: 21, time: 8060.595s, loss: 1.184, train accuracy: 0.547\n","epoch: 21, time: 8071.124s, loss: 0.486, train accuracy: 0.789\n","epoch: 21, time: 8081.651s, loss: 1.155, train accuracy: 0.570\n","epoch: 21, time: 8092.184s, loss: 1.109, train accuracy: 0.547\n","epoch: 21, time: 8102.732s, loss: 0.419, train accuracy: 0.820\n","epoch: 21, time: 8113.285s, loss: 0.474, train accuracy: 0.836\n","epoch: 21, time: 8123.828s, loss: 0.511, train accuracy: 0.820\n","epoch: 21, time: 8134.374s, loss: 1.069, train accuracy: 0.570\n","epoch: 21, time: 8144.920s, loss: 1.351, train accuracy: 0.500\n","epoch: 21, time: 8155.457s, loss: 1.034, train accuracy: 0.602\n","epoch: 21, time: 8166.002s, loss: 0.480, train accuracy: 0.844\n","epoch: 21, time: 8176.540s, loss: 1.209, train accuracy: 0.516\n","epoch: 21, time: 8187.075s, loss: 1.276, train accuracy: 0.461\n","epoch: 21, time: 8197.629s, loss: 0.466, train accuracy: 0.789\n","epoch: 21, time: 8208.170s, loss: 0.347, train accuracy: 0.867\n","epoch: 21, time: 8218.705s, loss: 1.296, train accuracy: 0.531\n","epoch: 21, time: 8229.254s, loss: 0.410, train accuracy: 0.812\n","epoch: 21, time: 8239.801s, loss: 0.471, train accuracy: 0.836\n","epoch: 21, time: 8250.346s, loss: 1.137, train accuracy: 0.547\n","epoch: 21, time: 8260.893s, loss: 0.554, train accuracy: 0.812\n","epoch: 21, time: 8271.432s, loss: 0.363, train accuracy: 0.828\n","epoch: 21, time: 8281.965s, loss: 1.201, train accuracy: 0.578\n","epoch: 21, time: 8292.503s, loss: 1.076, train accuracy: 0.570\n","epoch: 21, time: 8303.047s, loss: 1.142, train accuracy: 0.555\n","epoch: 21, time: 8313.592s, loss: 0.434, train accuracy: 0.836\n","epoch: 21, time: 8324.145s, loss: 0.394, train accuracy: 0.844\n","epoch: 21, time: 8334.692s, loss: 0.515, train accuracy: 0.805\n","epoch: 21, time: 8345.222s, loss: 0.382, train accuracy: 0.867\n","epoch: 21, time: 8355.760s, loss: 0.530, train accuracy: 0.789\n","epoch: 21, time: 8366.299s, loss: 0.409, train accuracy: 0.844\n","epoch: 21, time: 8376.849s, loss: 0.517, train accuracy: 0.805\n","epoch: 21, time: 8387.395s, loss: 0.464, train accuracy: 0.789\n","epoch: 21, time: 8397.939s, loss: 0.371, train accuracy: 0.852\n","epoch: 21, time: 8408.487s, loss: 0.418, train accuracy: 0.859\n","epoch: 21, time: 8419.023s, loss: 1.124, train accuracy: 0.531\n","epoch: 21, time: 8429.555s, loss: 1.238, train accuracy: 0.469\n","epoch: 21, time: 8440.097s, loss: 0.473, train accuracy: 0.797\n","epoch: 21, validation loss: 0.4342332501718993\n","epoch: 22, time: 8452.809s, loss: 0.493, train accuracy: 0.836\n","epoch: 22, time: 8463.342s, loss: 0.443, train accuracy: 0.844\n","epoch: 22, time: 8473.869s, loss: 0.490, train accuracy: 0.820\n","epoch: 22, time: 8484.385s, loss: 1.250, train accuracy: 0.523\n","epoch: 22, time: 8494.912s, loss: 0.495, train accuracy: 0.797\n","epoch: 22, time: 8505.437s, loss: 0.387, train accuracy: 0.867\n","epoch: 22, time: 8515.959s, loss: 1.080, train accuracy: 0.555\n","epoch: 22, time: 8526.484s, loss: 0.337, train accuracy: 0.883\n","epoch: 22, time: 8537.014s, loss: 1.153, train accuracy: 0.531\n","epoch: 22, time: 8547.541s, loss: 1.161, train accuracy: 0.531\n","epoch: 22, time: 8558.073s, loss: 0.457, train accuracy: 0.805\n","epoch: 22, time: 8568.595s, loss: 1.294, train accuracy: 0.531\n","epoch: 22, time: 8579.120s, loss: 1.143, train accuracy: 0.586\n","epoch: 22, time: 8589.649s, loss: 1.173, train accuracy: 0.555\n","epoch: 22, time: 8600.175s, loss: 0.567, train accuracy: 0.789\n","epoch: 22, time: 8610.701s, loss: 0.373, train accuracy: 0.852\n","epoch: 22, time: 8621.231s, loss: 0.456, train accuracy: 0.805\n","epoch: 22, time: 8631.762s, loss: 0.499, train accuracy: 0.789\n","epoch: 22, time: 8642.297s, loss: 0.467, train accuracy: 0.828\n","epoch: 22, time: 8652.825s, loss: 1.196, train accuracy: 0.578\n","epoch: 22, time: 8663.350s, loss: 0.340, train accuracy: 0.867\n","epoch: 22, time: 8673.886s, loss: 1.054, train accuracy: 0.516\n","epoch: 22, time: 8684.420s, loss: 0.359, train accuracy: 0.875\n","epoch: 22, time: 8694.942s, loss: 1.190, train accuracy: 0.516\n","epoch: 22, time: 8705.467s, loss: 0.319, train accuracy: 0.891\n","epoch: 22, time: 8715.998s, loss: 1.106, train accuracy: 0.539\n","epoch: 22, time: 8726.521s, loss: 1.259, train accuracy: 0.547\n","epoch: 22, time: 8737.062s, loss: 0.424, train accuracy: 0.828\n","epoch: 22, time: 8747.595s, loss: 0.382, train accuracy: 0.859\n","epoch: 22, time: 8758.125s, loss: 0.444, train accuracy: 0.797\n","epoch: 22, time: 8768.663s, loss: 0.928, train accuracy: 0.578\n","epoch: 22, time: 8779.205s, loss: 1.108, train accuracy: 0.523\n","epoch: 22, time: 8789.743s, loss: 0.385, train accuracy: 0.867\n","epoch: 22, time: 8800.287s, loss: 0.440, train accuracy: 0.820\n","epoch: 22, time: 8810.817s, loss: 0.592, train accuracy: 0.812\n","epoch: 22, time: 8821.366s, loss: 1.215, train accuracy: 0.539\n","epoch: 22, time: 8831.915s, loss: 0.936, train accuracy: 0.664\n","epoch: 22, time: 8842.459s, loss: 1.123, train accuracy: 0.562\n","epoch: 22, validation loss: 0.443232506259418\n","epoch: 23, time: 8855.120s, loss: 0.433, train accuracy: 0.844\n","epoch: 23, time: 8865.657s, loss: 1.194, train accuracy: 0.516\n","epoch: 23, time: 8876.179s, loss: 0.399, train accuracy: 0.828\n","epoch: 23, time: 8886.703s, loss: 1.179, train accuracy: 0.508\n","epoch: 23, time: 8897.218s, loss: 1.414, train accuracy: 0.461\n","epoch: 23, time: 8907.726s, loss: 1.173, train accuracy: 0.492\n","epoch: 23, time: 8918.234s, loss: 0.439, train accuracy: 0.852\n","epoch: 23, time: 8928.755s, loss: 0.327, train accuracy: 0.836\n","epoch: 23, time: 8939.284s, loss: 0.382, train accuracy: 0.852\n","epoch: 23, time: 8949.810s, loss: 1.164, train accuracy: 0.492\n","epoch: 23, time: 8960.329s, loss: 0.369, train accuracy: 0.859\n","epoch: 23, time: 8970.847s, loss: 0.403, train accuracy: 0.836\n","epoch: 23, time: 8981.361s, loss: 0.329, train accuracy: 0.852\n","epoch: 23, time: 8991.878s, loss: 0.430, train accuracy: 0.867\n","epoch: 23, time: 9002.397s, loss: 0.465, train accuracy: 0.820\n","epoch: 23, time: 9012.916s, loss: 1.254, train accuracy: 0.531\n","epoch: 23, time: 9023.436s, loss: 0.352, train accuracy: 0.867\n","epoch: 23, time: 9033.952s, loss: 0.482, train accuracy: 0.820\n","epoch: 23, time: 9044.478s, loss: 1.358, train accuracy: 0.539\n","epoch: 23, time: 9055.004s, loss: 0.463, train accuracy: 0.828\n","epoch: 23, time: 9065.522s, loss: 0.357, train accuracy: 0.867\n","epoch: 23, time: 9076.043s, loss: 0.464, train accuracy: 0.852\n","epoch: 23, time: 9086.563s, loss: 1.142, train accuracy: 0.578\n","epoch: 23, time: 9097.094s, loss: 0.362, train accuracy: 0.852\n","epoch: 23, time: 9107.617s, loss: 0.481, train accuracy: 0.805\n","epoch: 23, time: 9118.145s, loss: 0.417, train accuracy: 0.875\n","epoch: 23, time: 9128.664s, loss: 1.135, train accuracy: 0.570\n","epoch: 23, time: 9139.182s, loss: 0.991, train accuracy: 0.578\n","epoch: 23, time: 9149.716s, loss: 0.384, train accuracy: 0.867\n","epoch: 23, time: 9160.240s, loss: 1.108, train accuracy: 0.547\n","epoch: 23, time: 9170.751s, loss: 0.453, train accuracy: 0.805\n","epoch: 23, time: 9181.273s, loss: 1.128, train accuracy: 0.602\n","epoch: 23, time: 9191.787s, loss: 1.228, train accuracy: 0.539\n","epoch: 23, time: 9202.311s, loss: 0.474, train accuracy: 0.844\n","epoch: 23, time: 9212.832s, loss: 1.143, train accuracy: 0.500\n","epoch: 23, time: 9223.361s, loss: 0.440, train accuracy: 0.820\n","epoch: 23, time: 9233.878s, loss: 1.393, train accuracy: 0.453\n","epoch: 23, time: 9244.400s, loss: 1.093, train accuracy: 0.578\n","epoch: 23, validation loss: 0.4331035207964972\n","epoch: 24, time: 9257.067s, loss: 1.115, train accuracy: 0.570\n","epoch: 24, time: 9267.579s, loss: 1.224, train accuracy: 0.562\n","epoch: 24, time: 9278.099s, loss: 1.151, train accuracy: 0.570\n","epoch: 24, time: 9288.616s, loss: 0.606, train accuracy: 0.758\n","epoch: 24, time: 9299.137s, loss: 0.392, train accuracy: 0.875\n","epoch: 24, time: 9309.649s, loss: 1.220, train accuracy: 0.508\n","epoch: 24, time: 9320.173s, loss: 0.267, train accuracy: 0.930\n","epoch: 24, time: 9330.703s, loss: 0.504, train accuracy: 0.789\n","epoch: 24, time: 9341.241s, loss: 1.117, train accuracy: 0.570\n","epoch: 24, time: 9351.774s, loss: 0.567, train accuracy: 0.781\n","epoch: 24, time: 9362.300s, loss: 1.104, train accuracy: 0.570\n","epoch: 24, time: 9372.827s, loss: 1.185, train accuracy: 0.539\n","epoch: 24, time: 9383.342s, loss: 0.990, train accuracy: 0.594\n","epoch: 24, time: 9393.867s, loss: 1.186, train accuracy: 0.570\n","epoch: 24, time: 9404.397s, loss: 1.133, train accuracy: 0.586\n","epoch: 24, time: 9414.943s, loss: 1.201, train accuracy: 0.531\n","epoch: 24, time: 9425.468s, loss: 0.497, train accuracy: 0.797\n","epoch: 24, time: 9436.006s, loss: 0.353, train accuracy: 0.836\n","epoch: 24, time: 9446.540s, loss: 0.391, train accuracy: 0.844\n","epoch: 24, time: 9457.076s, loss: 0.403, train accuracy: 0.875\n","epoch: 24, time: 9467.607s, loss: 0.353, train accuracy: 0.844\n","epoch: 24, time: 9478.139s, loss: 0.517, train accuracy: 0.797\n","epoch: 24, time: 9488.669s, loss: 1.016, train accuracy: 0.570\n","epoch: 24, time: 9499.211s, loss: 0.403, train accuracy: 0.859\n","epoch: 24, time: 9509.741s, loss: 0.512, train accuracy: 0.844\n","epoch: 24, time: 9520.277s, loss: 0.367, train accuracy: 0.844\n","epoch: 24, time: 9530.806s, loss: 0.340, train accuracy: 0.867\n","epoch: 24, time: 9541.331s, loss: 0.440, train accuracy: 0.805\n","epoch: 24, time: 9551.863s, loss: 0.401, train accuracy: 0.844\n","epoch: 24, time: 9562.405s, loss: 0.446, train accuracy: 0.812\n","epoch: 24, time: 9572.941s, loss: 0.297, train accuracy: 0.914\n","epoch: 24, time: 9583.486s, loss: 1.143, train accuracy: 0.531\n","epoch: 24, time: 9594.023s, loss: 1.209, train accuracy: 0.578\n","epoch: 24, time: 9604.561s, loss: 1.333, train accuracy: 0.477\n","epoch: 24, time: 9615.102s, loss: 1.202, train accuracy: 0.508\n","epoch: 24, time: 9625.640s, loss: 0.521, train accuracy: 0.797\n","epoch: 24, time: 9636.176s, loss: 0.403, train accuracy: 0.875\n","epoch: 24, time: 9646.715s, loss: 1.101, train accuracy: 0.578\n","epoch: 24, validation loss: 0.4317157719689392\n","epoch: 25, time: 9659.407s, loss: 1.124, train accuracy: 0.625\n","epoch: 25, time: 9669.927s, loss: 1.110, train accuracy: 0.570\n","epoch: 25, time: 9680.453s, loss: 0.439, train accuracy: 0.820\n","epoch: 25, time: 9690.990s, loss: 0.407, train accuracy: 0.844\n","epoch: 25, time: 9701.528s, loss: 0.370, train accuracy: 0.859\n","epoch: 25, time: 9712.055s, loss: 0.278, train accuracy: 0.906\n","epoch: 25, time: 9722.586s, loss: 0.383, train accuracy: 0.836\n","epoch: 25, time: 9733.118s, loss: 1.298, train accuracy: 0.523\n","epoch: 25, time: 9743.646s, loss: 1.150, train accuracy: 0.500\n","epoch: 25, time: 9754.169s, loss: 1.180, train accuracy: 0.500\n","epoch: 25, time: 9764.692s, loss: 0.493, train accuracy: 0.828\n","epoch: 25, time: 9775.226s, loss: 1.297, train accuracy: 0.500\n","epoch: 25, time: 9785.761s, loss: 0.457, train accuracy: 0.812\n","epoch: 25, time: 9796.297s, loss: 0.377, train accuracy: 0.883\n","epoch: 25, time: 9806.844s, loss: 1.356, train accuracy: 0.477\n","epoch: 25, time: 9817.384s, loss: 0.362, train accuracy: 0.875\n","epoch: 25, time: 9827.932s, loss: 1.143, train accuracy: 0.523\n","epoch: 25, time: 9838.470s, loss: 1.235, train accuracy: 0.500\n","epoch: 25, time: 9849.004s, loss: 1.400, train accuracy: 0.414\n","epoch: 25, time: 9859.551s, loss: 0.381, train accuracy: 0.852\n","epoch: 25, time: 9870.099s, loss: 1.335, train accuracy: 0.516\n","epoch: 25, time: 9880.645s, loss: 0.406, train accuracy: 0.859\n","epoch: 25, time: 9891.188s, loss: 0.451, train accuracy: 0.859\n","epoch: 25, time: 9901.727s, loss: 1.076, train accuracy: 0.578\n","epoch: 25, time: 9912.274s, loss: 1.241, train accuracy: 0.531\n","epoch: 25, time: 9922.808s, loss: 0.366, train accuracy: 0.875\n","epoch: 25, time: 9933.349s, loss: 0.513, train accuracy: 0.797\n","epoch: 25, time: 9943.885s, loss: 1.056, train accuracy: 0.656\n","epoch: 25, time: 9954.424s, loss: 1.075, train accuracy: 0.602\n","epoch: 25, time: 9964.962s, loss: 0.424, train accuracy: 0.805\n","epoch: 25, time: 9975.509s, loss: 1.201, train accuracy: 0.516\n","epoch: 25, time: 9986.065s, loss: 0.473, train accuracy: 0.805\n","epoch: 25, time: 9996.595s, loss: 1.117, train accuracy: 0.562\n","epoch: 25, time: 10007.132s, loss: 1.207, train accuracy: 0.555\n","epoch: 25, time: 10017.677s, loss: 1.281, train accuracy: 0.484\n","epoch: 25, time: 10028.212s, loss: 0.421, train accuracy: 0.820\n","epoch: 25, time: 10038.745s, loss: 0.360, train accuracy: 0.852\n","epoch: 25, time: 10049.283s, loss: 1.343, train accuracy: 0.500\n","epoch: 25, validation loss: 0.4322779499518592\n","epoch: 26, time: 10061.966s, loss: 0.346, train accuracy: 0.891\n","epoch: 26, time: 10072.491s, loss: 0.409, train accuracy: 0.844\n","epoch: 26, time: 10083.024s, loss: 0.480, train accuracy: 0.836\n","epoch: 26, time: 10093.553s, loss: 1.066, train accuracy: 0.531\n","epoch: 26, time: 10104.091s, loss: 0.387, train accuracy: 0.867\n","epoch: 26, time: 10114.629s, loss: 0.393, train accuracy: 0.852\n","epoch: 26, time: 10125.155s, loss: 1.085, train accuracy: 0.586\n","epoch: 26, time: 10135.685s, loss: 0.423, train accuracy: 0.805\n","epoch: 26, time: 10146.213s, loss: 0.336, train accuracy: 0.891\n","epoch: 26, time: 10156.755s, loss: 1.203, train accuracy: 0.523\n","epoch: 26, time: 10167.283s, loss: 1.080, train accuracy: 0.555\n","epoch: 26, time: 10177.822s, loss: 1.069, train accuracy: 0.547\n","epoch: 26, time: 10188.371s, loss: 1.217, train accuracy: 0.555\n","epoch: 26, time: 10198.902s, loss: 0.452, train accuracy: 0.828\n","epoch: 26, time: 10209.438s, loss: 1.216, train accuracy: 0.555\n","epoch: 26, time: 10219.978s, loss: 0.434, train accuracy: 0.828\n","epoch: 26, time: 10230.527s, loss: 1.003, train accuracy: 0.609\n","epoch: 26, time: 10241.061s, loss: 1.168, train accuracy: 0.508\n","epoch: 26, time: 10251.590s, loss: 0.425, train accuracy: 0.820\n","epoch: 26, time: 10262.148s, loss: 1.269, train accuracy: 0.547\n","epoch: 26, time: 10272.671s, loss: 1.238, train accuracy: 0.531\n","epoch: 26, time: 10283.193s, loss: 0.337, train accuracy: 0.852\n","epoch: 26, time: 10293.731s, loss: 0.527, train accuracy: 0.781\n","epoch: 26, time: 10304.272s, loss: 0.357, train accuracy: 0.875\n","epoch: 26, time: 10314.807s, loss: 0.515, train accuracy: 0.789\n","epoch: 26, time: 10325.337s, loss: 0.944, train accuracy: 0.648\n","epoch: 26, time: 10335.875s, loss: 0.313, train accuracy: 0.906\n","epoch: 26, time: 10346.414s, loss: 0.316, train accuracy: 0.906\n","epoch: 26, time: 10356.943s, loss: 1.055, train accuracy: 0.602\n","epoch: 26, time: 10367.490s, loss: 1.095, train accuracy: 0.602\n","epoch: 26, time: 10378.034s, loss: 0.461, train accuracy: 0.828\n","epoch: 26, time: 10388.578s, loss: 1.122, train accuracy: 0.602\n","epoch: 26, time: 10399.123s, loss: 1.190, train accuracy: 0.570\n","epoch: 26, time: 10409.658s, loss: 0.458, train accuracy: 0.836\n","epoch: 26, time: 10420.190s, loss: 0.414, train accuracy: 0.867\n","epoch: 26, time: 10430.718s, loss: 0.438, train accuracy: 0.797\n","epoch: 26, time: 10441.255s, loss: 1.236, train accuracy: 0.594\n","epoch: 26, time: 10451.782s, loss: 0.334, train accuracy: 0.875\n","epoch: 26, validation loss: 0.4329477683313366\n","epoch: 27, time: 10464.525s, loss: 0.406, train accuracy: 0.844\n","epoch: 27, time: 10475.046s, loss: 1.149, train accuracy: 0.539\n","epoch: 27, time: 10485.579s, loss: 1.055, train accuracy: 0.609\n","epoch: 27, time: 10496.126s, loss: 0.370, train accuracy: 0.859\n","epoch: 27, time: 10506.659s, loss: 0.519, train accuracy: 0.742\n","epoch: 27, time: 10517.193s, loss: 1.170, train accuracy: 0.555\n","epoch: 27, time: 10527.732s, loss: 1.100, train accuracy: 0.602\n","epoch: 27, time: 10538.270s, loss: 0.428, train accuracy: 0.820\n","epoch: 27, time: 10548.805s, loss: 0.440, train accuracy: 0.859\n","epoch: 27, time: 10559.340s, loss: 0.313, train accuracy: 0.852\n","epoch: 27, time: 10569.874s, loss: 0.321, train accuracy: 0.859\n","epoch: 27, time: 10580.412s, loss: 0.469, train accuracy: 0.828\n","epoch: 27, time: 10590.953s, loss: 0.348, train accuracy: 0.852\n","epoch: 27, time: 10601.500s, loss: 0.349, train accuracy: 0.852\n","epoch: 27, time: 10612.038s, loss: 0.527, train accuracy: 0.797\n","epoch: 27, time: 10622.577s, loss: 1.179, train accuracy: 0.523\n","epoch: 27, time: 10633.115s, loss: 1.099, train accuracy: 0.562\n","epoch: 27, time: 10643.654s, loss: 1.329, train accuracy: 0.477\n","epoch: 27, time: 10654.194s, loss: 0.387, train accuracy: 0.852\n","epoch: 27, time: 10664.733s, loss: 1.321, train accuracy: 0.516\n","epoch: 27, time: 10675.279s, loss: 0.391, train accuracy: 0.836\n","epoch: 27, time: 10685.819s, loss: 1.366, train accuracy: 0.516\n","epoch: 27, time: 10696.365s, loss: 1.097, train accuracy: 0.570\n","epoch: 27, time: 10706.908s, loss: 0.460, train accuracy: 0.852\n","epoch: 27, time: 10717.445s, loss: 1.067, train accuracy: 0.633\n","epoch: 27, time: 10727.989s, loss: 0.332, train accuracy: 0.828\n","epoch: 27, time: 10738.542s, loss: 0.427, train accuracy: 0.844\n","epoch: 27, time: 10749.083s, loss: 1.121, train accuracy: 0.570\n","epoch: 27, time: 10759.619s, loss: 0.371, train accuracy: 0.859\n","epoch: 27, time: 10770.157s, loss: 1.206, train accuracy: 0.562\n","epoch: 27, time: 10780.696s, loss: 0.488, train accuracy: 0.820\n","epoch: 27, time: 10791.258s, loss: 1.204, train accuracy: 0.508\n","epoch: 27, time: 10801.810s, loss: 1.156, train accuracy: 0.562\n","epoch: 27, time: 10812.363s, loss: 0.615, train accuracy: 0.750\n","epoch: 27, time: 10822.896s, loss: 0.409, train accuracy: 0.859\n","epoch: 27, time: 10833.440s, loss: 1.197, train accuracy: 0.578\n","epoch: 27, time: 10843.979s, loss: 1.087, train accuracy: 0.570\n","epoch: 27, time: 10854.527s, loss: 0.461, train accuracy: 0.828\n","epoch: 27, validation loss: 0.43594471115801636\n","epoch: 28, time: 10867.233s, loss: 0.485, train accuracy: 0.836\n","epoch: 28, time: 10877.766s, loss: 1.173, train accuracy: 0.555\n","epoch: 28, time: 10888.284s, loss: 0.445, train accuracy: 0.828\n","epoch: 28, time: 10898.815s, loss: 0.412, train accuracy: 0.836\n","epoch: 28, time: 10909.362s, loss: 1.249, train accuracy: 0.531\n","epoch: 28, time: 10919.915s, loss: 0.466, train accuracy: 0.828\n","epoch: 28, time: 10930.470s, loss: 0.428, train accuracy: 0.812\n","epoch: 28, time: 10940.974s, loss: 1.130, train accuracy: 0.492\n","epoch: 28, time: 10951.489s, loss: 0.547, train accuracy: 0.805\n","epoch: 28, time: 10962.014s, loss: 1.112, train accuracy: 0.570\n","epoch: 28, time: 10972.537s, loss: 1.004, train accuracy: 0.641\n","epoch: 28, time: 10983.068s, loss: 1.138, train accuracy: 0.531\n","epoch: 28, time: 10993.617s, loss: 0.471, train accuracy: 0.859\n","epoch: 28, time: 11004.172s, loss: 1.146, train accuracy: 0.555\n","epoch: 28, time: 11014.723s, loss: 0.517, train accuracy: 0.820\n","epoch: 28, time: 11025.270s, loss: 1.148, train accuracy: 0.570\n","epoch: 28, time: 11035.824s, loss: 1.173, train accuracy: 0.523\n","epoch: 28, time: 11046.370s, loss: 1.203, train accuracy: 0.570\n","epoch: 28, time: 11056.904s, loss: 1.082, train accuracy: 0.586\n","epoch: 28, time: 11067.438s, loss: 1.280, train accuracy: 0.539\n","epoch: 28, time: 11077.973s, loss: 0.373, train accuracy: 0.883\n","epoch: 28, time: 11088.506s, loss: 0.495, train accuracy: 0.828\n","epoch: 28, time: 11099.038s, loss: 0.354, train accuracy: 0.859\n","epoch: 28, time: 11109.567s, loss: 1.110, train accuracy: 0.531\n","epoch: 28, time: 11120.112s, loss: 0.338, train accuracy: 0.875\n","epoch: 28, time: 11130.639s, loss: 0.423, train accuracy: 0.828\n","epoch: 28, time: 11141.176s, loss: 1.070, train accuracy: 0.625\n","epoch: 28, time: 11151.701s, loss: 1.214, train accuracy: 0.539\n","epoch: 28, time: 11162.232s, loss: 1.061, train accuracy: 0.555\n","epoch: 28, time: 11172.760s, loss: 0.309, train accuracy: 0.852\n","epoch: 28, time: 11183.285s, loss: 1.167, train accuracy: 0.570\n","epoch: 28, time: 11193.811s, loss: 1.091, train accuracy: 0.539\n","epoch: 28, time: 11204.340s, loss: 0.388, train accuracy: 0.883\n","epoch: 28, time: 11214.866s, loss: 0.359, train accuracy: 0.883\n","epoch: 28, time: 11225.392s, loss: 0.385, train accuracy: 0.859\n","epoch: 28, time: 11235.931s, loss: 0.433, train accuracy: 0.828\n","epoch: 28, time: 11246.467s, loss: 0.461, train accuracy: 0.797\n","epoch: 28, time: 11257.008s, loss: 1.172, train accuracy: 0.586\n","epoch: 28, validation loss: 0.4357239541722767\n","epoch: 29, time: 11269.725s, loss: 0.337, train accuracy: 0.875\n","epoch: 29, time: 11280.249s, loss: 0.391, train accuracy: 0.844\n","epoch: 29, time: 11290.786s, loss: 0.474, train accuracy: 0.820\n","epoch: 29, time: 11301.315s, loss: 1.113, train accuracy: 0.531\n","epoch: 29, time: 11311.848s, loss: 1.299, train accuracy: 0.547\n","epoch: 29, time: 11322.384s, loss: 1.473, train accuracy: 0.445\n","epoch: 29, time: 11332.924s, loss: 0.358, train accuracy: 0.852\n","epoch: 29, time: 11343.459s, loss: 1.145, train accuracy: 0.539\n","epoch: 29, time: 11354.013s, loss: 0.417, train accuracy: 0.820\n","epoch: 29, time: 11364.559s, loss: 0.442, train accuracy: 0.836\n","epoch: 29, time: 11375.106s, loss: 1.084, train accuracy: 0.594\n","epoch: 29, time: 11385.636s, loss: 0.470, train accuracy: 0.812\n","epoch: 29, time: 11396.183s, loss: 0.372, train accuracy: 0.828\n","epoch: 29, time: 11406.716s, loss: 0.427, train accuracy: 0.820\n","epoch: 29, time: 11417.265s, loss: 1.084, train accuracy: 0.586\n","epoch: 29, time: 11427.812s, loss: 1.128, train accuracy: 0.562\n","epoch: 29, time: 11438.365s, loss: 0.393, train accuracy: 0.828\n","epoch: 29, time: 11448.913s, loss: 0.492, train accuracy: 0.789\n","epoch: 29, time: 11459.465s, loss: 1.049, train accuracy: 0.594\n","epoch: 29, time: 11470.015s, loss: 0.325, train accuracy: 0.875\n","epoch: 29, time: 11480.568s, loss: 0.472, train accuracy: 0.836\n","epoch: 29, time: 11491.103s, loss: 0.394, train accuracy: 0.867\n","epoch: 29, time: 11501.639s, loss: 0.409, train accuracy: 0.844\n","epoch: 29, time: 11512.180s, loss: 1.074, train accuracy: 0.570\n","epoch: 29, time: 11522.714s, loss: 0.343, train accuracy: 0.859\n","epoch: 29, time: 11533.260s, loss: 0.487, train accuracy: 0.773\n","epoch: 29, time: 11543.803s, loss: 1.154, train accuracy: 0.578\n","epoch: 29, time: 11554.342s, loss: 1.020, train accuracy: 0.586\n","epoch: 29, time: 11564.877s, loss: 0.500, train accuracy: 0.812\n","epoch: 29, time: 11575.420s, loss: 1.126, train accuracy: 0.547\n","epoch: 29, time: 11585.944s, loss: 1.022, train accuracy: 0.602\n","epoch: 29, time: 11596.486s, loss: 1.436, train accuracy: 0.430\n","epoch: 29, time: 11607.020s, loss: 1.145, train accuracy: 0.531\n","epoch: 29, time: 11617.544s, loss: 1.092, train accuracy: 0.562\n","epoch: 29, time: 11628.078s, loss: 0.416, train accuracy: 0.828\n","epoch: 29, time: 11638.616s, loss: 1.338, train accuracy: 0.461\n","epoch: 29, time: 11649.154s, loss: 1.066, train accuracy: 0.602\n","epoch: 29, time: 11659.683s, loss: 0.558, train accuracy: 0.773\n","epoch: 29, validation loss: 0.4454693873998707\n","epoch: 30, time: 11672.367s, loss: 1.295, train accuracy: 0.492\n","epoch: 30, time: 11682.888s, loss: 1.000, train accuracy: 0.562\n","epoch: 30, time: 11693.411s, loss: 0.342, train accuracy: 0.898\n","epoch: 30, time: 11703.946s, loss: 1.113, train accuracy: 0.586\n","epoch: 30, time: 11714.472s, loss: 1.333, train accuracy: 0.555\n","epoch: 30, time: 11725.010s, loss: 0.504, train accuracy: 0.844\n","epoch: 30, time: 11735.548s, loss: 0.316, train accuracy: 0.906\n","epoch: 30, time: 11746.090s, loss: 0.958, train accuracy: 0.633\n","epoch: 30, time: 11756.637s, loss: 0.307, train accuracy: 0.898\n","epoch: 30, time: 11767.171s, loss: 1.209, train accuracy: 0.539\n","epoch: 30, time: 11777.711s, loss: 0.259, train accuracy: 0.906\n","epoch: 30, time: 11788.259s, loss: 1.152, train accuracy: 0.516\n","epoch: 30, time: 11798.802s, loss: 0.419, train accuracy: 0.828\n","epoch: 30, time: 11809.341s, loss: 1.152, train accuracy: 0.547\n","epoch: 30, time: 11819.879s, loss: 1.049, train accuracy: 0.570\n","epoch: 30, time: 11830.429s, loss: 1.369, train accuracy: 0.461\n","epoch: 30, time: 11840.969s, loss: 0.451, train accuracy: 0.789\n","epoch: 30, time: 11851.512s, loss: 1.193, train accuracy: 0.508\n","epoch: 30, time: 11862.060s, loss: 0.478, train accuracy: 0.828\n","epoch: 30, time: 11872.602s, loss: 0.399, train accuracy: 0.875\n","epoch: 30, time: 11883.143s, loss: 0.413, train accuracy: 0.859\n","epoch: 30, time: 11893.692s, loss: 0.451, train accuracy: 0.844\n","epoch: 30, time: 11904.227s, loss: 1.080, train accuracy: 0.602\n","epoch: 30, time: 11914.773s, loss: 1.227, train accuracy: 0.531\n","epoch: 30, time: 11925.311s, loss: 1.284, train accuracy: 0.508\n","epoch: 30, time: 11935.848s, loss: 0.388, train accuracy: 0.828\n","epoch: 30, time: 11946.383s, loss: 0.412, train accuracy: 0.805\n","epoch: 30, time: 11956.913s, loss: 1.138, train accuracy: 0.617\n","epoch: 30, time: 11967.446s, loss: 1.061, train accuracy: 0.555\n","epoch: 30, time: 11977.982s, loss: 0.350, train accuracy: 0.859\n","epoch: 30, time: 11988.520s, loss: 0.462, train accuracy: 0.844\n","epoch: 30, time: 11999.047s, loss: 1.305, train accuracy: 0.484\n","epoch: 30, time: 12009.588s, loss: 1.339, train accuracy: 0.461\n","epoch: 30, time: 12020.108s, loss: 1.013, train accuracy: 0.594\n","epoch: 30, time: 12030.645s, loss: 0.286, train accuracy: 0.891\n","epoch: 30, time: 12041.178s, loss: 1.125, train accuracy: 0.594\n","epoch: 30, time: 12051.717s, loss: 1.018, train accuracy: 0.531\n","epoch: 30, time: 12062.245s, loss: 0.469, train accuracy: 0.789\n","epoch: 30, validation loss: 0.43097343348236733\n","epoch: 31, time: 12075.079s, loss: 0.471, train accuracy: 0.820\n","epoch: 31, time: 12085.565s, loss: 0.425, train accuracy: 0.844\n","epoch: 31, time: 12096.064s, loss: 1.097, train accuracy: 0.594\n","epoch: 31, time: 12106.563s, loss: 1.002, train accuracy: 0.578\n","epoch: 31, time: 12117.077s, loss: 0.416, train accuracy: 0.852\n","epoch: 31, time: 12127.598s, loss: 1.325, train accuracy: 0.539\n","epoch: 31, time: 12138.120s, loss: 0.553, train accuracy: 0.781\n","epoch: 31, time: 12148.632s, loss: 1.066, train accuracy: 0.641\n","epoch: 31, time: 12159.160s, loss: 1.170, train accuracy: 0.500\n","epoch: 31, time: 12169.690s, loss: 0.384, train accuracy: 0.859\n","epoch: 31, time: 12180.216s, loss: 1.059, train accuracy: 0.562\n","epoch: 31, time: 12190.739s, loss: 1.006, train accuracy: 0.586\n","epoch: 31, time: 12201.276s, loss: 0.420, train accuracy: 0.812\n","epoch: 31, time: 12211.804s, loss: 1.267, train accuracy: 0.555\n","epoch: 31, time: 12222.331s, loss: 0.472, train accuracy: 0.820\n","epoch: 31, time: 12232.862s, loss: 1.110, train accuracy: 0.539\n","epoch: 31, time: 12243.387s, loss: 1.195, train accuracy: 0.555\n","epoch: 31, time: 12253.918s, loss: 0.328, train accuracy: 0.844\n","epoch: 31, time: 12264.459s, loss: 0.401, train accuracy: 0.891\n","epoch: 31, time: 12274.983s, loss: 0.407, train accuracy: 0.828\n","epoch: 31, time: 12285.525s, loss: 1.215, train accuracy: 0.500\n","epoch: 31, time: 12296.062s, loss: 0.490, train accuracy: 0.867\n","epoch: 31, time: 12306.593s, loss: 0.498, train accuracy: 0.836\n","epoch: 31, time: 12317.124s, loss: 1.126, train accuracy: 0.578\n","epoch: 31, time: 12327.663s, loss: 1.134, train accuracy: 0.617\n","epoch: 31, time: 12338.195s, loss: 1.373, train accuracy: 0.492\n","epoch: 31, time: 12348.734s, loss: 1.020, train accuracy: 0.555\n","epoch: 31, time: 12359.277s, loss: 0.344, train accuracy: 0.883\n","epoch: 31, time: 12369.803s, loss: 1.206, train accuracy: 0.578\n","epoch: 31, time: 12380.338s, loss: 0.327, train accuracy: 0.867\n","epoch: 31, time: 12390.866s, loss: 1.084, train accuracy: 0.570\n","epoch: 31, time: 12401.389s, loss: 0.351, train accuracy: 0.867\n","epoch: 31, time: 12411.932s, loss: 1.309, train accuracy: 0.453\n","epoch: 31, time: 12422.469s, loss: 1.064, train accuracy: 0.570\n","epoch: 31, time: 12433.005s, loss: 0.391, train accuracy: 0.852\n","epoch: 31, time: 12443.536s, loss: 1.270, train accuracy: 0.508\n","epoch: 31, time: 12454.065s, loss: 0.477, train accuracy: 0.781\n","epoch: 31, time: 12464.602s, loss: 0.933, train accuracy: 0.625\n","epoch: 31, validation loss: 0.44731232460373754\n","epoch: 32, time: 12477.312s, loss: 0.502, train accuracy: 0.828\n","epoch: 32, time: 12487.832s, loss: 1.044, train accuracy: 0.602\n","epoch: 32, time: 12498.350s, loss: 1.436, train accuracy: 0.570\n","epoch: 32, time: 12508.869s, loss: 1.222, train accuracy: 0.500\n","epoch: 32, time: 12519.392s, loss: 1.198, train accuracy: 0.539\n","epoch: 32, time: 12529.918s, loss: 1.149, train accuracy: 0.570\n","epoch: 32, time: 12540.452s, loss: 0.380, train accuracy: 0.828\n","epoch: 32, time: 12550.981s, loss: 0.295, train accuracy: 0.906\n","epoch: 32, time: 12561.519s, loss: 0.399, train accuracy: 0.828\n","epoch: 32, time: 12572.054s, loss: 0.967, train accuracy: 0.602\n","epoch: 32, time: 12582.599s, loss: 1.404, train accuracy: 0.453\n","epoch: 32, time: 12593.139s, loss: 1.203, train accuracy: 0.523\n","epoch: 32, time: 12603.688s, loss: 1.137, train accuracy: 0.555\n","epoch: 32, time: 12614.236s, loss: 1.332, train accuracy: 0.445\n","epoch: 32, time: 12624.783s, loss: 1.311, train accuracy: 0.469\n","epoch: 32, time: 12635.350s, loss: 0.405, train accuracy: 0.859\n","epoch: 32, time: 12645.901s, loss: 1.330, train accuracy: 0.508\n","epoch: 32, time: 12656.452s, loss: 1.475, train accuracy: 0.461\n","epoch: 32, time: 12667.006s, loss: 1.074, train accuracy: 0.625\n","epoch: 32, time: 12677.550s, loss: 0.404, train accuracy: 0.859\n","epoch: 32, time: 12688.090s, loss: 0.506, train accuracy: 0.820\n","epoch: 32, time: 12698.645s, loss: 0.376, train accuracy: 0.844\n","epoch: 32, time: 12709.197s, loss: 0.336, train accuracy: 0.828\n","epoch: 32, time: 12719.755s, loss: 0.381, train accuracy: 0.867\n","epoch: 32, time: 12730.288s, loss: 0.357, train accuracy: 0.875\n","epoch: 32, time: 12740.833s, loss: 1.000, train accuracy: 0.602\n","epoch: 32, time: 12751.387s, loss: 0.430, train accuracy: 0.797\n","epoch: 32, time: 12761.938s, loss: 1.080, train accuracy: 0.594\n","epoch: 32, time: 12772.481s, loss: 1.620, train accuracy: 0.445\n","epoch: 32, time: 12783.018s, loss: 1.229, train accuracy: 0.523\n","epoch: 32, time: 12793.567s, loss: 1.112, train accuracy: 0.547\n","epoch: 32, time: 12804.120s, loss: 0.319, train accuracy: 0.883\n","epoch: 32, time: 12814.663s, loss: 0.942, train accuracy: 0.648\n","epoch: 32, time: 12825.211s, loss: 0.498, train accuracy: 0.805\n","epoch: 32, time: 12835.754s, loss: 0.640, train accuracy: 0.812\n","epoch: 32, time: 12846.301s, loss: 1.080, train accuracy: 0.602\n","epoch: 32, time: 12856.839s, loss: 1.273, train accuracy: 0.492\n","epoch: 32, time: 12867.378s, loss: 0.319, train accuracy: 0.891\n","epoch: 32, validation loss: 0.43252058692578316\n","epoch: 33, time: 12880.183s, loss: 1.024, train accuracy: 0.609\n","epoch: 33, time: 12890.695s, loss: 0.495, train accuracy: 0.797\n","epoch: 33, time: 12901.206s, loss: 1.049, train accuracy: 0.562\n","epoch: 33, time: 12911.724s, loss: 0.335, train accuracy: 0.875\n","epoch: 33, time: 12922.246s, loss: 1.198, train accuracy: 0.562\n","epoch: 33, time: 12932.778s, loss: 0.511, train accuracy: 0.797\n","epoch: 33, time: 12943.305s, loss: 1.197, train accuracy: 0.555\n","epoch: 33, time: 12953.830s, loss: 1.062, train accuracy: 0.539\n","epoch: 33, time: 12964.359s, loss: 1.264, train accuracy: 0.516\n","epoch: 33, time: 12974.895s, loss: 0.311, train accuracy: 0.883\n","epoch: 33, time: 12985.422s, loss: 1.160, train accuracy: 0.562\n","epoch: 33, time: 12995.947s, loss: 1.025, train accuracy: 0.586\n","epoch: 33, time: 13006.469s, loss: 0.398, train accuracy: 0.867\n","epoch: 33, time: 13017.000s, loss: 1.078, train accuracy: 0.539\n","epoch: 33, time: 13027.528s, loss: 0.430, train accuracy: 0.797\n","epoch: 33, time: 13038.065s, loss: 0.318, train accuracy: 0.891\n","epoch: 33, time: 13048.593s, loss: 1.332, train accuracy: 0.469\n","epoch: 33, time: 13059.121s, loss: 0.604, train accuracy: 0.805\n","epoch: 33, time: 13069.645s, loss: 1.207, train accuracy: 0.547\n","epoch: 33, time: 13080.165s, loss: 0.513, train accuracy: 0.789\n","epoch: 33, time: 13090.702s, loss: 1.198, train accuracy: 0.523\n","epoch: 33, time: 13101.227s, loss: 1.027, train accuracy: 0.609\n","epoch: 33, time: 13111.763s, loss: 0.448, train accuracy: 0.797\n","epoch: 33, time: 13122.287s, loss: 0.436, train accuracy: 0.805\n","epoch: 33, time: 13132.819s, loss: 0.385, train accuracy: 0.875\n","epoch: 33, time: 13143.344s, loss: 0.332, train accuracy: 0.883\n","epoch: 33, time: 13153.869s, loss: 1.070, train accuracy: 0.594\n","epoch: 33, time: 13164.400s, loss: 0.998, train accuracy: 0.641\n","epoch: 33, time: 13174.928s, loss: 0.481, train accuracy: 0.766\n","epoch: 33, time: 13185.462s, loss: 0.314, train accuracy: 0.867\n","epoch: 33, time: 13195.985s, loss: 0.317, train accuracy: 0.859\n","epoch: 33, time: 13206.516s, loss: 1.097, train accuracy: 0.531\n","epoch: 33, time: 13217.047s, loss: 1.258, train accuracy: 0.508\n","epoch: 33, time: 13227.583s, loss: 0.518, train accuracy: 0.797\n","epoch: 33, time: 13238.115s, loss: 1.180, train accuracy: 0.547\n","epoch: 33, time: 13248.648s, loss: 1.086, train accuracy: 0.531\n","epoch: 33, time: 13259.184s, loss: 1.216, train accuracy: 0.523\n","epoch: 33, time: 13269.728s, loss: 1.170, train accuracy: 0.531\n","epoch: 33, validation loss: 0.4297084819152157\n","epoch: 34, time: 13282.501s, loss: 1.272, train accuracy: 0.523\n","epoch: 34, time: 13293.045s, loss: 0.412, train accuracy: 0.875\n","epoch: 34, time: 13303.583s, loss: 0.402, train accuracy: 0.836\n","epoch: 34, time: 13314.130s, loss: 1.282, train accuracy: 0.539\n","epoch: 34, time: 13324.682s, loss: 0.381, train accuracy: 0.836\n","epoch: 34, time: 13335.231s, loss: 1.401, train accuracy: 0.461\n","epoch: 34, time: 13345.775s, loss: 0.478, train accuracy: 0.805\n","epoch: 34, time: 13356.309s, loss: 0.513, train accuracy: 0.828\n","epoch: 34, time: 13366.853s, loss: 0.451, train accuracy: 0.836\n","epoch: 34, time: 13377.383s, loss: 0.393, train accuracy: 0.875\n","epoch: 34, time: 13387.916s, loss: 1.227, train accuracy: 0.547\n","epoch: 34, time: 13398.447s, loss: 0.414, train accuracy: 0.844\n","epoch: 34, time: 13408.986s, loss: 0.338, train accuracy: 0.836\n","epoch: 34, time: 13419.522s, loss: 0.337, train accuracy: 0.883\n","epoch: 34, time: 13430.053s, loss: 1.191, train accuracy: 0.500\n","epoch: 34, time: 13440.589s, loss: 1.063, train accuracy: 0.562\n","epoch: 34, time: 13451.128s, loss: 0.507, train accuracy: 0.781\n","epoch: 34, time: 13461.666s, loss: 1.212, train accuracy: 0.469\n","epoch: 34, time: 13472.199s, loss: 1.134, train accuracy: 0.516\n","epoch: 34, time: 13482.721s, loss: 0.530, train accuracy: 0.773\n","epoch: 34, time: 13493.253s, loss: 0.389, train accuracy: 0.820\n","epoch: 34, time: 13503.780s, loss: 1.222, train accuracy: 0.578\n","epoch: 34, time: 13514.308s, loss: 1.112, train accuracy: 0.594\n","epoch: 34, time: 13524.840s, loss: 0.465, train accuracy: 0.836\n","epoch: 34, time: 13535.378s, loss: 0.363, train accuracy: 0.875\n","epoch: 34, time: 13545.908s, loss: 0.420, train accuracy: 0.844\n","epoch: 34, time: 13556.462s, loss: 1.201, train accuracy: 0.547\n","epoch: 34, time: 13566.991s, loss: 1.273, train accuracy: 0.492\n","epoch: 34, time: 13577.532s, loss: 1.118, train accuracy: 0.570\n","epoch: 34, time: 13588.071s, loss: 0.348, train accuracy: 0.891\n","epoch: 34, time: 13598.625s, loss: 1.216, train accuracy: 0.516\n","epoch: 34, time: 13609.181s, loss: 0.368, train accuracy: 0.891\n","epoch: 34, time: 13619.734s, loss: 0.465, train accuracy: 0.820\n","epoch: 34, time: 13630.269s, loss: 1.237, train accuracy: 0.539\n","epoch: 34, time: 13640.813s, loss: 0.411, train accuracy: 0.828\n","epoch: 34, time: 13651.371s, loss: 1.377, train accuracy: 0.453\n","epoch: 34, time: 13661.929s, loss: 0.329, train accuracy: 0.852\n","epoch: 34, time: 13672.479s, loss: 0.439, train accuracy: 0.844\n","epoch: 34, validation loss: 0.42905991691261974\n","epoch: 35, time: 13685.363s, loss: 1.020, train accuracy: 0.625\n","epoch: 35, time: 13695.883s, loss: 1.096, train accuracy: 0.609\n","epoch: 35, time: 13706.415s, loss: 1.145, train accuracy: 0.539\n","epoch: 35, time: 13716.958s, loss: 1.295, train accuracy: 0.516\n","epoch: 35, time: 13727.496s, loss: 0.430, train accuracy: 0.844\n","epoch: 35, time: 13738.038s, loss: 1.044, train accuracy: 0.641\n","epoch: 35, time: 13748.578s, loss: 1.104, train accuracy: 0.602\n","epoch: 35, time: 13759.110s, loss: 0.346, train accuracy: 0.906\n","epoch: 35, time: 13769.651s, loss: 1.049, train accuracy: 0.609\n","epoch: 35, time: 13780.189s, loss: 0.327, train accuracy: 0.875\n","epoch: 35, time: 13790.727s, loss: 0.434, train accuracy: 0.805\n","epoch: 35, time: 13801.261s, loss: 1.222, train accuracy: 0.500\n","epoch: 35, time: 13811.800s, loss: 0.445, train accuracy: 0.859\n","epoch: 35, time: 13822.339s, loss: 1.253, train accuracy: 0.547\n","epoch: 35, time: 13832.875s, loss: 1.188, train accuracy: 0.539\n","epoch: 35, time: 13843.413s, loss: 1.252, train accuracy: 0.570\n","epoch: 35, time: 13853.954s, loss: 0.972, train accuracy: 0.609\n","epoch: 35, time: 13864.486s, loss: 1.259, train accuracy: 0.477\n","epoch: 35, time: 13875.021s, loss: 1.263, train accuracy: 0.508\n","epoch: 35, time: 13885.553s, loss: 0.536, train accuracy: 0.781\n","epoch: 35, time: 13896.082s, loss: 0.436, train accuracy: 0.867\n","epoch: 35, time: 13906.607s, loss: 1.091, train accuracy: 0.586\n","epoch: 35, time: 13917.142s, loss: 1.383, train accuracy: 0.445\n","epoch: 35, time: 13927.683s, loss: 0.515, train accuracy: 0.812\n","epoch: 35, time: 13938.209s, loss: 0.387, train accuracy: 0.820\n","epoch: 35, time: 13948.741s, loss: 0.380, train accuracy: 0.828\n","epoch: 35, time: 13959.279s, loss: 0.340, train accuracy: 0.875\n","epoch: 35, time: 13969.811s, loss: 1.348, train accuracy: 0.445\n","epoch: 35, time: 13980.357s, loss: 0.335, train accuracy: 0.867\n","epoch: 35, time: 13990.891s, loss: 1.156, train accuracy: 0.508\n","epoch: 35, time: 14001.432s, loss: 0.483, train accuracy: 0.844\n","epoch: 35, time: 14011.974s, loss: 1.279, train accuracy: 0.570\n","epoch: 35, time: 14022.518s, loss: 0.487, train accuracy: 0.828\n","epoch: 35, time: 14033.053s, loss: 0.455, train accuracy: 0.812\n","epoch: 35, time: 14043.581s, loss: 0.437, train accuracy: 0.859\n","epoch: 35, time: 14054.116s, loss: 0.362, train accuracy: 0.891\n","epoch: 35, time: 14064.650s, loss: 0.358, train accuracy: 0.914\n","epoch: 35, time: 14075.189s, loss: 0.369, train accuracy: 0.867\n","epoch: 35, validation loss: 0.44538662009147695\n","epoch: 36, time: 14087.994s, loss: 1.326, train accuracy: 0.484\n","epoch: 36, time: 14098.510s, loss: 0.398, train accuracy: 0.844\n","epoch: 36, time: 14109.032s, loss: 0.459, train accuracy: 0.828\n","epoch: 36, time: 14119.559s, loss: 0.413, train accuracy: 0.828\n","epoch: 36, time: 14130.075s, loss: 1.285, train accuracy: 0.531\n","epoch: 36, time: 14140.597s, loss: 1.179, train accuracy: 0.508\n","epoch: 36, time: 14151.121s, loss: 0.369, train accuracy: 0.859\n","epoch: 36, time: 14161.636s, loss: 0.403, train accuracy: 0.875\n","epoch: 36, time: 14172.162s, loss: 1.426, train accuracy: 0.430\n","epoch: 36, time: 14182.687s, loss: 0.555, train accuracy: 0.820\n","epoch: 36, time: 14193.217s, loss: 1.374, train accuracy: 0.508\n","epoch: 36, time: 14203.751s, loss: 0.432, train accuracy: 0.852\n","epoch: 36, time: 14214.282s, loss: 1.159, train accuracy: 0.570\n","epoch: 36, time: 14224.832s, loss: 1.110, train accuracy: 0.500\n","epoch: 36, time: 14235.367s, loss: 0.438, train accuracy: 0.836\n","epoch: 36, time: 14245.899s, loss: 1.125, train accuracy: 0.555\n","epoch: 36, time: 14256.436s, loss: 0.448, train accuracy: 0.781\n","epoch: 36, time: 14266.960s, loss: 1.044, train accuracy: 0.594\n","epoch: 36, time: 14277.499s, loss: 0.478, train accuracy: 0.820\n","epoch: 36, time: 14288.045s, loss: 1.083, train accuracy: 0.570\n","epoch: 36, time: 14298.585s, loss: 0.333, train accuracy: 0.883\n","epoch: 36, time: 14309.130s, loss: 0.365, train accuracy: 0.875\n","epoch: 36, time: 14319.656s, loss: 1.204, train accuracy: 0.578\n","epoch: 36, time: 14330.186s, loss: 0.448, train accuracy: 0.828\n","epoch: 36, time: 14340.724s, loss: 1.172, train accuracy: 0.586\n","epoch: 36, time: 14351.255s, loss: 0.459, train accuracy: 0.820\n","epoch: 36, time: 14361.779s, loss: 1.222, train accuracy: 0.531\n","epoch: 36, time: 14372.311s, loss: 0.390, train accuracy: 0.852\n","epoch: 36, time: 14382.847s, loss: 1.246, train accuracy: 0.508\n","epoch: 36, time: 14393.368s, loss: 1.137, train accuracy: 0.516\n","epoch: 36, time: 14403.904s, loss: 0.442, train accuracy: 0.805\n","epoch: 36, time: 14414.434s, loss: 0.490, train accuracy: 0.820\n","epoch: 36, time: 14424.968s, loss: 0.468, train accuracy: 0.836\n","epoch: 36, time: 14435.493s, loss: 0.311, train accuracy: 0.883\n","epoch: 36, time: 14446.020s, loss: 1.219, train accuracy: 0.508\n","epoch: 36, time: 14456.538s, loss: 0.399, train accuracy: 0.859\n","epoch: 36, time: 14467.067s, loss: 0.382, train accuracy: 0.844\n","epoch: 36, time: 14477.592s, loss: 0.411, train accuracy: 0.836\n","epoch: 36, validation loss: 0.42533898706248063\n","epoch: 37, time: 14490.404s, loss: 1.159, train accuracy: 0.539\n","epoch: 37, time: 14500.928s, loss: 0.987, train accuracy: 0.594\n","epoch: 37, time: 14511.459s, loss: 0.436, train accuracy: 0.805\n","epoch: 37, time: 14522.000s, loss: 1.278, train accuracy: 0.500\n","epoch: 37, time: 14532.560s, loss: 1.069, train accuracy: 0.547\n","epoch: 37, time: 14543.116s, loss: 1.124, train accuracy: 0.555\n","epoch: 37, time: 14553.641s, loss: 0.443, train accuracy: 0.844\n","epoch: 37, time: 14564.182s, loss: 0.348, train accuracy: 0.859\n","epoch: 37, time: 14574.719s, loss: 1.171, train accuracy: 0.539\n","epoch: 37, time: 14585.270s, loss: 1.266, train accuracy: 0.523\n","epoch: 37, time: 14595.823s, loss: 1.203, train accuracy: 0.531\n","epoch: 37, time: 14606.375s, loss: 1.226, train accuracy: 0.516\n","epoch: 37, time: 14616.932s, loss: 0.962, train accuracy: 0.562\n","epoch: 37, time: 14627.468s, loss: 1.270, train accuracy: 0.500\n","epoch: 37, time: 14637.996s, loss: 1.360, train accuracy: 0.500\n","epoch: 37, time: 14648.524s, loss: 0.343, train accuracy: 0.898\n","epoch: 37, time: 14659.056s, loss: 1.330, train accuracy: 0.500\n","epoch: 37, time: 14669.580s, loss: 0.351, train accuracy: 0.875\n","epoch: 37, time: 14680.117s, loss: 0.960, train accuracy: 0.625\n","epoch: 37, time: 14690.647s, loss: 1.319, train accuracy: 0.477\n","epoch: 37, time: 14701.175s, loss: 0.435, train accuracy: 0.828\n","epoch: 37, time: 14711.718s, loss: 1.077, train accuracy: 0.461\n","epoch: 37, time: 14722.260s, loss: 1.058, train accuracy: 0.609\n","epoch: 37, time: 14732.819s, loss: 1.047, train accuracy: 0.633\n","epoch: 37, time: 14743.372s, loss: 1.144, train accuracy: 0.555\n","epoch: 37, time: 14753.923s, loss: 0.403, train accuracy: 0.836\n","epoch: 37, time: 14764.463s, loss: 0.455, train accuracy: 0.852\n","epoch: 37, time: 14775.013s, loss: 1.106, train accuracy: 0.555\n","epoch: 37, time: 14785.564s, loss: 1.165, train accuracy: 0.578\n","epoch: 37, time: 14796.114s, loss: 0.537, train accuracy: 0.805\n","epoch: 37, time: 14806.673s, loss: 1.168, train accuracy: 0.562\n","epoch: 37, time: 14817.256s, loss: 1.224, train accuracy: 0.547\n","epoch: 37, time: 14827.825s, loss: 0.388, train accuracy: 0.836\n","epoch: 37, time: 14838.397s, loss: 1.211, train accuracy: 0.539\n","epoch: 37, time: 14848.966s, loss: 0.435, train accuracy: 0.859\n","epoch: 37, time: 14859.520s, loss: 0.403, train accuracy: 0.852\n","epoch: 37, time: 14870.081s, loss: 1.323, train accuracy: 0.531\n","epoch: 37, time: 14880.638s, loss: 0.398, train accuracy: 0.820\n","epoch: 37, validation loss: 0.42273000365635477\n","epoch: 38, time: 14893.701s, loss: 0.524, train accuracy: 0.773\n","epoch: 38, time: 14904.232s, loss: 0.386, train accuracy: 0.875\n","epoch: 38, time: 14914.757s, loss: 1.215, train accuracy: 0.555\n","epoch: 38, time: 14925.289s, loss: 1.169, train accuracy: 0.547\n","epoch: 38, time: 14935.824s, loss: 1.148, train accuracy: 0.578\n","epoch: 38, time: 14946.367s, loss: 0.384, train accuracy: 0.820\n","epoch: 38, time: 14956.924s, loss: 0.407, train accuracy: 0.844\n","epoch: 38, time: 14967.485s, loss: 0.414, train accuracy: 0.812\n","epoch: 38, time: 14978.038s, loss: 1.169, train accuracy: 0.516\n","epoch: 38, time: 14988.592s, loss: 0.391, train accuracy: 0.859\n","epoch: 38, time: 14999.140s, loss: 0.275, train accuracy: 0.875\n","epoch: 38, time: 15009.692s, loss: 0.504, train accuracy: 0.820\n","epoch: 38, time: 15020.239s, loss: 0.463, train accuracy: 0.805\n","epoch: 38, time: 15030.803s, loss: 1.230, train accuracy: 0.562\n","epoch: 38, time: 15041.350s, loss: 1.209, train accuracy: 0.586\n","epoch: 38, time: 15051.897s, loss: 1.203, train accuracy: 0.555\n","epoch: 38, time: 15062.454s, loss: 0.383, train accuracy: 0.883\n","epoch: 38, time: 15073.017s, loss: 1.231, train accuracy: 0.523\n","epoch: 38, time: 15083.572s, loss: 0.519, train accuracy: 0.805\n","epoch: 38, time: 15094.130s, loss: 0.418, train accuracy: 0.859\n","epoch: 38, time: 15104.687s, loss: 0.468, train accuracy: 0.844\n","epoch: 38, time: 15115.234s, loss: 1.124, train accuracy: 0.547\n","epoch: 38, time: 15125.782s, loss: 0.439, train accuracy: 0.828\n","epoch: 38, time: 15136.324s, loss: 0.436, train accuracy: 0.789\n","epoch: 38, time: 15146.882s, loss: 0.437, train accuracy: 0.836\n","epoch: 38, time: 15157.440s, loss: 1.133, train accuracy: 0.547\n","epoch: 38, time: 15167.986s, loss: 1.054, train accuracy: 0.578\n","epoch: 38, time: 15178.530s, loss: 0.398, train accuracy: 0.844\n","epoch: 38, time: 15189.078s, loss: 1.176, train accuracy: 0.562\n","epoch: 38, time: 15199.623s, loss: 0.490, train accuracy: 0.828\n","epoch: 38, time: 15210.178s, loss: 0.406, train accuracy: 0.852\n","epoch: 38, time: 15220.727s, loss: 1.153, train accuracy: 0.570\n","epoch: 38, time: 15231.291s, loss: 1.140, train accuracy: 0.602\n","epoch: 38, time: 15241.848s, loss: 0.424, train accuracy: 0.828\n","epoch: 38, time: 15252.419s, loss: 1.129, train accuracy: 0.531\n","epoch: 38, time: 15262.968s, loss: 0.416, train accuracy: 0.852\n","epoch: 38, time: 15273.523s, loss: 0.441, train accuracy: 0.867\n","epoch: 38, time: 15284.071s, loss: 1.165, train accuracy: 0.570\n","epoch: 38, validation loss: 0.445811583225661\n","epoch: 39, time: 15296.782s, loss: 0.465, train accuracy: 0.789\n","epoch: 39, time: 15307.312s, loss: 1.089, train accuracy: 0.531\n","epoch: 39, time: 15317.844s, loss: 0.398, train accuracy: 0.820\n","epoch: 39, time: 15328.376s, loss: 0.442, train accuracy: 0.812\n","epoch: 39, time: 15338.907s, loss: 0.438, train accuracy: 0.828\n","epoch: 39, time: 15349.426s, loss: 1.156, train accuracy: 0.523\n","epoch: 39, time: 15359.957s, loss: 0.393, train accuracy: 0.859\n","epoch: 39, time: 15370.482s, loss: 1.166, train accuracy: 0.570\n","epoch: 39, time: 15381.004s, loss: 1.395, train accuracy: 0.492\n","epoch: 39, time: 15391.543s, loss: 1.087, train accuracy: 0.547\n","epoch: 39, time: 15402.084s, loss: 0.319, train accuracy: 0.883\n","epoch: 39, time: 15412.609s, loss: 1.224, train accuracy: 0.516\n","epoch: 39, time: 15423.141s, loss: 0.418, train accuracy: 0.828\n","epoch: 39, time: 15433.671s, loss: 0.354, train accuracy: 0.883\n","epoch: 39, time: 15444.208s, loss: 1.047, train accuracy: 0.586\n","epoch: 39, time: 15454.749s, loss: 0.286, train accuracy: 0.906\n","epoch: 39, time: 15465.301s, loss: 1.198, train accuracy: 0.570\n","epoch: 39, time: 15475.833s, loss: 1.057, train accuracy: 0.539\n","epoch: 39, time: 15486.376s, loss: 0.454, train accuracy: 0.836\n","epoch: 39, time: 15496.904s, loss: 0.350, train accuracy: 0.891\n","epoch: 39, time: 15507.437s, loss: 0.303, train accuracy: 0.891\n","epoch: 39, time: 15517.971s, loss: 1.096, train accuracy: 0.594\n","epoch: 39, time: 15528.513s, loss: 1.111, train accuracy: 0.570\n","epoch: 39, time: 15539.055s, loss: 0.502, train accuracy: 0.805\n","epoch: 39, time: 15549.599s, loss: 0.372, train accuracy: 0.844\n","epoch: 39, time: 15560.126s, loss: 0.299, train accuracy: 0.898\n","epoch: 39, time: 15570.651s, loss: 0.473, train accuracy: 0.836\n","epoch: 39, time: 15581.185s, loss: 0.382, train accuracy: 0.852\n","epoch: 39, time: 15591.713s, loss: 1.066, train accuracy: 0.555\n","epoch: 39, time: 15602.255s, loss: 1.308, train accuracy: 0.484\n","epoch: 39, time: 15612.789s, loss: 0.415, train accuracy: 0.844\n","epoch: 39, time: 15623.332s, loss: 0.406, train accuracy: 0.820\n","epoch: 39, time: 15633.863s, loss: 0.521, train accuracy: 0.789\n","epoch: 39, time: 15644.399s, loss: 0.428, train accuracy: 0.828\n","epoch: 39, time: 15654.931s, loss: 0.427, train accuracy: 0.867\n","epoch: 39, time: 15665.458s, loss: 0.464, train accuracy: 0.820\n","epoch: 39, time: 15675.992s, loss: 1.249, train accuracy: 0.508\n","epoch: 39, time: 15686.516s, loss: 0.363, train accuracy: 0.852\n","epoch: 39, validation loss: 0.42612892198664293\n","epoch: 40, time: 15699.283s, loss: 1.311, train accuracy: 0.523\n","epoch: 40, time: 15709.791s, loss: 1.197, train accuracy: 0.539\n","epoch: 40, time: 15720.311s, loss: 0.366, train accuracy: 0.875\n","epoch: 40, time: 15730.842s, loss: 1.561, train accuracy: 0.492\n","epoch: 40, time: 15741.359s, loss: 1.162, train accuracy: 0.547\n","epoch: 40, time: 15751.893s, loss: 1.171, train accuracy: 0.508\n","epoch: 40, time: 15762.423s, loss: 0.318, train accuracy: 0.906\n","epoch: 40, time: 15772.982s, loss: 0.443, train accuracy: 0.836\n","epoch: 40, time: 15783.542s, loss: 0.414, train accuracy: 0.875\n","epoch: 40, time: 15794.086s, loss: 1.090, train accuracy: 0.570\n","epoch: 40, time: 15804.633s, loss: 0.481, train accuracy: 0.797\n","epoch: 40, time: 15815.179s, loss: 1.038, train accuracy: 0.578\n","epoch: 40, time: 15825.727s, loss: 0.378, train accuracy: 0.867\n","epoch: 40, time: 15836.278s, loss: 1.161, train accuracy: 0.531\n","epoch: 40, time: 15846.822s, loss: 0.505, train accuracy: 0.844\n","epoch: 40, time: 15857.376s, loss: 0.486, train accuracy: 0.836\n","epoch: 40, time: 15867.920s, loss: 1.375, train accuracy: 0.477\n","epoch: 40, time: 15878.477s, loss: 0.400, train accuracy: 0.836\n","epoch: 40, time: 15889.027s, loss: 0.319, train accuracy: 0.859\n","epoch: 40, time: 15899.574s, loss: 1.133, train accuracy: 0.609\n","epoch: 40, time: 15910.115s, loss: 0.447, train accuracy: 0.812\n","epoch: 40, time: 15920.653s, loss: 1.045, train accuracy: 0.594\n","epoch: 40, time: 15931.197s, loss: 0.484, train accuracy: 0.805\n","epoch: 40, time: 15941.740s, loss: 0.417, train accuracy: 0.867\n","epoch: 40, time: 15952.274s, loss: 0.974, train accuracy: 0.625\n","epoch: 40, time: 15962.808s, loss: 1.205, train accuracy: 0.555\n","epoch: 40, time: 15973.361s, loss: 0.376, train accuracy: 0.859\n","epoch: 40, time: 15983.897s, loss: 1.187, train accuracy: 0.562\n","epoch: 40, time: 15994.436s, loss: 0.418, train accuracy: 0.820\n","epoch: 40, time: 16004.965s, loss: 1.163, train accuracy: 0.555\n","epoch: 40, time: 16015.503s, loss: 1.051, train accuracy: 0.609\n","epoch: 40, time: 16026.032s, loss: 0.337, train accuracy: 0.875\n","epoch: 40, time: 16036.580s, loss: 0.989, train accuracy: 0.633\n","epoch: 40, time: 16047.115s, loss: 1.243, train accuracy: 0.508\n","epoch: 40, time: 16057.650s, loss: 1.084, train accuracy: 0.625\n","epoch: 40, time: 16068.195s, loss: 1.231, train accuracy: 0.562\n","epoch: 40, time: 16078.742s, loss: 0.505, train accuracy: 0.836\n","epoch: 40, time: 16089.294s, loss: 0.329, train accuracy: 0.875\n","epoch: 40, validation loss: 0.44066582747232685\n","epoch: 41, time: 16102.006s, loss: 0.294, train accuracy: 0.891\n","epoch: 41, time: 16112.526s, loss: 0.466, train accuracy: 0.805\n","epoch: 41, time: 16123.049s, loss: 0.492, train accuracy: 0.852\n","epoch: 41, time: 16133.575s, loss: 1.360, train accuracy: 0.508\n","epoch: 41, time: 16144.100s, loss: 0.388, train accuracy: 0.812\n","epoch: 41, time: 16154.634s, loss: 0.414, train accuracy: 0.828\n","epoch: 41, time: 16165.158s, loss: 1.068, train accuracy: 0.602\n","epoch: 41, time: 16175.692s, loss: 0.489, train accuracy: 0.828\n","epoch: 41, time: 16186.227s, loss: 0.367, train accuracy: 0.844\n","epoch: 41, time: 16196.763s, loss: 1.294, train accuracy: 0.516\n","epoch: 41, time: 16207.293s, loss: 1.414, train accuracy: 0.453\n","epoch: 41, time: 16217.821s, loss: 1.189, train accuracy: 0.531\n","epoch: 41, time: 16228.357s, loss: 0.386, train accuracy: 0.805\n","epoch: 41, time: 16238.898s, loss: 0.484, train accuracy: 0.836\n","epoch: 41, time: 16249.429s, loss: 1.104, train accuracy: 0.539\n","epoch: 41, time: 16259.968s, loss: 1.299, train accuracy: 0.484\n","epoch: 41, time: 16270.517s, loss: 1.290, train accuracy: 0.500\n","epoch: 41, time: 16281.044s, loss: 1.302, train accuracy: 0.531\n","epoch: 41, time: 16291.577s, loss: 0.352, train accuracy: 0.898\n","epoch: 41, time: 16302.107s, loss: 0.435, train accuracy: 0.836\n","epoch: 41, time: 16312.638s, loss: 1.368, train accuracy: 0.484\n","epoch: 41, time: 16323.179s, loss: 0.396, train accuracy: 0.852\n","epoch: 41, time: 16333.707s, loss: 0.548, train accuracy: 0.773\n","epoch: 41, time: 16344.235s, loss: 0.405, train accuracy: 0.836\n","epoch: 41, time: 16354.769s, loss: 1.132, train accuracy: 0.578\n","epoch: 41, time: 16365.298s, loss: 1.175, train accuracy: 0.562\n","epoch: 41, time: 16375.830s, loss: 0.480, train accuracy: 0.852\n","epoch: 41, time: 16386.380s, loss: 0.468, train accuracy: 0.836\n","epoch: 41, time: 16396.918s, loss: 1.524, train accuracy: 0.492\n","epoch: 41, time: 16407.447s, loss: 0.384, train accuracy: 0.875\n","epoch: 41, time: 16417.988s, loss: 1.222, train accuracy: 0.586\n","epoch: 41, time: 16428.536s, loss: 0.376, train accuracy: 0.852\n","epoch: 41, time: 16439.067s, loss: 0.290, train accuracy: 0.875\n","epoch: 41, time: 16449.603s, loss: 1.107, train accuracy: 0.594\n","epoch: 41, time: 16460.141s, loss: 0.486, train accuracy: 0.828\n","epoch: 41, time: 16470.671s, loss: 0.388, train accuracy: 0.875\n","epoch: 41, time: 16481.211s, loss: 1.274, train accuracy: 0.555\n","epoch: 41, time: 16491.754s, loss: 1.137, train accuracy: 0.516\n","epoch: 41, validation loss: 0.4462760562645093\n","epoch: 42, time: 16504.468s, loss: 0.465, train accuracy: 0.805\n","epoch: 42, time: 16514.996s, loss: 1.186, train accuracy: 0.516\n","epoch: 42, time: 16525.523s, loss: 0.435, train accuracy: 0.844\n","epoch: 42, time: 16536.049s, loss: 0.413, train accuracy: 0.828\n","epoch: 42, time: 16546.586s, loss: 0.414, train accuracy: 0.828\n","epoch: 42, time: 16557.119s, loss: 0.544, train accuracy: 0.766\n","epoch: 42, time: 16567.646s, loss: 0.405, train accuracy: 0.820\n","epoch: 42, time: 16578.189s, loss: 1.040, train accuracy: 0.609\n","epoch: 42, time: 16588.725s, loss: 0.351, train accuracy: 0.859\n","epoch: 42, time: 16599.260s, loss: 1.212, train accuracy: 0.523\n","epoch: 42, time: 16609.792s, loss: 1.306, train accuracy: 0.531\n","epoch: 42, time: 16620.335s, loss: 0.436, train accuracy: 0.859\n","epoch: 42, time: 16630.868s, loss: 1.020, train accuracy: 0.625\n","epoch: 42, time: 16641.407s, loss: 1.554, train accuracy: 0.461\n","epoch: 42, time: 16651.945s, loss: 0.393, train accuracy: 0.859\n","epoch: 42, time: 16662.486s, loss: 1.501, train accuracy: 0.562\n","epoch: 42, time: 16673.043s, loss: 1.112, train accuracy: 0.578\n","epoch: 42, time: 16683.588s, loss: 1.109, train accuracy: 0.570\n","epoch: 42, time: 16694.119s, loss: 1.214, train accuracy: 0.586\n","epoch: 42, time: 16704.668s, loss: 1.091, train accuracy: 0.562\n","epoch: 42, time: 16715.215s, loss: 1.448, train accuracy: 0.453\n","epoch: 42, time: 16725.750s, loss: 0.453, train accuracy: 0.859\n","epoch: 42, time: 16736.291s, loss: 0.465, train accuracy: 0.812\n","epoch: 42, time: 16746.829s, loss: 1.069, train accuracy: 0.578\n","epoch: 42, time: 16757.365s, loss: 1.079, train accuracy: 0.609\n","epoch: 42, time: 16767.895s, loss: 1.317, train accuracy: 0.492\n","epoch: 42, time: 16778.446s, loss: 1.104, train accuracy: 0.570\n","epoch: 42, time: 16788.975s, loss: 1.215, train accuracy: 0.516\n","epoch: 42, time: 16799.501s, loss: 0.481, train accuracy: 0.828\n","epoch: 42, time: 16810.033s, loss: 1.300, train accuracy: 0.547\n","epoch: 42, time: 16820.560s, loss: 0.464, train accuracy: 0.828\n","epoch: 42, time: 16831.085s, loss: 1.101, train accuracy: 0.594\n","epoch: 42, time: 16841.609s, loss: 1.249, train accuracy: 0.539\n","epoch: 42, time: 16852.136s, loss: 1.186, train accuracy: 0.570\n","epoch: 42, time: 16862.659s, loss: 1.180, train accuracy: 0.516\n","epoch: 42, time: 16873.175s, loss: 0.381, train accuracy: 0.867\n","epoch: 42, time: 16883.712s, loss: 0.399, train accuracy: 0.836\n","epoch: 42, time: 16894.227s, loss: 0.475, train accuracy: 0.805\n","epoch: 42, validation loss: 0.4287994122073086\n","epoch: 43, time: 16907.030s, loss: 0.389, train accuracy: 0.875\n","epoch: 43, time: 16917.544s, loss: 0.401, train accuracy: 0.828\n","epoch: 43, time: 16928.064s, loss: 1.135, train accuracy: 0.516\n","epoch: 43, time: 16938.568s, loss: 0.619, train accuracy: 0.773\n","epoch: 43, time: 16949.071s, loss: 0.354, train accuracy: 0.867\n","epoch: 43, time: 16959.586s, loss: 0.386, train accuracy: 0.844\n","epoch: 43, time: 16970.102s, loss: 1.317, train accuracy: 0.484\n","epoch: 43, time: 16980.614s, loss: 0.380, train accuracy: 0.836\n","epoch: 43, time: 16991.144s, loss: 0.406, train accuracy: 0.859\n","epoch: 43, time: 17001.673s, loss: 0.257, train accuracy: 0.914\n","epoch: 43, time: 17012.208s, loss: 0.421, train accuracy: 0.820\n","epoch: 43, time: 17022.760s, loss: 1.009, train accuracy: 0.555\n","epoch: 43, time: 17033.304s, loss: 0.391, train accuracy: 0.859\n","epoch: 43, time: 17043.849s, loss: 0.383, train accuracy: 0.836\n","epoch: 43, time: 17054.390s, loss: 1.383, train accuracy: 0.484\n","epoch: 43, time: 17064.928s, loss: 0.486, train accuracy: 0.812\n","epoch: 43, time: 17075.456s, loss: 1.136, train accuracy: 0.555\n","epoch: 43, time: 17085.995s, loss: 0.476, train accuracy: 0.797\n","epoch: 43, time: 17096.518s, loss: 1.030, train accuracy: 0.586\n","epoch: 43, time: 17107.033s, loss: 1.061, train accuracy: 0.555\n","epoch: 43, time: 17117.557s, loss: 0.379, train accuracy: 0.898\n","epoch: 43, time: 17128.079s, loss: 0.431, train accuracy: 0.852\n","epoch: 43, time: 17138.598s, loss: 1.175, train accuracy: 0.578\n","epoch: 43, time: 17149.125s, loss: 0.529, train accuracy: 0.820\n","epoch: 43, time: 17159.645s, loss: 1.228, train accuracy: 0.531\n","epoch: 43, time: 17170.164s, loss: 1.117, train accuracy: 0.570\n","epoch: 43, time: 17180.689s, loss: 1.115, train accuracy: 0.609\n","epoch: 43, time: 17191.217s, loss: 0.509, train accuracy: 0.820\n","epoch: 43, time: 17201.747s, loss: 1.457, train accuracy: 0.484\n","epoch: 43, time: 17212.274s, loss: 0.431, train accuracy: 0.812\n","epoch: 43, time: 17222.814s, loss: 0.430, train accuracy: 0.820\n","epoch: 43, time: 17233.352s, loss: 0.490, train accuracy: 0.789\n","epoch: 43, time: 17243.893s, loss: 0.996, train accuracy: 0.594\n","epoch: 43, time: 17254.441s, loss: 1.112, train accuracy: 0.578\n","epoch: 43, time: 17264.977s, loss: 0.505, train accuracy: 0.812\n","epoch: 43, time: 17275.522s, loss: 1.277, train accuracy: 0.523\n","epoch: 43, time: 17286.067s, loss: 0.380, train accuracy: 0.859\n","epoch: 43, time: 17296.610s, loss: 1.315, train accuracy: 0.516\n","epoch: 43, validation loss: 0.4389288458488643\n","epoch: 44, time: 17309.379s, loss: 0.462, train accuracy: 0.852\n","epoch: 44, time: 17319.903s, loss: 1.106, train accuracy: 0.586\n","epoch: 44, time: 17330.438s, loss: 0.379, train accuracy: 0.836\n","epoch: 44, time: 17340.957s, loss: 0.399, train accuracy: 0.836\n","epoch: 44, time: 17351.488s, loss: 1.061, train accuracy: 0.602\n","epoch: 44, time: 17362.010s, loss: 0.466, train accuracy: 0.844\n","epoch: 44, time: 17372.541s, loss: 0.403, train accuracy: 0.836\n","epoch: 44, time: 17383.072s, loss: 0.436, train accuracy: 0.836\n","epoch: 44, time: 17393.595s, loss: 1.324, train accuracy: 0.523\n","epoch: 44, time: 17404.122s, loss: 0.455, train accuracy: 0.820\n","epoch: 44, time: 17414.653s, loss: 1.226, train accuracy: 0.492\n","epoch: 44, time: 17425.178s, loss: 0.407, train accuracy: 0.875\n","epoch: 44, time: 17435.711s, loss: 1.310, train accuracy: 0.500\n","epoch: 44, time: 17446.242s, loss: 1.153, train accuracy: 0.523\n","epoch: 44, time: 17456.776s, loss: 0.977, train accuracy: 0.578\n","epoch: 44, time: 17467.306s, loss: 0.385, train accuracy: 0.891\n","epoch: 44, time: 17477.840s, loss: 1.137, train accuracy: 0.578\n","epoch: 44, time: 17488.368s, loss: 0.430, train accuracy: 0.844\n","epoch: 44, time: 17498.906s, loss: 1.172, train accuracy: 0.562\n","epoch: 44, time: 17509.431s, loss: 0.451, train accuracy: 0.820\n","epoch: 44, time: 17519.958s, loss: 0.310, train accuracy: 0.867\n","epoch: 44, time: 17530.496s, loss: 0.450, train accuracy: 0.828\n","epoch: 44, time: 17541.026s, loss: 1.397, train accuracy: 0.516\n","epoch: 44, time: 17551.553s, loss: 0.401, train accuracy: 0.844\n","epoch: 44, time: 17562.096s, loss: 1.120, train accuracy: 0.562\n","epoch: 44, time: 17572.620s, loss: 1.182, train accuracy: 0.539\n","epoch: 44, time: 17583.138s, loss: 0.380, train accuracy: 0.867\n","epoch: 44, time: 17593.661s, loss: 1.225, train accuracy: 0.477\n","epoch: 44, time: 17604.188s, loss: 0.396, train accuracy: 0.883\n","epoch: 44, time: 17614.713s, loss: 1.178, train accuracy: 0.508\n","epoch: 44, time: 17625.252s, loss: 0.445, train accuracy: 0.797\n","epoch: 44, time: 17635.783s, loss: 0.446, train accuracy: 0.805\n","epoch: 44, time: 17646.324s, loss: 1.399, train accuracy: 0.492\n","epoch: 44, time: 17656.860s, loss: 0.426, train accuracy: 0.812\n","epoch: 44, time: 17667.383s, loss: 1.154, train accuracy: 0.555\n","epoch: 44, time: 17677.921s, loss: 1.184, train accuracy: 0.562\n","epoch: 44, time: 17688.454s, loss: 1.125, train accuracy: 0.562\n","epoch: 44, time: 17698.999s, loss: 1.139, train accuracy: 0.570\n","epoch: 44, validation loss: 0.4496808561689056\n","epoch: 45, time: 17711.737s, loss: 0.419, train accuracy: 0.812\n","epoch: 45, time: 17722.251s, loss: 0.985, train accuracy: 0.586\n","epoch: 45, time: 17732.769s, loss: 1.004, train accuracy: 0.578\n","epoch: 45, time: 17743.296s, loss: 0.402, train accuracy: 0.875\n","epoch: 45, time: 17753.824s, loss: 1.095, train accuracy: 0.555\n","epoch: 45, time: 17764.348s, loss: 0.353, train accuracy: 0.891\n","epoch: 45, time: 17774.884s, loss: 1.091, train accuracy: 0.602\n","epoch: 45, time: 17785.412s, loss: 1.247, train accuracy: 0.469\n","epoch: 45, time: 17795.945s, loss: 0.424, train accuracy: 0.828\n","epoch: 45, time: 17806.474s, loss: 0.536, train accuracy: 0.820\n","epoch: 45, time: 17817.008s, loss: 0.338, train accuracy: 0.875\n","epoch: 45, time: 17827.529s, loss: 1.350, train accuracy: 0.453\n","epoch: 45, time: 17838.058s, loss: 1.317, train accuracy: 0.508\n","epoch: 45, time: 17848.588s, loss: 1.133, train accuracy: 0.547\n","epoch: 45, time: 17859.119s, loss: 1.293, train accuracy: 0.523\n","epoch: 45, time: 17869.649s, loss: 1.002, train accuracy: 0.578\n","epoch: 45, time: 17880.190s, loss: 1.188, train accuracy: 0.531\n","epoch: 45, time: 17890.710s, loss: 1.249, train accuracy: 0.523\n","epoch: 45, time: 17901.238s, loss: 0.476, train accuracy: 0.820\n","epoch: 45, time: 17911.763s, loss: 0.367, train accuracy: 0.844\n","epoch: 45, time: 17922.287s, loss: 1.318, train accuracy: 0.500\n","epoch: 45, time: 17932.822s, loss: 1.255, train accuracy: 0.531\n","epoch: 45, time: 17943.356s, loss: 0.349, train accuracy: 0.852\n","epoch: 45, time: 17953.888s, loss: 0.533, train accuracy: 0.836\n","epoch: 45, time: 17964.419s, loss: 1.107, train accuracy: 0.547\n","epoch: 45, time: 17974.946s, loss: 0.455, train accuracy: 0.797\n","epoch: 45, time: 17985.473s, loss: 0.457, train accuracy: 0.797\n","epoch: 45, time: 17996.007s, loss: 0.459, train accuracy: 0.789\n","epoch: 45, time: 18006.546s, loss: 1.057, train accuracy: 0.602\n","epoch: 45, time: 18017.076s, loss: 0.422, train accuracy: 0.844\n","epoch: 45, time: 18027.604s, loss: 0.387, train accuracy: 0.836\n","epoch: 45, time: 18038.135s, loss: 0.369, train accuracy: 0.859\n","epoch: 45, time: 18048.668s, loss: 1.269, train accuracy: 0.539\n","epoch: 45, time: 18059.195s, loss: 1.273, train accuracy: 0.539\n","epoch: 45, time: 18069.735s, loss: 1.199, train accuracy: 0.539\n","epoch: 45, time: 18080.269s, loss: 1.332, train accuracy: 0.500\n","epoch: 45, time: 18090.803s, loss: 1.045, train accuracy: 0.656\n","epoch: 45, time: 18101.348s, loss: 0.432, train accuracy: 0.859\n","epoch: 45, validation loss: 0.431929467901238\n","epoch: 46, time: 18114.101s, loss: 1.163, train accuracy: 0.578\n","epoch: 46, time: 18124.624s, loss: 0.484, train accuracy: 0.836\n","epoch: 46, time: 18135.144s, loss: 0.414, train accuracy: 0.844\n","epoch: 46, time: 18145.676s, loss: 0.415, train accuracy: 0.828\n","epoch: 46, time: 18156.203s, loss: 1.309, train accuracy: 0.461\n","epoch: 46, time: 18166.733s, loss: 0.995, train accuracy: 0.602\n","epoch: 46, time: 18177.260s, loss: 1.097, train accuracy: 0.586\n","epoch: 46, time: 18187.794s, loss: 1.145, train accuracy: 0.594\n","epoch: 46, time: 18198.336s, loss: 1.400, train accuracy: 0.523\n","epoch: 46, time: 18208.875s, loss: 1.179, train accuracy: 0.523\n","epoch: 46, time: 18219.413s, loss: 1.444, train accuracy: 0.477\n","epoch: 46, time: 18229.941s, loss: 1.157, train accuracy: 0.539\n","epoch: 46, time: 18240.471s, loss: 1.103, train accuracy: 0.547\n","epoch: 46, time: 18251.009s, loss: 1.155, train accuracy: 0.531\n","epoch: 46, time: 18261.545s, loss: 0.324, train accuracy: 0.867\n","epoch: 46, time: 18272.086s, loss: 0.428, train accuracy: 0.820\n","epoch: 46, time: 18282.613s, loss: 0.436, train accuracy: 0.820\n","epoch: 46, time: 18293.133s, loss: 1.104, train accuracy: 0.602\n","epoch: 46, time: 18303.653s, loss: 1.103, train accuracy: 0.609\n","epoch: 46, time: 18314.173s, loss: 1.170, train accuracy: 0.500\n","epoch: 46, time: 18324.691s, loss: 1.203, train accuracy: 0.531\n","epoch: 46, time: 18335.217s, loss: 0.339, train accuracy: 0.891\n","epoch: 46, time: 18345.743s, loss: 1.112, train accuracy: 0.555\n","epoch: 46, time: 18356.259s, loss: 1.154, train accuracy: 0.500\n","epoch: 46, time: 18366.773s, loss: 0.379, train accuracy: 0.891\n","epoch: 46, time: 18377.304s, loss: 0.543, train accuracy: 0.797\n","epoch: 46, time: 18387.829s, loss: 0.411, train accuracy: 0.859\n","epoch: 46, time: 18398.359s, loss: 1.134, train accuracy: 0.594\n","epoch: 46, time: 18408.877s, loss: 1.125, train accuracy: 0.547\n","epoch: 46, time: 18419.416s, loss: 1.093, train accuracy: 0.492\n","epoch: 46, time: 18429.952s, loss: 1.007, train accuracy: 0.602\n","epoch: 46, time: 18440.490s, loss: 1.223, train accuracy: 0.523\n","epoch: 46, time: 18451.026s, loss: 0.492, train accuracy: 0.812\n","epoch: 46, time: 18461.549s, loss: 0.399, train accuracy: 0.844\n","epoch: 46, time: 18472.077s, loss: 0.392, train accuracy: 0.844\n","epoch: 46, time: 18482.610s, loss: 0.332, train accuracy: 0.867\n","epoch: 46, time: 18493.134s, loss: 0.359, train accuracy: 0.852\n","epoch: 46, time: 18503.668s, loss: 1.203, train accuracy: 0.539\n","epoch: 46, validation loss: 0.4274855342501008\n","epoch: 47, time: 18516.381s, loss: 0.559, train accuracy: 0.820\n","epoch: 47, time: 18526.896s, loss: 0.308, train accuracy: 0.883\n","epoch: 47, time: 18537.430s, loss: 0.462, train accuracy: 0.844\n","epoch: 47, time: 18547.936s, loss: 0.483, train accuracy: 0.812\n","epoch: 47, time: 18558.451s, loss: 0.429, train accuracy: 0.836\n","epoch: 47, time: 18568.983s, loss: 0.282, train accuracy: 0.922\n","epoch: 47, time: 18579.495s, loss: 1.094, train accuracy: 0.531\n","epoch: 47, time: 18590.016s, loss: 1.268, train accuracy: 0.516\n","epoch: 47, time: 18600.545s, loss: 1.362, train accuracy: 0.500\n","epoch: 47, time: 18611.073s, loss: 0.425, train accuracy: 0.797\n","epoch: 47, time: 18621.590s, loss: 1.209, train accuracy: 0.562\n","epoch: 47, time: 18632.114s, loss: 1.257, train accuracy: 0.508\n","epoch: 47, time: 18642.644s, loss: 1.161, train accuracy: 0.555\n","epoch: 47, time: 18653.163s, loss: 1.218, train accuracy: 0.555\n","epoch: 47, time: 18663.688s, loss: 0.441, train accuracy: 0.820\n","epoch: 47, time: 18674.218s, loss: 0.469, train accuracy: 0.781\n","epoch: 47, time: 18684.745s, loss: 0.477, train accuracy: 0.844\n","epoch: 47, time: 18695.279s, loss: 0.384, train accuracy: 0.836\n","epoch: 47, time: 18705.818s, loss: 0.503, train accuracy: 0.820\n","epoch: 47, time: 18716.347s, loss: 0.446, train accuracy: 0.828\n","epoch: 47, time: 18726.872s, loss: 1.124, train accuracy: 0.609\n","epoch: 47, time: 18737.392s, loss: 0.553, train accuracy: 0.773\n","epoch: 47, time: 18747.918s, loss: 1.179, train accuracy: 0.578\n","epoch: 47, time: 18758.441s, loss: 0.531, train accuracy: 0.781\n","epoch: 47, time: 18768.959s, loss: 1.113, train accuracy: 0.609\n","epoch: 47, time: 18779.484s, loss: 0.461, train accuracy: 0.828\n","epoch: 47, time: 18790.004s, loss: 1.330, train accuracy: 0.484\n","epoch: 47, time: 18800.530s, loss: 1.220, train accuracy: 0.508\n","epoch: 47, time: 18811.046s, loss: 1.260, train accuracy: 0.539\n","epoch: 47, time: 18821.563s, loss: 0.379, train accuracy: 0.844\n","epoch: 47, time: 18832.086s, loss: 1.368, train accuracy: 0.484\n","epoch: 47, time: 18842.616s, loss: 1.330, train accuracy: 0.547\n","epoch: 47, time: 18853.140s, loss: 0.993, train accuracy: 0.594\n","epoch: 47, time: 18863.673s, loss: 1.344, train accuracy: 0.445\n","epoch: 47, time: 18874.207s, loss: 1.082, train accuracy: 0.539\n","epoch: 47, time: 18884.745s, loss: 1.211, train accuracy: 0.523\n","epoch: 47, time: 18895.277s, loss: 0.455, train accuracy: 0.789\n","epoch: 47, time: 18905.814s, loss: 0.455, train accuracy: 0.805\n","epoch: 47, validation loss: 0.4319099263786507\n","epoch: 48, time: 18918.563s, loss: 0.365, train accuracy: 0.883\n","epoch: 48, time: 18929.087s, loss: 0.460, train accuracy: 0.812\n","epoch: 48, time: 18939.613s, loss: 0.402, train accuracy: 0.867\n","epoch: 48, time: 18950.142s, loss: 1.261, train accuracy: 0.484\n","epoch: 48, time: 18960.669s, loss: 1.052, train accuracy: 0.547\n","epoch: 48, time: 18971.201s, loss: 1.367, train accuracy: 0.445\n","epoch: 48, time: 18981.740s, loss: 0.515, train accuracy: 0.820\n","epoch: 48, time: 18992.279s, loss: 1.283, train accuracy: 0.562\n","epoch: 48, time: 19002.813s, loss: 1.225, train accuracy: 0.547\n","epoch: 48, time: 19013.351s, loss: 1.007, train accuracy: 0.594\n","epoch: 48, time: 19023.883s, loss: 0.583, train accuracy: 0.820\n","epoch: 48, time: 19034.416s, loss: 0.371, train accuracy: 0.883\n","epoch: 48, time: 19044.952s, loss: 1.283, train accuracy: 0.461\n","epoch: 48, time: 19055.490s, loss: 1.104, train accuracy: 0.609\n","epoch: 48, time: 19066.031s, loss: 1.025, train accuracy: 0.602\n","epoch: 48, time: 19076.569s, loss: 1.380, train accuracy: 0.523\n","epoch: 48, time: 19087.115s, loss: 1.165, train accuracy: 0.539\n","epoch: 48, time: 19097.656s, loss: 1.252, train accuracy: 0.516\n","epoch: 48, time: 19108.191s, loss: 1.131, train accuracy: 0.625\n","epoch: 48, time: 19118.730s, loss: 1.082, train accuracy: 0.578\n","epoch: 48, time: 19129.264s, loss: 1.169, train accuracy: 0.562\n","epoch: 48, time: 19139.804s, loss: 0.434, train accuracy: 0.828\n","epoch: 48, time: 19150.343s, loss: 1.264, train accuracy: 0.523\n","epoch: 48, time: 19160.888s, loss: 0.519, train accuracy: 0.820\n","epoch: 48, time: 19171.427s, loss: 1.049, train accuracy: 0.555\n","epoch: 48, time: 19181.959s, loss: 0.462, train accuracy: 0.852\n","epoch: 48, time: 19192.506s, loss: 0.379, train accuracy: 0.859\n","epoch: 48, time: 19203.026s, loss: 1.065, train accuracy: 0.578\n","epoch: 48, time: 19213.558s, loss: 0.408, train accuracy: 0.828\n","epoch: 48, time: 19224.087s, loss: 1.293, train accuracy: 0.508\n","epoch: 48, time: 19234.613s, loss: 0.318, train accuracy: 0.891\n","epoch: 48, time: 19245.139s, loss: 0.478, train accuracy: 0.805\n","epoch: 48, time: 19255.659s, loss: 0.965, train accuracy: 0.570\n","epoch: 48, time: 19266.185s, loss: 0.467, train accuracy: 0.820\n","epoch: 48, time: 19276.709s, loss: 0.351, train accuracy: 0.859\n","epoch: 48, time: 19287.235s, loss: 0.361, train accuracy: 0.844\n","epoch: 48, time: 19297.771s, loss: 0.422, train accuracy: 0.820\n","epoch: 48, time: 19308.304s, loss: 1.275, train accuracy: 0.531\n","epoch: 48, validation loss: 0.42083175451770777\n","epoch: 49, time: 19321.054s, loss: 1.133, train accuracy: 0.547\n","epoch: 49, time: 19331.577s, loss: 0.432, train accuracy: 0.820\n","epoch: 49, time: 19342.101s, loss: 1.139, train accuracy: 0.516\n","epoch: 49, time: 19352.624s, loss: 1.216, train accuracy: 0.516\n","epoch: 49, time: 19363.157s, loss: 0.516, train accuracy: 0.820\n","epoch: 49, time: 19373.685s, loss: 1.041, train accuracy: 0.609\n","epoch: 49, time: 19384.216s, loss: 0.623, train accuracy: 0.742\n","epoch: 49, time: 19394.749s, loss: 0.431, train accuracy: 0.844\n","epoch: 49, time: 19405.297s, loss: 0.306, train accuracy: 0.906\n","epoch: 49, time: 19415.828s, loss: 0.377, train accuracy: 0.875\n","epoch: 49, time: 19426.356s, loss: 0.478, train accuracy: 0.812\n","epoch: 49, time: 19436.892s, loss: 0.334, train accuracy: 0.898\n","epoch: 49, time: 19447.412s, loss: 1.281, train accuracy: 0.562\n","epoch: 49, time: 19457.944s, loss: 0.389, train accuracy: 0.852\n","epoch: 49, time: 19468.463s, loss: 1.142, train accuracy: 0.602\n","epoch: 49, time: 19478.995s, loss: 1.015, train accuracy: 0.555\n","epoch: 49, time: 19489.529s, loss: 1.302, train accuracy: 0.445\n","epoch: 49, time: 19500.057s, loss: 0.433, train accuracy: 0.828\n","epoch: 49, time: 19510.580s, loss: 0.477, train accuracy: 0.820\n","epoch: 49, time: 19521.110s, loss: 0.424, train accuracy: 0.836\n","epoch: 49, time: 19531.630s, loss: 1.040, train accuracy: 0.617\n","epoch: 49, time: 19542.154s, loss: 1.056, train accuracy: 0.578\n","epoch: 49, time: 19552.683s, loss: 1.316, train accuracy: 0.477\n","epoch: 49, time: 19563.229s, loss: 1.328, train accuracy: 0.477\n","epoch: 49, time: 19573.777s, loss: 0.539, train accuracy: 0.828\n","epoch: 49, time: 19584.311s, loss: 1.109, train accuracy: 0.555\n","epoch: 49, time: 19594.848s, loss: 1.068, train accuracy: 0.555\n","epoch: 49, time: 19605.374s, loss: 1.100, train accuracy: 0.570\n","epoch: 49, time: 19615.887s, loss: 1.141, train accuracy: 0.570\n","epoch: 49, time: 19626.405s, loss: 0.349, train accuracy: 0.875\n","epoch: 49, time: 19636.909s, loss: 0.397, train accuracy: 0.852\n","epoch: 49, time: 19647.414s, loss: 1.230, train accuracy: 0.539\n","epoch: 49, time: 19657.925s, loss: 0.984, train accuracy: 0.586\n","epoch: 49, time: 19668.446s, loss: 1.004, train accuracy: 0.602\n","epoch: 49, time: 19678.974s, loss: 1.118, train accuracy: 0.531\n","epoch: 49, time: 19689.514s, loss: 0.408, train accuracy: 0.844\n","epoch: 49, time: 19700.051s, loss: 0.482, train accuracy: 0.781\n","epoch: 49, time: 19710.584s, loss: 1.121, train accuracy: 0.531\n","epoch: 49, validation loss: 0.42599812197659825\n","epoch: 50, time: 19723.393s, loss: 1.182, train accuracy: 0.531\n","epoch: 50, time: 19733.897s, loss: 0.918, train accuracy: 0.617\n","epoch: 50, time: 19744.401s, loss: 1.107, train accuracy: 0.578\n","epoch: 50, time: 19754.904s, loss: 0.375, train accuracy: 0.852\n","epoch: 50, time: 19765.410s, loss: 1.103, train accuracy: 0.578\n","epoch: 50, time: 19775.921s, loss: 0.374, train accuracy: 0.867\n","epoch: 50, time: 19786.441s, loss: 0.425, train accuracy: 0.859\n","epoch: 50, time: 19796.947s, loss: 0.469, train accuracy: 0.820\n","epoch: 50, time: 19807.463s, loss: 0.360, train accuracy: 0.875\n","epoch: 50, time: 19817.983s, loss: 1.272, train accuracy: 0.555\n","epoch: 50, time: 19828.495s, loss: 0.438, train accuracy: 0.875\n","epoch: 50, time: 19838.995s, loss: 1.023, train accuracy: 0.633\n","epoch: 50, time: 19849.496s, loss: 1.063, train accuracy: 0.594\n","epoch: 50, time: 19860.011s, loss: 0.312, train accuracy: 0.906\n","epoch: 50, time: 19870.534s, loss: 0.373, train accuracy: 0.859\n","epoch: 50, time: 19881.050s, loss: 1.408, train accuracy: 0.477\n","epoch: 50, time: 19891.572s, loss: 0.440, train accuracy: 0.828\n","epoch: 50, time: 19902.088s, loss: 1.254, train accuracy: 0.602\n","epoch: 50, time: 19912.620s, loss: 0.370, train accuracy: 0.844\n","epoch: 50, time: 19923.160s, loss: 0.520, train accuracy: 0.805\n","epoch: 50, time: 19933.699s, loss: 0.730, train accuracy: 0.727\n","epoch: 50, time: 19944.241s, loss: 0.424, train accuracy: 0.828\n","epoch: 50, time: 19954.784s, loss: 0.380, train accuracy: 0.852\n","epoch: 50, time: 19965.315s, loss: 1.361, train accuracy: 0.492\n","epoch: 50, time: 19975.854s, loss: 1.334, train accuracy: 0.531\n","epoch: 50, time: 19986.381s, loss: 0.390, train accuracy: 0.836\n","epoch: 50, time: 19996.901s, loss: 1.187, train accuracy: 0.516\n","epoch: 50, time: 20007.433s, loss: 1.210, train accuracy: 0.570\n","epoch: 50, time: 20017.966s, loss: 1.324, train accuracy: 0.516\n","epoch: 50, time: 20028.482s, loss: 1.083, train accuracy: 0.586\n","epoch: 50, time: 20039.004s, loss: 0.369, train accuracy: 0.859\n","epoch: 50, time: 20049.529s, loss: 0.501, train accuracy: 0.789\n","epoch: 50, time: 20060.058s, loss: 0.407, train accuracy: 0.852\n","epoch: 50, time: 20070.573s, loss: 0.394, train accuracy: 0.852\n","epoch: 50, time: 20081.106s, loss: 1.280, train accuracy: 0.531\n","epoch: 50, time: 20091.640s, loss: 1.124, train accuracy: 0.578\n","epoch: 50, time: 20102.160s, loss: 0.469, train accuracy: 0.828\n","epoch: 50, time: 20112.688s, loss: 0.365, train accuracy: 0.828\n","epoch: 50, validation loss: 0.4361432710690285\n","epoch: 51, time: 20125.477s, loss: 1.098, train accuracy: 0.539\n","epoch: 51, time: 20135.992s, loss: 0.378, train accuracy: 0.859\n","epoch: 51, time: 20146.503s, loss: 0.371, train accuracy: 0.820\n","epoch: 51, time: 20157.027s, loss: 1.067, train accuracy: 0.617\n","epoch: 51, time: 20167.541s, loss: 0.325, train accuracy: 0.891\n","epoch: 51, time: 20178.060s, loss: 0.382, train accuracy: 0.828\n","epoch: 51, time: 20188.583s, loss: 1.241, train accuracy: 0.555\n","epoch: 51, time: 20199.115s, loss: 1.074, train accuracy: 0.562\n","epoch: 51, time: 20209.654s, loss: 1.040, train accuracy: 0.594\n","epoch: 51, time: 20220.181s, loss: 1.048, train accuracy: 0.586\n","epoch: 51, time: 20230.711s, loss: 1.084, train accuracy: 0.609\n","epoch: 51, time: 20241.241s, loss: 1.174, train accuracy: 0.531\n","epoch: 51, time: 20251.776s, loss: 0.313, train accuracy: 0.898\n","epoch: 51, time: 20262.299s, loss: 0.502, train accuracy: 0.852\n","epoch: 51, time: 20272.836s, loss: 1.209, train accuracy: 0.516\n","epoch: 51, time: 20283.366s, loss: 0.484, train accuracy: 0.836\n","epoch: 51, time: 20293.902s, loss: 0.291, train accuracy: 0.922\n","epoch: 51, time: 20304.432s, loss: 0.453, train accuracy: 0.820\n","epoch: 51, time: 20314.968s, loss: 0.411, train accuracy: 0.828\n","epoch: 51, time: 20325.501s, loss: 1.167, train accuracy: 0.539\n","epoch: 51, time: 20336.043s, loss: 0.438, train accuracy: 0.844\n","epoch: 51, time: 20346.577s, loss: 0.955, train accuracy: 0.656\n","epoch: 51, time: 20357.111s, loss: 1.233, train accuracy: 0.516\n","epoch: 51, time: 20367.649s, loss: 1.096, train accuracy: 0.555\n","epoch: 51, time: 20378.188s, loss: 0.438, train accuracy: 0.820\n","epoch: 51, time: 20388.723s, loss: 0.334, train accuracy: 0.852\n","epoch: 51, time: 20399.255s, loss: 0.991, train accuracy: 0.602\n","epoch: 51, time: 20409.787s, loss: 0.437, train accuracy: 0.852\n","epoch: 51, time: 20420.317s, loss: 0.543, train accuracy: 0.766\n","epoch: 51, time: 20430.844s, loss: 0.376, train accuracy: 0.836\n","epoch: 51, time: 20441.373s, loss: 1.156, train accuracy: 0.539\n","epoch: 51, time: 20451.904s, loss: 1.157, train accuracy: 0.586\n","epoch: 51, time: 20462.433s, loss: 0.529, train accuracy: 0.820\n","epoch: 51, time: 20472.954s, loss: 1.277, train accuracy: 0.523\n","epoch: 51, time: 20483.471s, loss: 0.430, train accuracy: 0.859\n","epoch: 51, time: 20493.990s, loss: 1.077, train accuracy: 0.594\n","epoch: 51, time: 20504.514s, loss: 0.989, train accuracy: 0.547\n","epoch: 51, time: 20515.035s, loss: 0.929, train accuracy: 0.648\n","epoch: 51, validation loss: 0.4468643074033103\n","epoch: 52, time: 20527.723s, loss: 1.393, train accuracy: 0.438\n","epoch: 52, time: 20538.238s, loss: 1.325, train accuracy: 0.445\n","epoch: 52, time: 20548.750s, loss: 0.516, train accuracy: 0.852\n","epoch: 52, time: 20559.257s, loss: 0.311, train accuracy: 0.898\n","epoch: 52, time: 20569.767s, loss: 0.395, train accuracy: 0.828\n","epoch: 52, time: 20580.268s, loss: 1.268, train accuracy: 0.562\n","epoch: 52, time: 20590.790s, loss: 1.242, train accuracy: 0.578\n","epoch: 52, time: 20601.303s, loss: 1.122, train accuracy: 0.523\n","epoch: 52, time: 20611.833s, loss: 1.282, train accuracy: 0.516\n","epoch: 52, time: 20622.349s, loss: 0.423, train accuracy: 0.859\n","epoch: 52, time: 20632.868s, loss: 0.345, train accuracy: 0.891\n","epoch: 52, time: 20643.395s, loss: 0.382, train accuracy: 0.852\n","epoch: 52, time: 20653.933s, loss: 0.420, train accuracy: 0.859\n","epoch: 52, time: 20664.466s, loss: 0.379, train accuracy: 0.867\n","epoch: 52, time: 20674.989s, loss: 1.150, train accuracy: 0.531\n","epoch: 52, time: 20685.517s, loss: 1.194, train accuracy: 0.523\n","epoch: 52, time: 20696.048s, loss: 0.520, train accuracy: 0.812\n","epoch: 52, time: 20706.567s, loss: 0.477, train accuracy: 0.773\n","epoch: 52, time: 20717.081s, loss: 0.357, train accuracy: 0.867\n","epoch: 52, time: 20727.594s, loss: 0.403, train accuracy: 0.844\n","epoch: 52, time: 20738.115s, loss: 0.456, train accuracy: 0.797\n","epoch: 52, time: 20748.659s, loss: 1.113, train accuracy: 0.578\n","epoch: 52, time: 20759.191s, loss: 0.391, train accuracy: 0.852\n","epoch: 52, time: 20769.711s, loss: 1.179, train accuracy: 0.547\n","epoch: 52, time: 20780.225s, loss: 0.480, train accuracy: 0.828\n","epoch: 52, time: 20790.745s, loss: 0.419, train accuracy: 0.844\n","epoch: 52, time: 20801.261s, loss: 1.296, train accuracy: 0.539\n","epoch: 52, time: 20811.797s, loss: 1.241, train accuracy: 0.539\n","epoch: 52, time: 20822.319s, loss: 1.248, train accuracy: 0.570\n","epoch: 52, time: 20832.841s, loss: 0.321, train accuracy: 0.883\n","epoch: 52, time: 20843.364s, loss: 1.059, train accuracy: 0.562\n","epoch: 52, time: 20853.878s, loss: 1.091, train accuracy: 0.578\n","epoch: 52, time: 20864.394s, loss: 0.342, train accuracy: 0.883\n","epoch: 52, time: 20874.913s, loss: 0.509, train accuracy: 0.836\n","epoch: 52, time: 20885.424s, loss: 0.419, train accuracy: 0.828\n","epoch: 52, time: 20895.940s, loss: 1.222, train accuracy: 0.492\n","epoch: 52, time: 20906.461s, loss: 0.478, train accuracy: 0.836\n","epoch: 52, time: 20916.984s, loss: 0.421, train accuracy: 0.852\n","epoch: 52, validation loss: 0.423291783692486\n","epoch: 53, time: 20929.712s, loss: 1.247, train accuracy: 0.523\n","epoch: 53, time: 20940.210s, loss: 1.105, train accuracy: 0.539\n","epoch: 53, time: 20950.721s, loss: 0.842, train accuracy: 0.664\n","epoch: 53, time: 20961.235s, loss: 0.404, train accuracy: 0.852\n","epoch: 53, time: 20971.748s, loss: 1.376, train accuracy: 0.492\n","epoch: 53, time: 20982.254s, loss: 1.227, train accuracy: 0.555\n","epoch: 53, time: 20992.774s, loss: 0.362, train accuracy: 0.844\n","epoch: 53, time: 21003.278s, loss: 1.346, train accuracy: 0.484\n","epoch: 53, time: 21013.795s, loss: 0.319, train accuracy: 0.898\n","epoch: 53, time: 21024.317s, loss: 0.406, train accuracy: 0.820\n","epoch: 53, time: 21034.831s, loss: 1.178, train accuracy: 0.531\n","epoch: 53, time: 21045.354s, loss: 1.222, train accuracy: 0.539\n","epoch: 53, time: 21055.875s, loss: 1.106, train accuracy: 0.570\n","epoch: 53, time: 21066.401s, loss: 0.378, train accuracy: 0.828\n","epoch: 53, time: 21076.933s, loss: 0.314, train accuracy: 0.891\n","epoch: 53, time: 21087.459s, loss: 0.935, train accuracy: 0.625\n","epoch: 53, time: 21097.985s, loss: 1.194, train accuracy: 0.484\n","epoch: 53, time: 21108.518s, loss: 1.291, train accuracy: 0.469\n","epoch: 53, time: 21119.039s, loss: 1.303, train accuracy: 0.461\n","epoch: 53, time: 21129.573s, loss: 1.244, train accuracy: 0.500\n","epoch: 53, time: 21140.109s, loss: 0.546, train accuracy: 0.820\n","epoch: 53, time: 21150.640s, loss: 0.437, train accuracy: 0.805\n","epoch: 53, time: 21161.178s, loss: 0.391, train accuracy: 0.875\n","epoch: 53, time: 21171.707s, loss: 1.079, train accuracy: 0.586\n","epoch: 53, time: 21182.242s, loss: 0.384, train accuracy: 0.867\n","epoch: 53, time: 21192.768s, loss: 0.384, train accuracy: 0.836\n","epoch: 53, time: 21203.299s, loss: 1.078, train accuracy: 0.641\n","epoch: 53, time: 21213.829s, loss: 1.459, train accuracy: 0.500\n","epoch: 53, time: 21224.358s, loss: 1.094, train accuracy: 0.570\n","epoch: 53, time: 21234.894s, loss: 1.193, train accuracy: 0.500\n","epoch: 53, time: 21245.433s, loss: 0.521, train accuracy: 0.820\n","epoch: 53, time: 21255.968s, loss: 1.134, train accuracy: 0.578\n","epoch: 53, time: 21266.503s, loss: 1.279, train accuracy: 0.539\n","epoch: 53, time: 21277.044s, loss: 1.126, train accuracy: 0.609\n","epoch: 53, time: 21287.573s, loss: 1.050, train accuracy: 0.578\n","epoch: 53, time: 21298.104s, loss: 1.231, train accuracy: 0.523\n","epoch: 53, time: 21308.636s, loss: 0.479, train accuracy: 0.852\n","epoch: 53, time: 21319.164s, loss: 1.176, train accuracy: 0.508\n","epoch: 53, validation loss: 0.45805159449450245\n","epoch: 54, time: 21331.823s, loss: 1.156, train accuracy: 0.523\n","epoch: 54, time: 21342.349s, loss: 0.446, train accuracy: 0.859\n","epoch: 54, time: 21352.868s, loss: 1.401, train accuracy: 0.539\n","epoch: 54, time: 21363.391s, loss: 1.129, train accuracy: 0.500\n","epoch: 54, time: 21373.924s, loss: 0.393, train accuracy: 0.891\n","epoch: 54, time: 21384.457s, loss: 0.957, train accuracy: 0.648\n","epoch: 54, time: 21394.967s, loss: 0.272, train accuracy: 0.875\n","epoch: 54, time: 21405.514s, loss: 1.233, train accuracy: 0.492\n","epoch: 54, time: 21416.053s, loss: 1.183, train accuracy: 0.547\n","epoch: 54, time: 21426.591s, loss: 0.406, train accuracy: 0.867\n","epoch: 54, time: 21437.125s, loss: 1.074, train accuracy: 0.586\n","epoch: 54, time: 21447.652s, loss: 1.136, train accuracy: 0.555\n","epoch: 54, time: 21458.166s, loss: 1.611, train accuracy: 0.367\n","epoch: 54, time: 21468.681s, loss: 0.409, train accuracy: 0.844\n","epoch: 54, time: 21479.202s, loss: 0.514, train accuracy: 0.812\n","epoch: 54, time: 21489.722s, loss: 0.555, train accuracy: 0.844\n","epoch: 54, time: 21500.236s, loss: 0.358, train accuracy: 0.859\n","epoch: 54, time: 21510.754s, loss: 1.116, train accuracy: 0.555\n","epoch: 54, time: 21521.264s, loss: 0.369, train accuracy: 0.859\n","epoch: 54, time: 21531.777s, loss: 0.548, train accuracy: 0.758\n","epoch: 54, time: 21542.285s, loss: 1.315, train accuracy: 0.562\n","epoch: 54, time: 21552.796s, loss: 0.395, train accuracy: 0.875\n","epoch: 54, time: 21563.312s, loss: 1.251, train accuracy: 0.523\n","epoch: 54, time: 21573.828s, loss: 1.236, train accuracy: 0.547\n","epoch: 54, time: 21584.351s, loss: 0.253, train accuracy: 0.930\n","epoch: 54, time: 21594.881s, loss: 1.183, train accuracy: 0.562\n","epoch: 54, time: 21605.408s, loss: 0.443, train accuracy: 0.859\n","epoch: 54, time: 21615.929s, loss: 1.058, train accuracy: 0.570\n","epoch: 54, time: 21626.454s, loss: 0.381, train accuracy: 0.867\n","epoch: 54, time: 21636.980s, loss: 1.071, train accuracy: 0.516\n","epoch: 54, time: 21647.508s, loss: 0.349, train accuracy: 0.883\n","epoch: 54, time: 21658.050s, loss: 0.428, train accuracy: 0.836\n","epoch: 54, time: 21668.582s, loss: 1.476, train accuracy: 0.500\n","epoch: 54, time: 21679.118s, loss: 0.528, train accuracy: 0.812\n","epoch: 54, time: 21689.649s, loss: 0.400, train accuracy: 0.859\n","epoch: 54, time: 21700.171s, loss: 0.465, train accuracy: 0.797\n","epoch: 54, time: 21710.704s, loss: 1.015, train accuracy: 0.609\n","epoch: 54, time: 21721.236s, loss: 1.325, train accuracy: 0.445\n","epoch: 54, validation loss: 0.41836467172418323\n","epoch: 55, time: 21733.933s, loss: 1.078, train accuracy: 0.578\n","epoch: 55, time: 21744.454s, loss: 1.267, train accuracy: 0.555\n","epoch: 55, time: 21754.973s, loss: 1.276, train accuracy: 0.508\n","epoch: 55, time: 21765.494s, loss: 1.263, train accuracy: 0.523\n","epoch: 55, time: 21776.019s, loss: 0.466, train accuracy: 0.836\n","epoch: 55, time: 21786.551s, loss: 0.436, train accuracy: 0.781\n","epoch: 55, time: 21797.084s, loss: 1.073, train accuracy: 0.586\n","epoch: 55, time: 21807.609s, loss: 1.229, train accuracy: 0.500\n","epoch: 55, time: 21818.139s, loss: 0.435, train accuracy: 0.828\n","epoch: 55, time: 21828.671s, loss: 0.377, train accuracy: 0.883\n","epoch: 55, time: 21839.210s, loss: 1.417, train accuracy: 0.477\n","epoch: 55, time: 21849.754s, loss: 0.520, train accuracy: 0.789\n","epoch: 55, time: 21860.282s, loss: 0.513, train accuracy: 0.781\n","epoch: 55, time: 21870.815s, loss: 0.333, train accuracy: 0.891\n","epoch: 55, time: 21881.348s, loss: 0.433, train accuracy: 0.812\n","epoch: 55, time: 21891.880s, loss: 0.574, train accuracy: 0.812\n","epoch: 55, time: 21902.412s, loss: 1.299, train accuracy: 0.484\n","epoch: 55, time: 21912.951s, loss: 0.348, train accuracy: 0.883\n","epoch: 55, time: 21923.482s, loss: 0.391, train accuracy: 0.859\n","epoch: 55, time: 21934.016s, loss: 1.205, train accuracy: 0.555\n","epoch: 55, time: 21944.544s, loss: 1.272, train accuracy: 0.555\n","epoch: 55, time: 21955.078s, loss: 0.448, train accuracy: 0.773\n","epoch: 55, time: 21965.624s, loss: 0.466, train accuracy: 0.828\n","epoch: 55, time: 21976.162s, loss: 0.339, train accuracy: 0.883\n","epoch: 55, time: 21986.705s, loss: 0.881, train accuracy: 0.664\n","epoch: 55, time: 21997.244s, loss: 1.137, train accuracy: 0.578\n","epoch: 55, time: 22007.784s, loss: 0.429, train accuracy: 0.859\n","epoch: 55, time: 22018.313s, loss: 0.409, train accuracy: 0.844\n","epoch: 55, time: 22028.850s, loss: 0.321, train accuracy: 0.883\n","epoch: 55, time: 22039.386s, loss: 0.315, train accuracy: 0.883\n","epoch: 55, time: 22049.928s, loss: 0.445, train accuracy: 0.844\n","epoch: 55, time: 22060.471s, loss: 0.474, train accuracy: 0.828\n","epoch: 55, time: 22071.017s, loss: 0.521, train accuracy: 0.812\n","epoch: 55, time: 22081.563s, loss: 1.134, train accuracy: 0.562\n","epoch: 55, time: 22092.094s, loss: 1.166, train accuracy: 0.562\n","epoch: 55, time: 22102.637s, loss: 0.465, train accuracy: 0.828\n","epoch: 55, time: 22113.176s, loss: 0.331, train accuracy: 0.891\n","epoch: 55, time: 22123.714s, loss: 0.435, train accuracy: 0.812\n","epoch: 55, validation loss: 0.427504698414284\n","epoch: 56, time: 22136.389s, loss: 1.271, train accuracy: 0.523\n","epoch: 56, time: 22146.911s, loss: 0.384, train accuracy: 0.867\n","epoch: 56, time: 22157.427s, loss: 0.293, train accuracy: 0.898\n","epoch: 56, time: 22167.958s, loss: 0.445, train accuracy: 0.805\n","epoch: 56, time: 22178.479s, loss: 1.031, train accuracy: 0.625\n","epoch: 56, time: 22188.995s, loss: 1.199, train accuracy: 0.516\n","epoch: 56, time: 22199.511s, loss: 0.447, train accuracy: 0.859\n","epoch: 56, time: 22210.015s, loss: 1.065, train accuracy: 0.594\n","epoch: 56, time: 22220.542s, loss: 0.379, train accuracy: 0.859\n","epoch: 56, time: 22231.062s, loss: 1.262, train accuracy: 0.508\n","epoch: 56, time: 22241.586s, loss: 1.160, train accuracy: 0.570\n","epoch: 56, time: 22252.091s, loss: 0.370, train accuracy: 0.836\n","epoch: 56, time: 22262.596s, loss: 1.298, train accuracy: 0.445\n","epoch: 56, time: 22273.111s, loss: 1.415, train accuracy: 0.484\n","epoch: 56, time: 22283.614s, loss: 1.361, train accuracy: 0.477\n","epoch: 56, time: 22294.134s, loss: 0.331, train accuracy: 0.883\n","epoch: 56, time: 22304.658s, loss: 1.239, train accuracy: 0.539\n","epoch: 56, time: 22315.177s, loss: 1.102, train accuracy: 0.531\n","epoch: 56, time: 22325.697s, loss: 0.436, train accuracy: 0.875\n","epoch: 56, time: 22336.220s, loss: 1.196, train accuracy: 0.523\n","epoch: 56, time: 22346.743s, loss: 1.055, train accuracy: 0.578\n","epoch: 56, time: 22357.259s, loss: 1.042, train accuracy: 0.594\n","epoch: 56, time: 22367.769s, loss: 1.010, train accuracy: 0.570\n","epoch: 56, time: 22378.287s, loss: 1.476, train accuracy: 0.461\n","epoch: 56, time: 22388.816s, loss: 0.405, train accuracy: 0.844\n","epoch: 56, time: 22399.353s, loss: 0.405, train accuracy: 0.859\n","epoch: 56, time: 22409.890s, loss: 0.482, train accuracy: 0.844\n","epoch: 56, time: 22420.426s, loss: 0.530, train accuracy: 0.805\n","epoch: 56, time: 22430.960s, loss: 1.263, train accuracy: 0.555\n","epoch: 56, time: 22441.487s, loss: 0.403, train accuracy: 0.852\n","epoch: 56, time: 22452.041s, loss: 1.144, train accuracy: 0.555\n","epoch: 56, time: 22462.583s, loss: 0.348, train accuracy: 0.883\n","epoch: 56, time: 22473.122s, loss: 0.610, train accuracy: 0.789\n","epoch: 56, time: 22483.664s, loss: 0.409, train accuracy: 0.828\n","epoch: 56, time: 22494.200s, loss: 1.068, train accuracy: 0.625\n","epoch: 56, time: 22504.731s, loss: 0.448, train accuracy: 0.812\n","epoch: 56, time: 22515.253s, loss: 0.346, train accuracy: 0.906\n","epoch: 56, time: 22525.777s, loss: 1.040, train accuracy: 0.570\n","epoch: 56, validation loss: 0.43044555568491727\n","epoch: 57, time: 22538.508s, loss: 0.315, train accuracy: 0.875\n","epoch: 57, time: 22549.009s, loss: 0.355, train accuracy: 0.867\n","epoch: 57, time: 22559.500s, loss: 1.073, train accuracy: 0.516\n","epoch: 57, time: 22570.001s, loss: 0.377, train accuracy: 0.867\n","epoch: 57, time: 22580.520s, loss: 0.370, train accuracy: 0.875\n","epoch: 57, time: 22591.031s, loss: 0.329, train accuracy: 0.883\n","epoch: 57, time: 22601.560s, loss: 0.365, train accuracy: 0.859\n","epoch: 57, time: 22612.103s, loss: 0.486, train accuracy: 0.812\n","epoch: 57, time: 22622.639s, loss: 0.505, train accuracy: 0.781\n","epoch: 57, time: 22633.178s, loss: 0.475, train accuracy: 0.867\n","epoch: 57, time: 22643.721s, loss: 1.057, train accuracy: 0.633\n","epoch: 57, time: 22654.259s, loss: 0.995, train accuracy: 0.594\n","epoch: 57, time: 22664.791s, loss: 0.413, train accuracy: 0.852\n","epoch: 57, time: 22675.335s, loss: 0.220, train accuracy: 0.914\n","epoch: 57, time: 22685.873s, loss: 0.366, train accuracy: 0.852\n","epoch: 57, time: 22696.388s, loss: 1.072, train accuracy: 0.562\n","epoch: 57, time: 22706.909s, loss: 0.426, train accuracy: 0.859\n","epoch: 57, time: 22717.429s, loss: 0.412, train accuracy: 0.812\n","epoch: 57, time: 22727.955s, loss: 1.324, train accuracy: 0.562\n","epoch: 57, time: 22738.477s, loss: 1.186, train accuracy: 0.500\n","epoch: 57, time: 22748.989s, loss: 0.430, train accuracy: 0.820\n","epoch: 57, time: 22759.496s, loss: 0.447, train accuracy: 0.836\n","epoch: 57, time: 22770.017s, loss: 1.200, train accuracy: 0.531\n","epoch: 57, time: 22780.530s, loss: 0.373, train accuracy: 0.859\n","epoch: 57, time: 22791.054s, loss: 0.459, train accuracy: 0.852\n","epoch: 57, time: 22801.583s, loss: 0.537, train accuracy: 0.812\n","epoch: 57, time: 22812.109s, loss: 0.387, train accuracy: 0.883\n","epoch: 57, time: 22822.630s, loss: 0.408, train accuracy: 0.867\n","epoch: 57, time: 22833.160s, loss: 0.372, train accuracy: 0.883\n","epoch: 57, time: 22843.686s, loss: 0.443, train accuracy: 0.812\n","epoch: 57, time: 22854.218s, loss: 0.470, train accuracy: 0.797\n","epoch: 57, time: 22864.745s, loss: 1.052, train accuracy: 0.633\n","epoch: 57, time: 22875.281s, loss: 0.362, train accuracy: 0.883\n","epoch: 57, time: 22885.809s, loss: 0.999, train accuracy: 0.602\n","epoch: 57, time: 22896.336s, loss: 1.114, train accuracy: 0.586\n","epoch: 57, time: 22906.868s, loss: 0.448, train accuracy: 0.820\n","epoch: 57, time: 22917.408s, loss: 1.155, train accuracy: 0.586\n","epoch: 57, time: 22927.951s, loss: 1.270, train accuracy: 0.570\n","epoch: 57, validation loss: 0.42793184423497493\n","epoch: 58, time: 22940.595s, loss: 1.181, train accuracy: 0.484\n","epoch: 58, time: 22951.116s, loss: 0.422, train accuracy: 0.867\n","epoch: 58, time: 22961.644s, loss: 1.153, train accuracy: 0.562\n","epoch: 58, time: 22972.176s, loss: 0.928, train accuracy: 0.648\n","epoch: 58, time: 22982.696s, loss: 0.893, train accuracy: 0.641\n","epoch: 58, time: 22993.215s, loss: 1.503, train accuracy: 0.508\n","epoch: 58, time: 23003.746s, loss: 0.459, train accuracy: 0.805\n","epoch: 58, time: 23014.283s, loss: 0.494, train accuracy: 0.828\n","epoch: 58, time: 23024.821s, loss: 0.380, train accuracy: 0.844\n","epoch: 58, time: 23035.353s, loss: 0.446, train accuracy: 0.797\n","epoch: 58, time: 23045.882s, loss: 0.430, train accuracy: 0.836\n","epoch: 58, time: 23056.409s, loss: 0.397, train accuracy: 0.844\n","epoch: 58, time: 23066.940s, loss: 1.110, train accuracy: 0.547\n","epoch: 58, time: 23077.466s, loss: 0.500, train accuracy: 0.805\n","epoch: 58, time: 23088.003s, loss: 0.299, train accuracy: 0.875\n","epoch: 58, time: 23098.527s, loss: 1.114, train accuracy: 0.531\n","epoch: 58, time: 23109.066s, loss: 0.351, train accuracy: 0.875\n","epoch: 58, time: 23119.600s, loss: 0.450, train accuracy: 0.773\n","epoch: 58, time: 23130.135s, loss: 0.480, train accuracy: 0.820\n","epoch: 58, time: 23140.671s, loss: 0.355, train accuracy: 0.859\n","epoch: 58, time: 23151.209s, loss: 1.265, train accuracy: 0.516\n","epoch: 58, time: 23161.741s, loss: 0.392, train accuracy: 0.844\n","epoch: 58, time: 23172.263s, loss: 0.995, train accuracy: 0.594\n","epoch: 58, time: 23182.804s, loss: 0.455, train accuracy: 0.859\n","epoch: 58, time: 23193.332s, loss: 1.421, train accuracy: 0.469\n","epoch: 58, time: 23203.856s, loss: 1.065, train accuracy: 0.570\n","epoch: 58, time: 23214.387s, loss: 1.454, train accuracy: 0.500\n","epoch: 58, time: 23224.923s, loss: 0.404, train accuracy: 0.828\n","epoch: 58, time: 23235.462s, loss: 1.118, train accuracy: 0.555\n","epoch: 58, time: 23245.987s, loss: 0.970, train accuracy: 0.625\n","epoch: 58, time: 23256.512s, loss: 0.549, train accuracy: 0.828\n","epoch: 58, time: 23267.040s, loss: 1.052, train accuracy: 0.562\n","epoch: 58, time: 23277.560s, loss: 0.335, train accuracy: 0.859\n","epoch: 58, time: 23288.080s, loss: 0.405, train accuracy: 0.875\n","epoch: 58, time: 23298.601s, loss: 0.423, train accuracy: 0.828\n","epoch: 58, time: 23309.121s, loss: 0.463, train accuracy: 0.820\n","epoch: 58, time: 23319.635s, loss: 1.125, train accuracy: 0.570\n","epoch: 58, time: 23330.155s, loss: 0.974, train accuracy: 0.586\n","epoch: 58, validation loss: 0.4346218629877196\n","epoch: 59, time: 23342.769s, loss: 0.961, train accuracy: 0.578\n","epoch: 59, time: 23353.277s, loss: 1.199, train accuracy: 0.562\n","epoch: 59, time: 23363.785s, loss: 0.460, train accuracy: 0.828\n","epoch: 59, time: 23374.288s, loss: 0.445, train accuracy: 0.836\n","epoch: 59, time: 23384.793s, loss: 1.106, train accuracy: 0.516\n","epoch: 59, time: 23395.294s, loss: 0.418, train accuracy: 0.875\n","epoch: 59, time: 23405.801s, loss: 0.495, train accuracy: 0.773\n","epoch: 59, time: 23416.319s, loss: 1.158, train accuracy: 0.516\n","epoch: 59, time: 23426.833s, loss: 1.429, train accuracy: 0.453\n","epoch: 59, time: 23437.335s, loss: 0.378, train accuracy: 0.828\n","epoch: 59, time: 23447.860s, loss: 0.419, train accuracy: 0.836\n","epoch: 59, time: 23458.369s, loss: 0.314, train accuracy: 0.883\n","epoch: 59, time: 23468.887s, loss: 0.367, train accuracy: 0.828\n","epoch: 59, time: 23479.397s, loss: 1.172, train accuracy: 0.547\n","epoch: 59, time: 23489.909s, loss: 1.063, train accuracy: 0.578\n","epoch: 59, time: 23500.420s, loss: 1.277, train accuracy: 0.562\n","epoch: 59, time: 23510.942s, loss: 1.046, train accuracy: 0.570\n","epoch: 59, time: 23521.456s, loss: 0.450, train accuracy: 0.805\n","epoch: 59, time: 23531.972s, loss: 1.063, train accuracy: 0.586\n","epoch: 59, time: 23542.488s, loss: 0.891, train accuracy: 0.633\n","epoch: 59, time: 23553.001s, loss: 0.896, train accuracy: 0.602\n","epoch: 59, time: 23563.499s, loss: 1.274, train accuracy: 0.523\n","epoch: 59, time: 23574.019s, loss: 0.292, train accuracy: 0.875\n","epoch: 59, time: 23584.530s, loss: 0.444, train accuracy: 0.797\n","epoch: 59, time: 23595.055s, loss: 1.095, train accuracy: 0.625\n","epoch: 59, time: 23605.559s, loss: 0.354, train accuracy: 0.859\n","epoch: 59, time: 23616.079s, loss: 1.071, train accuracy: 0.578\n","epoch: 59, time: 23626.589s, loss: 1.229, train accuracy: 0.500\n","epoch: 59, time: 23637.099s, loss: 1.134, train accuracy: 0.570\n","epoch: 59, time: 23647.616s, loss: 0.472, train accuracy: 0.820\n","epoch: 59, time: 23658.141s, loss: 0.296, train accuracy: 0.867\n","epoch: 59, time: 23668.662s, loss: 0.347, train accuracy: 0.859\n","epoch: 59, time: 23679.199s, loss: 1.099, train accuracy: 0.570\n","epoch: 59, time: 23689.725s, loss: 0.332, train accuracy: 0.836\n","epoch: 59, time: 23700.252s, loss: 0.303, train accuracy: 0.852\n","epoch: 59, time: 23710.784s, loss: 0.435, train accuracy: 0.852\n","epoch: 59, time: 23721.312s, loss: 1.088, train accuracy: 0.609\n","epoch: 59, time: 23731.838s, loss: 1.124, train accuracy: 0.531\n","epoch: 59, validation loss: 0.437357806511271\n","epoch: 60, time: 23744.563s, loss: 1.184, train accuracy: 0.484\n","epoch: 60, time: 23755.056s, loss: 0.447, train accuracy: 0.812\n","epoch: 60, time: 23765.565s, loss: 0.270, train accuracy: 0.891\n","epoch: 60, time: 23776.072s, loss: 1.285, train accuracy: 0.539\n","epoch: 60, time: 23786.583s, loss: 0.499, train accuracy: 0.781\n","epoch: 60, time: 23797.107s, loss: 0.344, train accuracy: 0.867\n","epoch: 60, time: 23807.632s, loss: 0.454, train accuracy: 0.805\n","epoch: 60, time: 23818.144s, loss: 0.547, train accuracy: 0.844\n","epoch: 60, time: 23828.663s, loss: 1.105, train accuracy: 0.531\n","epoch: 60, time: 23839.184s, loss: 0.415, train accuracy: 0.852\n","epoch: 60, time: 23849.701s, loss: 1.016, train accuracy: 0.633\n","epoch: 60, time: 23860.224s, loss: 1.200, train accuracy: 0.578\n","epoch: 60, time: 23870.742s, loss: 0.356, train accuracy: 0.875\n","epoch: 60, time: 23881.258s, loss: 0.366, train accuracy: 0.867\n","epoch: 60, time: 23891.769s, loss: 1.094, train accuracy: 0.594\n","epoch: 60, time: 23902.286s, loss: 1.275, train accuracy: 0.516\n","epoch: 60, time: 23912.800s, loss: 1.134, train accuracy: 0.555\n","epoch: 60, time: 23923.322s, loss: 1.289, train accuracy: 0.523\n","epoch: 60, time: 23933.834s, loss: 0.507, train accuracy: 0.820\n","epoch: 60, time: 23944.349s, loss: 1.328, train accuracy: 0.453\n","epoch: 60, time: 23954.869s, loss: 1.197, train accuracy: 0.539\n","epoch: 60, time: 23965.382s, loss: 1.381, train accuracy: 0.477\n","epoch: 60, time: 23975.896s, loss: 0.383, train accuracy: 0.852\n","epoch: 60, time: 23986.411s, loss: 1.183, train accuracy: 0.492\n","epoch: 60, time: 23996.925s, loss: 0.383, train accuracy: 0.844\n","epoch: 60, time: 24007.449s, loss: 0.986, train accuracy: 0.617\n","epoch: 60, time: 24017.961s, loss: 1.191, train accuracy: 0.578\n","epoch: 60, time: 24028.467s, loss: 0.290, train accuracy: 0.898\n","epoch: 60, time: 24038.988s, loss: 0.429, train accuracy: 0.836\n","epoch: 60, time: 24049.498s, loss: 0.452, train accuracy: 0.820\n","epoch: 60, time: 24060.021s, loss: 0.484, train accuracy: 0.820\n","epoch: 60, time: 24070.544s, loss: 0.497, train accuracy: 0.805\n","epoch: 60, time: 24081.061s, loss: 1.256, train accuracy: 0.516\n","epoch: 60, time: 24091.577s, loss: 0.388, train accuracy: 0.844\n","epoch: 60, time: 24102.090s, loss: 0.333, train accuracy: 0.836\n","epoch: 60, time: 24112.613s, loss: 0.961, train accuracy: 0.602\n","epoch: 60, time: 24123.141s, loss: 0.475, train accuracy: 0.859\n","epoch: 60, time: 24133.666s, loss: 1.058, train accuracy: 0.547\n","epoch: 60, validation loss: 0.4418028582260807\n","epoch: 61, time: 24146.279s, loss: 0.446, train accuracy: 0.781\n","epoch: 61, time: 24156.800s, loss: 1.089, train accuracy: 0.609\n","epoch: 61, time: 24167.328s, loss: 0.329, train accuracy: 0.883\n","epoch: 61, time: 24177.854s, loss: 1.182, train accuracy: 0.594\n","epoch: 61, time: 24188.379s, loss: 1.114, train accuracy: 0.547\n","epoch: 61, time: 24198.888s, loss: 0.344, train accuracy: 0.891\n","epoch: 61, time: 24209.419s, loss: 1.063, train accuracy: 0.602\n","epoch: 61, time: 24219.938s, loss: 0.401, train accuracy: 0.812\n","epoch: 61, time: 24230.461s, loss: 0.413, train accuracy: 0.844\n","epoch: 61, time: 24240.988s, loss: 1.399, train accuracy: 0.414\n","epoch: 61, time: 24251.508s, loss: 0.401, train accuracy: 0.859\n","epoch: 61, time: 24262.032s, loss: 0.412, train accuracy: 0.859\n","epoch: 61, time: 24272.567s, loss: 0.427, train accuracy: 0.836\n","epoch: 61, time: 24283.096s, loss: 0.371, train accuracy: 0.859\n","epoch: 61, time: 24293.627s, loss: 1.267, train accuracy: 0.586\n","epoch: 61, time: 24304.155s, loss: 1.113, train accuracy: 0.547\n","epoch: 61, time: 24314.684s, loss: 0.550, train accuracy: 0.828\n","epoch: 61, time: 24325.213s, loss: 1.213, train accuracy: 0.578\n","epoch: 61, time: 24335.723s, loss: 0.287, train accuracy: 0.922\n","epoch: 61, time: 24346.246s, loss: 1.163, train accuracy: 0.562\n","epoch: 61, time: 24356.785s, loss: 0.531, train accuracy: 0.797\n","epoch: 61, time: 24367.318s, loss: 1.046, train accuracy: 0.586\n","epoch: 61, time: 24377.858s, loss: 0.408, train accuracy: 0.852\n","epoch: 61, time: 24388.391s, loss: 0.362, train accuracy: 0.867\n","epoch: 61, time: 24398.922s, loss: 0.371, train accuracy: 0.891\n","epoch: 61, time: 24409.454s, loss: 0.443, train accuracy: 0.844\n","epoch: 61, time: 24419.973s, loss: 0.463, train accuracy: 0.820\n","epoch: 61, time: 24430.490s, loss: 1.107, train accuracy: 0.555\n","epoch: 61, time: 24441.001s, loss: 0.978, train accuracy: 0.570\n","epoch: 61, time: 24451.509s, loss: 1.006, train accuracy: 0.633\n","epoch: 61, time: 24462.030s, loss: 1.223, train accuracy: 0.484\n","epoch: 61, time: 24472.547s, loss: 1.295, train accuracy: 0.523\n","epoch: 61, time: 24483.071s, loss: 1.169, train accuracy: 0.562\n","epoch: 61, time: 24493.591s, loss: 1.020, train accuracy: 0.602\n","epoch: 61, time: 24504.109s, loss: 0.399, train accuracy: 0.906\n","epoch: 61, time: 24514.617s, loss: 0.425, train accuracy: 0.844\n","epoch: 61, time: 24525.127s, loss: 1.065, train accuracy: 0.570\n","epoch: 61, time: 24535.643s, loss: 0.421, train accuracy: 0.875\n","epoch: 61, validation loss: 0.449600787908792\n","epoch: 62, time: 24548.238s, loss: 0.374, train accuracy: 0.859\n","epoch: 62, time: 24558.764s, loss: 0.409, train accuracy: 0.812\n","epoch: 62, time: 24569.298s, loss: 1.245, train accuracy: 0.508\n","epoch: 62, time: 24579.828s, loss: 0.346, train accuracy: 0.836\n","epoch: 62, time: 24590.360s, loss: 1.181, train accuracy: 0.523\n","epoch: 62, time: 24600.891s, loss: 0.412, train accuracy: 0.836\n","epoch: 62, time: 24611.416s, loss: 0.311, train accuracy: 0.898\n","epoch: 62, time: 24621.939s, loss: 0.411, train accuracy: 0.859\n","epoch: 62, time: 24632.459s, loss: 0.380, train accuracy: 0.859\n","epoch: 62, time: 24642.969s, loss: 0.492, train accuracy: 0.781\n","epoch: 62, time: 24653.493s, loss: 0.520, train accuracy: 0.805\n","epoch: 62, time: 24664.013s, loss: 0.417, train accuracy: 0.797\n","epoch: 62, time: 24674.539s, loss: 1.032, train accuracy: 0.594\n","epoch: 62, time: 24685.058s, loss: 1.217, train accuracy: 0.602\n","epoch: 62, time: 24695.584s, loss: 1.086, train accuracy: 0.586\n","epoch: 62, time: 24706.103s, loss: 1.157, train accuracy: 0.539\n","epoch: 62, time: 24716.631s, loss: 0.344, train accuracy: 0.859\n","epoch: 62, time: 24727.164s, loss: 0.408, train accuracy: 0.867\n","epoch: 62, time: 24737.685s, loss: 0.422, train accuracy: 0.805\n","epoch: 62, time: 24748.210s, loss: 0.516, train accuracy: 0.805\n","epoch: 62, time: 24758.744s, loss: 1.233, train accuracy: 0.539\n","epoch: 62, time: 24769.269s, loss: 1.029, train accuracy: 0.570\n","epoch: 62, time: 24779.800s, loss: 0.451, train accuracy: 0.805\n","epoch: 62, time: 24790.331s, loss: 0.440, train accuracy: 0.820\n","epoch: 62, time: 24800.875s, loss: 0.414, train accuracy: 0.805\n","epoch: 62, time: 24811.400s, loss: 0.450, train accuracy: 0.836\n","epoch: 62, time: 24821.937s, loss: 1.232, train accuracy: 0.562\n","epoch: 62, time: 24832.460s, loss: 1.157, train accuracy: 0.570\n","epoch: 62, time: 24842.993s, loss: 0.404, train accuracy: 0.836\n","epoch: 62, time: 24853.517s, loss: 0.473, train accuracy: 0.805\n","epoch: 62, time: 24864.046s, loss: 1.264, train accuracy: 0.547\n","epoch: 62, time: 24874.571s, loss: 1.158, train accuracy: 0.586\n","epoch: 62, time: 24885.103s, loss: 0.388, train accuracy: 0.867\n","epoch: 62, time: 24895.637s, loss: 0.373, train accuracy: 0.852\n","epoch: 62, time: 24906.181s, loss: 0.964, train accuracy: 0.633\n","epoch: 62, time: 24916.716s, loss: 0.960, train accuracy: 0.633\n","epoch: 62, time: 24927.250s, loss: 0.353, train accuracy: 0.859\n","epoch: 62, time: 24937.787s, loss: 0.453, train accuracy: 0.844\n","epoch: 62, validation loss: 0.441852784614319\n","epoch: 63, time: 24950.410s, loss: 0.504, train accuracy: 0.789\n","epoch: 63, time: 24960.939s, loss: 1.169, train accuracy: 0.594\n","epoch: 63, time: 24971.466s, loss: 1.130, train accuracy: 0.570\n","epoch: 63, time: 24981.988s, loss: 0.991, train accuracy: 0.562\n","epoch: 63, time: 24992.516s, loss: 0.353, train accuracy: 0.875\n","epoch: 63, time: 25003.041s, loss: 1.173, train accuracy: 0.570\n","epoch: 63, time: 25013.568s, loss: 1.071, train accuracy: 0.531\n","epoch: 63, time: 25024.105s, loss: 0.459, train accuracy: 0.867\n","epoch: 63, time: 25034.642s, loss: 0.425, train accuracy: 0.812\n","epoch: 63, time: 25045.172s, loss: 1.027, train accuracy: 0.555\n","epoch: 63, time: 25055.706s, loss: 0.348, train accuracy: 0.867\n","epoch: 63, time: 25066.238s, loss: 1.146, train accuracy: 0.531\n","epoch: 63, time: 25076.759s, loss: 0.486, train accuracy: 0.852\n","epoch: 63, time: 25087.292s, loss: 1.280, train accuracy: 0.547\n","epoch: 63, time: 25097.814s, loss: 1.070, train accuracy: 0.539\n","epoch: 63, time: 25108.342s, loss: 0.648, train accuracy: 0.805\n","epoch: 63, time: 25118.885s, loss: 0.336, train accuracy: 0.883\n","epoch: 63, time: 25129.414s, loss: 0.429, train accuracy: 0.789\n","epoch: 63, time: 25139.930s, loss: 0.370, train accuracy: 0.836\n","epoch: 63, time: 25150.453s, loss: 1.394, train accuracy: 0.406\n","epoch: 63, time: 25160.989s, loss: 0.387, train accuracy: 0.859\n","epoch: 63, time: 25171.517s, loss: 0.395, train accuracy: 0.844\n","epoch: 63, time: 25182.047s, loss: 1.223, train accuracy: 0.523\n","epoch: 63, time: 25192.590s, loss: 1.239, train accuracy: 0.523\n","epoch: 63, time: 25203.124s, loss: 0.982, train accuracy: 0.641\n","epoch: 63, time: 25213.642s, loss: 0.459, train accuracy: 0.828\n","epoch: 63, time: 25224.180s, loss: 0.417, train accuracy: 0.852\n","epoch: 63, time: 25234.721s, loss: 0.395, train accuracy: 0.844\n","epoch: 63, time: 25245.250s, loss: 1.090, train accuracy: 0.523\n","epoch: 63, time: 25255.788s, loss: 0.461, train accuracy: 0.844\n","epoch: 63, time: 25266.320s, loss: 0.387, train accuracy: 0.852\n","epoch: 63, time: 25276.860s, loss: 1.148, train accuracy: 0.539\n","epoch: 63, time: 25287.393s, loss: 1.293, train accuracy: 0.461\n","epoch: 63, time: 25297.931s, loss: 0.470, train accuracy: 0.836\n","epoch: 63, time: 25308.447s, loss: 0.460, train accuracy: 0.844\n","epoch: 63, time: 25318.976s, loss: 1.002, train accuracy: 0.633\n","epoch: 63, time: 25329.505s, loss: 1.005, train accuracy: 0.594\n","epoch: 63, time: 25340.037s, loss: 0.475, train accuracy: 0.820\n","epoch: 63, validation loss: 0.43310684203974475\n","epoch: 64, time: 25352.711s, loss: 1.163, train accuracy: 0.531\n","epoch: 64, time: 25363.233s, loss: 0.998, train accuracy: 0.609\n","epoch: 64, time: 25373.755s, loss: 1.089, train accuracy: 0.609\n","epoch: 64, time: 25384.287s, loss: 1.153, train accuracy: 0.562\n","epoch: 64, time: 25394.815s, loss: 0.483, train accuracy: 0.820\n","epoch: 64, time: 25405.355s, loss: 1.308, train accuracy: 0.492\n","epoch: 64, time: 25415.888s, loss: 0.341, train accuracy: 0.836\n","epoch: 64, time: 25426.422s, loss: 0.607, train accuracy: 0.742\n","epoch: 64, time: 25436.955s, loss: 1.180, train accuracy: 0.570\n","epoch: 64, time: 25447.483s, loss: 0.399, train accuracy: 0.844\n","epoch: 64, time: 25458.007s, loss: 1.009, train accuracy: 0.625\n","epoch: 64, time: 25468.536s, loss: 1.142, train accuracy: 0.508\n","epoch: 64, time: 25479.071s, loss: 1.234, train accuracy: 0.531\n","epoch: 64, time: 25489.600s, loss: 0.367, train accuracy: 0.859\n","epoch: 64, time: 25500.132s, loss: 0.418, train accuracy: 0.875\n","epoch: 64, time: 25510.651s, loss: 0.378, train accuracy: 0.844\n","epoch: 64, time: 25521.189s, loss: 1.379, train accuracy: 0.523\n","epoch: 64, time: 25531.721s, loss: 0.386, train accuracy: 0.867\n","epoch: 64, time: 25542.250s, loss: 0.374, train accuracy: 0.836\n","epoch: 64, time: 25552.782s, loss: 0.409, train accuracy: 0.867\n","epoch: 64, time: 25563.316s, loss: 0.467, train accuracy: 0.805\n","epoch: 64, time: 25573.851s, loss: 0.465, train accuracy: 0.789\n","epoch: 64, time: 25584.385s, loss: 1.152, train accuracy: 0.547\n","epoch: 64, time: 25594.917s, loss: 0.389, train accuracy: 0.891\n","epoch: 64, time: 25605.456s, loss: 0.506, train accuracy: 0.805\n","epoch: 64, time: 25616.003s, loss: 0.390, train accuracy: 0.844\n","epoch: 64, time: 25626.538s, loss: 0.517, train accuracy: 0.773\n","epoch: 64, time: 25637.073s, loss: 1.290, train accuracy: 0.555\n","epoch: 64, time: 25647.618s, loss: 1.218, train accuracy: 0.453\n","epoch: 64, time: 25658.155s, loss: 1.098, train accuracy: 0.547\n","epoch: 64, time: 25668.694s, loss: 0.374, train accuracy: 0.883\n","epoch: 64, time: 25679.226s, loss: 0.395, train accuracy: 0.836\n","epoch: 64, time: 25689.763s, loss: 0.466, train accuracy: 0.781\n","epoch: 64, time: 25700.299s, loss: 0.989, train accuracy: 0.594\n","epoch: 64, time: 25710.846s, loss: 1.326, train accuracy: 0.539\n","epoch: 64, time: 25721.379s, loss: 1.107, train accuracy: 0.570\n","epoch: 64, time: 25731.908s, loss: 0.333, train accuracy: 0.867\n","epoch: 64, time: 25742.443s, loss: 0.339, train accuracy: 0.867\n","epoch: 64, validation loss: 0.4235464309070156\n","epoch: 65, time: 25755.113s, loss: 0.276, train accuracy: 0.891\n","epoch: 65, time: 25765.617s, loss: 1.240, train accuracy: 0.523\n","epoch: 65, time: 25776.142s, loss: 1.150, train accuracy: 0.594\n","epoch: 65, time: 25786.649s, loss: 0.436, train accuracy: 0.844\n","epoch: 65, time: 25797.172s, loss: 1.159, train accuracy: 0.523\n","epoch: 65, time: 25807.684s, loss: 1.210, train accuracy: 0.523\n","epoch: 65, time: 25818.190s, loss: 0.547, train accuracy: 0.805\n","epoch: 65, time: 25828.706s, loss: 0.482, train accuracy: 0.820\n","epoch: 65, time: 25839.228s, loss: 1.071, train accuracy: 0.586\n","epoch: 65, time: 25849.750s, loss: 0.569, train accuracy: 0.750\n","epoch: 65, time: 25860.268s, loss: 0.410, train accuracy: 0.844\n","epoch: 65, time: 25870.777s, loss: 1.141, train accuracy: 0.539\n","epoch: 65, time: 25881.293s, loss: 0.441, train accuracy: 0.836\n","epoch: 65, time: 25891.815s, loss: 0.498, train accuracy: 0.812\n","epoch: 65, time: 25902.343s, loss: 0.329, train accuracy: 0.836\n","epoch: 65, time: 25912.878s, loss: 1.006, train accuracy: 0.586\n","epoch: 65, time: 25923.413s, loss: 0.462, train accuracy: 0.797\n","epoch: 65, time: 25933.953s, loss: 0.432, train accuracy: 0.828\n","epoch: 65, time: 25944.501s, loss: 1.156, train accuracy: 0.562\n","epoch: 65, time: 25955.043s, loss: 0.433, train accuracy: 0.828\n","epoch: 65, time: 25965.579s, loss: 1.331, train accuracy: 0.508\n","epoch: 65, time: 25976.114s, loss: 0.580, train accuracy: 0.820\n","epoch: 65, time: 25986.650s, loss: 1.151, train accuracy: 0.523\n","epoch: 65, time: 25997.189s, loss: 0.367, train accuracy: 0.859\n","epoch: 65, time: 26007.724s, loss: 1.107, train accuracy: 0.562\n","epoch: 65, time: 26018.263s, loss: 0.479, train accuracy: 0.805\n","epoch: 65, time: 26028.808s, loss: 0.620, train accuracy: 0.781\n","epoch: 65, time: 26039.350s, loss: 1.296, train accuracy: 0.531\n","epoch: 65, time: 26049.891s, loss: 1.137, train accuracy: 0.531\n","epoch: 65, time: 26060.433s, loss: 1.171, train accuracy: 0.578\n","epoch: 65, time: 26070.972s, loss: 1.381, train accuracy: 0.508\n","epoch: 65, time: 26081.525s, loss: 1.269, train accuracy: 0.562\n","epoch: 65, time: 26092.062s, loss: 0.420, train accuracy: 0.820\n","epoch: 65, time: 26102.601s, loss: 1.116, train accuracy: 0.539\n","epoch: 65, time: 26113.122s, loss: 0.454, train accuracy: 0.828\n","epoch: 65, time: 26123.652s, loss: 1.241, train accuracy: 0.570\n","epoch: 65, time: 26134.185s, loss: 0.414, train accuracy: 0.852\n","epoch: 65, time: 26144.713s, loss: 1.236, train accuracy: 0.500\n","epoch: 65, validation loss: 0.4403686570460354\n","epoch: 66, time: 26157.325s, loss: 0.499, train accuracy: 0.797\n","epoch: 66, time: 26167.839s, loss: 1.025, train accuracy: 0.586\n","epoch: 66, time: 26178.347s, loss: 1.174, train accuracy: 0.523\n","epoch: 66, time: 26188.860s, loss: 0.354, train accuracy: 0.867\n","epoch: 66, time: 26199.378s, loss: 0.385, train accuracy: 0.844\n","epoch: 66, time: 26209.881s, loss: 0.356, train accuracy: 0.859\n","epoch: 66, time: 26220.395s, loss: 0.318, train accuracy: 0.844\n","epoch: 66, time: 26230.914s, loss: 0.366, train accuracy: 0.867\n","epoch: 66, time: 26241.431s, loss: 0.451, train accuracy: 0.820\n","epoch: 66, time: 26251.956s, loss: 0.367, train accuracy: 0.836\n","epoch: 66, time: 26262.477s, loss: 1.263, train accuracy: 0.516\n","epoch: 66, time: 26273.005s, loss: 0.407, train accuracy: 0.844\n","epoch: 66, time: 26283.528s, loss: 1.125, train accuracy: 0.547\n","epoch: 66, time: 26294.053s, loss: 0.529, train accuracy: 0.820\n","epoch: 66, time: 26304.596s, loss: 1.220, train accuracy: 0.555\n","epoch: 66, time: 26315.137s, loss: 0.414, train accuracy: 0.844\n","epoch: 66, time: 26325.682s, loss: 1.222, train accuracy: 0.562\n","epoch: 66, time: 26336.238s, loss: 1.105, train accuracy: 0.586\n","epoch: 66, time: 26346.780s, loss: 0.458, train accuracy: 0.805\n","epoch: 66, time: 26357.317s, loss: 0.424, train accuracy: 0.797\n","epoch: 66, time: 26367.841s, loss: 0.377, train accuracy: 0.844\n","epoch: 66, time: 26378.369s, loss: 0.298, train accuracy: 0.898\n","epoch: 66, time: 26388.904s, loss: 1.004, train accuracy: 0.609\n","epoch: 66, time: 26399.444s, loss: 0.483, train accuracy: 0.820\n","epoch: 66, time: 26409.972s, loss: 1.406, train accuracy: 0.469\n","epoch: 66, time: 26420.496s, loss: 1.160, train accuracy: 0.602\n","epoch: 66, time: 26431.020s, loss: 0.342, train accuracy: 0.875\n","epoch: 66, time: 26441.540s, loss: 0.417, train accuracy: 0.820\n","epoch: 66, time: 26452.066s, loss: 0.378, train accuracy: 0.875\n","epoch: 66, time: 26462.588s, loss: 0.535, train accuracy: 0.797\n","epoch: 66, time: 26473.111s, loss: 1.260, train accuracy: 0.547\n","epoch: 66, time: 26483.627s, loss: 1.099, train accuracy: 0.539\n","epoch: 66, time: 26494.146s, loss: 0.450, train accuracy: 0.820\n","epoch: 66, time: 26504.653s, loss: 0.383, train accuracy: 0.859\n","epoch: 66, time: 26515.179s, loss: 0.357, train accuracy: 0.867\n","epoch: 66, time: 26525.688s, loss: 1.198, train accuracy: 0.523\n","epoch: 66, time: 26536.220s, loss: 0.364, train accuracy: 0.875\n","epoch: 66, time: 26546.742s, loss: 1.066, train accuracy: 0.609\n","epoch: 66, validation loss: 0.4234778912527475\n","epoch: 67, time: 26559.395s, loss: 0.344, train accuracy: 0.891\n","epoch: 67, time: 26569.902s, loss: 0.449, train accuracy: 0.797\n","epoch: 67, time: 26580.414s, loss: 1.183, train accuracy: 0.523\n","epoch: 67, time: 26590.937s, loss: 1.211, train accuracy: 0.578\n","epoch: 67, time: 26601.466s, loss: 0.901, train accuracy: 0.641\n","epoch: 67, time: 26611.993s, loss: 0.431, train accuracy: 0.844\n","epoch: 67, time: 26622.510s, loss: 0.420, train accuracy: 0.859\n","epoch: 67, time: 26633.039s, loss: 0.386, train accuracy: 0.836\n","epoch: 67, time: 26643.579s, loss: 1.242, train accuracy: 0.477\n","epoch: 67, time: 26654.116s, loss: 0.478, train accuracy: 0.836\n","epoch: 67, time: 26664.653s, loss: 1.070, train accuracy: 0.508\n","epoch: 67, time: 26675.195s, loss: 0.852, train accuracy: 0.688\n","epoch: 67, time: 26685.724s, loss: 0.379, train accuracy: 0.867\n","epoch: 67, time: 26696.256s, loss: 0.329, train accuracy: 0.867\n","epoch: 67, time: 26706.799s, loss: 0.394, train accuracy: 0.859\n","epoch: 67, time: 26717.333s, loss: 0.418, train accuracy: 0.836\n","epoch: 67, time: 26727.883s, loss: 1.133, train accuracy: 0.539\n","epoch: 67, time: 26738.427s, loss: 1.485, train accuracy: 0.500\n","epoch: 67, time: 26748.972s, loss: 1.208, train accuracy: 0.570\n","epoch: 67, time: 26759.509s, loss: 1.315, train accuracy: 0.531\n","epoch: 67, time: 26770.050s, loss: 0.371, train accuracy: 0.875\n","epoch: 67, time: 26780.581s, loss: 1.054, train accuracy: 0.586\n","epoch: 67, time: 26791.115s, loss: 0.375, train accuracy: 0.883\n","epoch: 67, time: 26801.651s, loss: 0.569, train accuracy: 0.773\n","epoch: 67, time: 26812.181s, loss: 1.258, train accuracy: 0.523\n","epoch: 67, time: 26822.704s, loss: 0.379, train accuracy: 0.836\n","epoch: 67, time: 26833.235s, loss: 0.338, train accuracy: 0.906\n","epoch: 67, time: 26843.759s, loss: 1.277, train accuracy: 0.500\n","epoch: 67, time: 26854.274s, loss: 0.330, train accuracy: 0.852\n","epoch: 67, time: 26864.790s, loss: 0.363, train accuracy: 0.852\n","epoch: 67, time: 26875.311s, loss: 1.018, train accuracy: 0.555\n","epoch: 67, time: 26885.824s, loss: 0.440, train accuracy: 0.859\n","epoch: 67, time: 26896.345s, loss: 0.419, train accuracy: 0.844\n","epoch: 67, time: 26906.859s, loss: 0.466, train accuracy: 0.812\n","epoch: 67, time: 26917.376s, loss: 1.150, train accuracy: 0.531\n","epoch: 67, time: 26927.883s, loss: 1.054, train accuracy: 0.625\n","epoch: 67, time: 26938.396s, loss: 1.023, train accuracy: 0.594\n","epoch: 67, time: 26948.901s, loss: 1.112, train accuracy: 0.547\n","epoch: 67, validation loss: 0.4159142362918935\n","epoch: 68, time: 26961.674s, loss: 1.065, train accuracy: 0.586\n","epoch: 68, time: 26972.182s, loss: 1.347, train accuracy: 0.531\n","epoch: 68, time: 26982.689s, loss: 1.054, train accuracy: 0.602\n","epoch: 68, time: 26993.193s, loss: 0.459, train accuracy: 0.797\n","epoch: 68, time: 27003.704s, loss: 0.424, train accuracy: 0.828\n","epoch: 68, time: 27014.208s, loss: 1.287, train accuracy: 0.461\n","epoch: 68, time: 27024.713s, loss: 1.326, train accuracy: 0.500\n","epoch: 68, time: 27035.213s, loss: 1.172, train accuracy: 0.586\n","epoch: 68, time: 27045.722s, loss: 0.432, train accuracy: 0.836\n","epoch: 68, time: 27056.243s, loss: 1.474, train accuracy: 0.461\n","epoch: 68, time: 27066.756s, loss: 1.466, train accuracy: 0.461\n","epoch: 68, time: 27077.272s, loss: 1.048, train accuracy: 0.609\n","epoch: 68, time: 27087.783s, loss: 0.435, train accuracy: 0.820\n","epoch: 68, time: 27098.304s, loss: 1.314, train accuracy: 0.516\n","epoch: 68, time: 27108.817s, loss: 0.336, train accuracy: 0.867\n","epoch: 68, time: 27119.331s, loss: 0.453, train accuracy: 0.836\n","epoch: 68, time: 27129.855s, loss: 0.364, train accuracy: 0.859\n","epoch: 68, time: 27140.368s, loss: 1.118, train accuracy: 0.562\n","epoch: 68, time: 27150.876s, loss: 1.368, train accuracy: 0.453\n","epoch: 68, time: 27161.400s, loss: 0.964, train accuracy: 0.648\n","epoch: 68, time: 27171.912s, loss: 0.351, train accuracy: 0.836\n","epoch: 68, time: 27182.433s, loss: 1.259, train accuracy: 0.508\n","epoch: 68, time: 27192.958s, loss: 1.167, train accuracy: 0.508\n","epoch: 68, time: 27203.487s, loss: 0.559, train accuracy: 0.773\n","epoch: 68, time: 27214.025s, loss: 0.486, train accuracy: 0.805\n","epoch: 68, time: 27224.556s, loss: 1.186, train accuracy: 0.578\n","epoch: 68, time: 27235.098s, loss: 1.241, train accuracy: 0.531\n","epoch: 68, time: 27245.638s, loss: 0.423, train accuracy: 0.828\n","epoch: 68, time: 27256.177s, loss: 1.237, train accuracy: 0.484\n","epoch: 68, time: 27266.711s, loss: 0.425, train accuracy: 0.828\n","epoch: 68, time: 27277.251s, loss: 1.087, train accuracy: 0.594\n","epoch: 68, time: 27287.787s, loss: 0.547, train accuracy: 0.797\n","epoch: 68, time: 27298.307s, loss: 0.376, train accuracy: 0.844\n","epoch: 68, time: 27308.831s, loss: 0.459, train accuracy: 0.812\n","epoch: 68, time: 27319.348s, loss: 0.418, train accuracy: 0.805\n","epoch: 68, time: 27329.863s, loss: 0.452, train accuracy: 0.805\n","epoch: 68, time: 27340.376s, loss: 0.417, train accuracy: 0.852\n","epoch: 68, time: 27350.907s, loss: 1.027, train accuracy: 0.602\n","epoch: 68, validation loss: 0.4388221945208527\n","epoch: 69, time: 27363.673s, loss: 1.060, train accuracy: 0.625\n","epoch: 69, time: 27374.185s, loss: 1.239, train accuracy: 0.570\n","epoch: 69, time: 27384.706s, loss: 1.251, train accuracy: 0.508\n","epoch: 69, time: 27395.225s, loss: 0.313, train accuracy: 0.859\n","epoch: 69, time: 27405.735s, loss: 1.059, train accuracy: 0.578\n","epoch: 69, time: 27416.265s, loss: 0.302, train accuracy: 0.883\n","epoch: 69, time: 27426.792s, loss: 0.549, train accuracy: 0.789\n","epoch: 69, time: 27437.319s, loss: 0.398, train accuracy: 0.859\n","epoch: 69, time: 27447.852s, loss: 0.338, train accuracy: 0.875\n","epoch: 69, time: 27458.392s, loss: 1.075, train accuracy: 0.531\n","epoch: 69, time: 27468.914s, loss: 1.296, train accuracy: 0.508\n","epoch: 69, time: 27479.445s, loss: 1.139, train accuracy: 0.539\n","epoch: 69, time: 27489.975s, loss: 1.182, train accuracy: 0.516\n","epoch: 69, time: 27500.497s, loss: 1.199, train accuracy: 0.547\n","epoch: 69, time: 27511.020s, loss: 0.362, train accuracy: 0.891\n","epoch: 69, time: 27521.545s, loss: 0.320, train accuracy: 0.891\n","epoch: 69, time: 27532.063s, loss: 0.447, train accuracy: 0.859\n","epoch: 69, time: 27542.580s, loss: 0.557, train accuracy: 0.781\n","epoch: 69, time: 27553.110s, loss: 1.409, train accuracy: 0.508\n","epoch: 69, time: 27563.622s, loss: 0.482, train accuracy: 0.836\n","epoch: 69, time: 27574.145s, loss: 0.361, train accuracy: 0.852\n","epoch: 69, time: 27584.686s, loss: 1.377, train accuracy: 0.477\n","epoch: 69, time: 27595.211s, loss: 1.120, train accuracy: 0.633\n","epoch: 69, time: 27605.738s, loss: 1.297, train accuracy: 0.516\n","epoch: 69, time: 27616.274s, loss: 1.206, train accuracy: 0.531\n","epoch: 69, time: 27626.809s, loss: 1.223, train accuracy: 0.523\n","epoch: 69, time: 27637.340s, loss: 1.095, train accuracy: 0.609\n","epoch: 69, time: 27647.875s, loss: 1.210, train accuracy: 0.539\n","epoch: 69, time: 27658.405s, loss: 1.168, train accuracy: 0.570\n","epoch: 69, time: 27668.942s, loss: 1.034, train accuracy: 0.633\n","epoch: 69, time: 27679.482s, loss: 1.346, train accuracy: 0.477\n","epoch: 69, time: 27690.017s, loss: 0.505, train accuracy: 0.828\n","epoch: 69, time: 27700.554s, loss: 0.379, train accuracy: 0.844\n","epoch: 69, time: 27711.099s, loss: 0.392, train accuracy: 0.867\n","epoch: 69, time: 27721.636s, loss: 0.266, train accuracy: 0.883\n","epoch: 69, time: 27732.176s, loss: 0.522, train accuracy: 0.789\n","epoch: 69, time: 27742.730s, loss: 0.464, train accuracy: 0.836\n","epoch: 69, time: 27753.271s, loss: 0.363, train accuracy: 0.867\n","epoch: 69, validation loss: 0.43970215695499104\n","epoch: 70, time: 27765.953s, loss: 0.531, train accuracy: 0.820\n","epoch: 70, time: 27776.475s, loss: 1.458, train accuracy: 0.539\n","epoch: 70, time: 27787.009s, loss: 0.369, train accuracy: 0.820\n","epoch: 70, time: 27797.529s, loss: 0.438, train accuracy: 0.828\n","epoch: 70, time: 27808.056s, loss: 0.452, train accuracy: 0.867\n","epoch: 70, time: 27818.586s, loss: 1.186, train accuracy: 0.586\n","epoch: 70, time: 27829.115s, loss: 0.435, train accuracy: 0.844\n","epoch: 70, time: 27839.653s, loss: 1.199, train accuracy: 0.578\n","epoch: 70, time: 27850.188s, loss: 0.314, train accuracy: 0.906\n","epoch: 70, time: 27860.735s, loss: 1.159, train accuracy: 0.578\n","epoch: 70, time: 27871.273s, loss: 1.009, train accuracy: 0.648\n","epoch: 70, time: 27881.806s, loss: 0.415, train accuracy: 0.898\n","epoch: 70, time: 27892.339s, loss: 1.151, train accuracy: 0.555\n","epoch: 70, time: 27902.874s, loss: 1.304, train accuracy: 0.508\n","epoch: 70, time: 27913.406s, loss: 1.338, train accuracy: 0.477\n","epoch: 70, time: 27923.938s, loss: 0.288, train accuracy: 0.898\n","epoch: 70, time: 27934.470s, loss: 0.344, train accuracy: 0.875\n","epoch: 70, time: 27945.012s, loss: 0.474, train accuracy: 0.859\n","epoch: 70, time: 27955.551s, loss: 0.408, train accuracy: 0.875\n","epoch: 70, time: 27966.085s, loss: 0.421, train accuracy: 0.812\n","epoch: 70, time: 27976.636s, loss: 0.354, train accuracy: 0.891\n","epoch: 70, time: 27987.180s, loss: 0.370, train accuracy: 0.867\n","epoch: 70, time: 27997.702s, loss: 1.185, train accuracy: 0.531\n","epoch: 70, time: 28008.233s, loss: 0.420, train accuracy: 0.836\n","epoch: 70, time: 28018.770s, loss: 1.346, train accuracy: 0.445\n","epoch: 70, time: 28029.303s, loss: 1.266, train accuracy: 0.555\n","epoch: 70, time: 28039.833s, loss: 0.367, train accuracy: 0.844\n","epoch: 70, time: 28050.363s, loss: 1.341, train accuracy: 0.477\n","epoch: 70, time: 28060.890s, loss: 1.072, train accuracy: 0.555\n","epoch: 70, time: 28071.422s, loss: 0.310, train accuracy: 0.875\n","epoch: 70, time: 28081.949s, loss: 1.347, train accuracy: 0.469\n","epoch: 70, time: 28092.479s, loss: 1.124, train accuracy: 0.562\n","epoch: 70, time: 28102.998s, loss: 1.126, train accuracy: 0.578\n","epoch: 70, time: 28113.525s, loss: 1.104, train accuracy: 0.570\n","epoch: 70, time: 28124.058s, loss: 1.147, train accuracy: 0.484\n","epoch: 70, time: 28134.594s, loss: 0.383, train accuracy: 0.859\n","epoch: 70, time: 28145.124s, loss: 0.418, train accuracy: 0.836\n","epoch: 70, time: 28155.637s, loss: 1.133, train accuracy: 0.539\n","epoch: 70, validation loss: 0.43056381581180386\n","epoch: 71, time: 28168.371s, loss: 1.279, train accuracy: 0.555\n","epoch: 71, time: 28178.883s, loss: 0.339, train accuracy: 0.875\n","epoch: 71, time: 28189.403s, loss: 0.453, train accuracy: 0.797\n","epoch: 71, time: 28199.944s, loss: 0.348, train accuracy: 0.836\n","epoch: 71, time: 28210.484s, loss: 0.486, train accuracy: 0.820\n","epoch: 71, time: 28221.021s, loss: 1.184, train accuracy: 0.516\n","epoch: 71, time: 28231.563s, loss: 1.022, train accuracy: 0.547\n","epoch: 71, time: 28242.094s, loss: 0.357, train accuracy: 0.883\n","epoch: 71, time: 28252.640s, loss: 0.353, train accuracy: 0.820\n","epoch: 71, time: 28263.188s, loss: 0.441, train accuracy: 0.859\n","epoch: 71, time: 28273.742s, loss: 0.982, train accuracy: 0.594\n","epoch: 71, time: 28284.282s, loss: 1.089, train accuracy: 0.594\n","epoch: 71, time: 28294.827s, loss: 0.607, train accuracy: 0.789\n","epoch: 71, time: 28305.366s, loss: 1.418, train accuracy: 0.500\n","epoch: 71, time: 28315.915s, loss: 1.101, train accuracy: 0.570\n","epoch: 71, time: 28326.459s, loss: 0.465, train accuracy: 0.844\n","epoch: 71, time: 28336.997s, loss: 0.500, train accuracy: 0.789\n","epoch: 71, time: 28347.534s, loss: 0.453, train accuracy: 0.836\n","epoch: 71, time: 28358.078s, loss: 0.322, train accuracy: 0.875\n","epoch: 71, time: 28368.610s, loss: 0.568, train accuracy: 0.789\n","epoch: 71, time: 28379.143s, loss: 0.388, train accuracy: 0.836\n","epoch: 71, time: 28389.677s, loss: 1.221, train accuracy: 0.516\n","epoch: 71, time: 28400.208s, loss: 0.376, train accuracy: 0.875\n","epoch: 71, time: 28410.747s, loss: 1.184, train accuracy: 0.562\n","epoch: 71, time: 28421.278s, loss: 1.003, train accuracy: 0.625\n","epoch: 71, time: 28431.799s, loss: 0.964, train accuracy: 0.656\n","epoch: 71, time: 28442.318s, loss: 0.410, train accuracy: 0.844\n","epoch: 71, time: 28452.850s, loss: 0.330, train accuracy: 0.891\n","epoch: 71, time: 28463.374s, loss: 0.473, train accuracy: 0.781\n","epoch: 71, time: 28473.899s, loss: 0.408, train accuracy: 0.852\n","epoch: 71, time: 28484.427s, loss: 1.135, train accuracy: 0.531\n","epoch: 71, time: 28494.946s, loss: 0.443, train accuracy: 0.820\n","epoch: 71, time: 28505.474s, loss: 0.273, train accuracy: 0.914\n","epoch: 71, time: 28516.001s, loss: 1.203, train accuracy: 0.523\n","epoch: 71, time: 28526.536s, loss: 0.407, train accuracy: 0.836\n","epoch: 71, time: 28537.061s, loss: 0.449, train accuracy: 0.812\n","epoch: 71, time: 28547.582s, loss: 0.460, train accuracy: 0.789\n","epoch: 71, time: 28558.109s, loss: 0.541, train accuracy: 0.789\n","epoch: 71, validation loss: 0.44164556646143704\n","epoch: 72, time: 28570.802s, loss: 0.390, train accuracy: 0.836\n","epoch: 72, time: 28581.317s, loss: 0.289, train accuracy: 0.914\n","epoch: 72, time: 28591.835s, loss: 1.161, train accuracy: 0.516\n","epoch: 72, time: 28602.359s, loss: 0.288, train accuracy: 0.898\n","epoch: 72, time: 28612.893s, loss: 1.197, train accuracy: 0.523\n","epoch: 72, time: 28623.445s, loss: 0.590, train accuracy: 0.773\n","epoch: 72, time: 28633.984s, loss: 1.218, train accuracy: 0.500\n","epoch: 72, time: 28644.534s, loss: 1.120, train accuracy: 0.602\n","epoch: 72, time: 28655.074s, loss: 0.455, train accuracy: 0.812\n","epoch: 72, time: 28665.604s, loss: 0.337, train accuracy: 0.875\n","epoch: 72, time: 28676.149s, loss: 0.384, train accuracy: 0.852\n","epoch: 72, time: 28686.671s, loss: 1.309, train accuracy: 0.508\n","epoch: 72, time: 28697.203s, loss: 1.072, train accuracy: 0.570\n","epoch: 72, time: 28707.734s, loss: 1.149, train accuracy: 0.555\n","epoch: 72, time: 28718.262s, loss: 0.490, train accuracy: 0.773\n","epoch: 72, time: 28728.795s, loss: 1.160, train accuracy: 0.562\n","epoch: 72, time: 28739.327s, loss: 0.404, train accuracy: 0.812\n","epoch: 72, time: 28749.853s, loss: 0.372, train accuracy: 0.859\n","epoch: 72, time: 28760.380s, loss: 1.270, train accuracy: 0.492\n","epoch: 72, time: 28770.905s, loss: 1.075, train accuracy: 0.562\n","epoch: 72, time: 28781.431s, loss: 1.110, train accuracy: 0.547\n","epoch: 72, time: 28791.960s, loss: 0.406, train accuracy: 0.828\n","epoch: 72, time: 28802.490s, loss: 0.370, train accuracy: 0.898\n","epoch: 72, time: 28813.019s, loss: 0.674, train accuracy: 0.742\n","epoch: 72, time: 28823.556s, loss: 1.342, train accuracy: 0.555\n","epoch: 72, time: 28834.083s, loss: 1.447, train accuracy: 0.422\n","epoch: 72, time: 28844.606s, loss: 1.167, train accuracy: 0.492\n","epoch: 72, time: 28855.131s, loss: 0.295, train accuracy: 0.898\n","epoch: 72, time: 28865.653s, loss: 0.378, train accuracy: 0.867\n","epoch: 72, time: 28876.181s, loss: 1.167, train accuracy: 0.570\n","epoch: 72, time: 28886.707s, loss: 0.283, train accuracy: 0.875\n","epoch: 72, time: 28897.231s, loss: 0.303, train accuracy: 0.914\n","epoch: 72, time: 28907.760s, loss: 0.493, train accuracy: 0.805\n","epoch: 72, time: 28918.291s, loss: 0.352, train accuracy: 0.875\n","epoch: 72, time: 28928.808s, loss: 1.076, train accuracy: 0.555\n","epoch: 72, time: 28939.330s, loss: 0.436, train accuracy: 0.859\n","epoch: 72, time: 28949.850s, loss: 1.216, train accuracy: 0.500\n","epoch: 72, time: 28960.365s, loss: 0.476, train accuracy: 0.820\n","epoch: 72, validation loss: 0.4391668911046311\n","epoch: 73, time: 28973.161s, loss: 1.443, train accuracy: 0.445\n","epoch: 73, time: 28983.667s, loss: 1.305, train accuracy: 0.484\n","epoch: 73, time: 28994.170s, loss: 0.939, train accuracy: 0.617\n","epoch: 73, time: 29004.671s, loss: 0.454, train accuracy: 0.828\n","epoch: 73, time: 29015.180s, loss: 0.417, train accuracy: 0.836\n","epoch: 73, time: 29025.682s, loss: 0.409, train accuracy: 0.828\n","epoch: 73, time: 29036.195s, loss: 0.386, train accuracy: 0.867\n","epoch: 73, time: 29046.710s, loss: 0.989, train accuracy: 0.594\n","epoch: 73, time: 29057.228s, loss: 0.417, train accuracy: 0.844\n","epoch: 73, time: 29067.741s, loss: 1.223, train accuracy: 0.562\n","epoch: 73, time: 29078.261s, loss: 0.942, train accuracy: 0.602\n","epoch: 73, time: 29088.786s, loss: 0.346, train accuracy: 0.906\n","epoch: 73, time: 29099.306s, loss: 0.339, train accuracy: 0.836\n","epoch: 73, time: 29109.826s, loss: 0.368, train accuracy: 0.891\n","epoch: 73, time: 29120.362s, loss: 0.409, train accuracy: 0.852\n","epoch: 73, time: 29130.917s, loss: 0.372, train accuracy: 0.883\n","epoch: 73, time: 29141.458s, loss: 0.454, train accuracy: 0.836\n","epoch: 73, time: 29151.969s, loss: 0.493, train accuracy: 0.797\n","epoch: 73, time: 29162.485s, loss: 0.417, train accuracy: 0.828\n","epoch: 73, time: 29172.991s, loss: 1.146, train accuracy: 0.562\n","epoch: 73, time: 29183.509s, loss: 1.131, train accuracy: 0.531\n","epoch: 73, time: 29194.032s, loss: 0.446, train accuracy: 0.836\n","epoch: 73, time: 29204.569s, loss: 1.127, train accuracy: 0.531\n","epoch: 73, time: 29215.105s, loss: 1.042, train accuracy: 0.609\n","epoch: 73, time: 29225.645s, loss: 1.544, train accuracy: 0.469\n","epoch: 73, time: 29236.189s, loss: 0.492, train accuracy: 0.797\n","epoch: 73, time: 29246.732s, loss: 0.489, train accuracy: 0.820\n","epoch: 73, time: 29257.258s, loss: 1.064, train accuracy: 0.578\n","epoch: 73, time: 29267.778s, loss: 1.304, train accuracy: 0.523\n","epoch: 73, time: 29278.297s, loss: 0.378, train accuracy: 0.852\n","epoch: 73, time: 29288.808s, loss: 0.929, train accuracy: 0.586\n","epoch: 73, time: 29299.330s, loss: 0.471, train accuracy: 0.828\n","epoch: 73, time: 29309.852s, loss: 1.350, train accuracy: 0.508\n","epoch: 73, time: 29320.374s, loss: 0.434, train accuracy: 0.844\n","epoch: 73, time: 29330.890s, loss: 0.361, train accuracy: 0.844\n","epoch: 73, time: 29341.415s, loss: 1.149, train accuracy: 0.609\n","epoch: 73, time: 29351.940s, loss: 1.051, train accuracy: 0.570\n","epoch: 73, time: 29362.467s, loss: 1.168, train accuracy: 0.562\n","epoch: 73, validation loss: 0.4377577477998571\n","epoch: 74, time: 29375.162s, loss: 1.140, train accuracy: 0.609\n","epoch: 74, time: 29385.688s, loss: 1.316, train accuracy: 0.484\n","epoch: 74, time: 29396.205s, loss: 1.229, train accuracy: 0.516\n","epoch: 74, time: 29406.726s, loss: 0.359, train accuracy: 0.836\n","epoch: 74, time: 29417.254s, loss: 0.421, train accuracy: 0.836\n","epoch: 74, time: 29427.774s, loss: 0.365, train accuracy: 0.844\n","epoch: 74, time: 29438.311s, loss: 0.401, train accuracy: 0.812\n","epoch: 74, time: 29448.849s, loss: 0.656, train accuracy: 0.805\n","epoch: 74, time: 29459.376s, loss: 1.370, train accuracy: 0.555\n","epoch: 74, time: 29469.912s, loss: 1.003, train accuracy: 0.562\n","epoch: 74, time: 29480.452s, loss: 0.372, train accuracy: 0.844\n","epoch: 74, time: 29490.986s, loss: 1.330, train accuracy: 0.523\n","epoch: 74, time: 29501.536s, loss: 1.046, train accuracy: 0.570\n","epoch: 74, time: 29512.071s, loss: 1.151, train accuracy: 0.531\n","epoch: 74, time: 29522.617s, loss: 0.388, train accuracy: 0.844\n","epoch: 74, time: 29533.167s, loss: 1.220, train accuracy: 0.555\n","epoch: 74, time: 29543.704s, loss: 0.409, train accuracy: 0.852\n","epoch: 74, time: 29554.248s, loss: 1.258, train accuracy: 0.523\n","epoch: 74, time: 29564.787s, loss: 1.270, train accuracy: 0.547\n","epoch: 74, time: 29575.324s, loss: 0.416, train accuracy: 0.828\n","epoch: 74, time: 29585.871s, loss: 1.145, train accuracy: 0.562\n","epoch: 74, time: 29596.415s, loss: 0.419, train accuracy: 0.836\n","epoch: 74, time: 29606.950s, loss: 0.498, train accuracy: 0.812\n","epoch: 74, time: 29617.489s, loss: 1.184, train accuracy: 0.430\n","epoch: 74, time: 29628.034s, loss: 0.375, train accuracy: 0.859\n","epoch: 74, time: 29638.579s, loss: 1.325, train accuracy: 0.469\n","epoch: 74, time: 29649.122s, loss: 1.128, train accuracy: 0.539\n","epoch: 74, time: 29659.670s, loss: 0.430, train accuracy: 0.836\n","epoch: 74, time: 29670.210s, loss: 0.466, train accuracy: 0.844\n","epoch: 74, time: 29680.746s, loss: 0.473, train accuracy: 0.820\n","epoch: 74, time: 29691.290s, loss: 0.464, train accuracy: 0.812\n","epoch: 74, time: 29701.835s, loss: 0.495, train accuracy: 0.781\n","epoch: 74, time: 29712.394s, loss: 0.427, train accuracy: 0.859\n","epoch: 74, time: 29722.936s, loss: 0.420, train accuracy: 0.836\n","epoch: 74, time: 29733.473s, loss: 0.360, train accuracy: 0.844\n","epoch: 74, time: 29744.024s, loss: 0.512, train accuracy: 0.797\n","epoch: 74, time: 29754.573s, loss: 0.353, train accuracy: 0.836\n","epoch: 74, time: 29765.119s, loss: 0.364, train accuracy: 0.883\n","epoch: 74, validation loss: 0.4344847236297278\n","epoch: 75, time: 29777.810s, loss: 1.183, train accuracy: 0.539\n","epoch: 75, time: 29788.346s, loss: 1.365, train accuracy: 0.484\n","epoch: 75, time: 29798.878s, loss: 0.389, train accuracy: 0.867\n","epoch: 75, time: 29809.420s, loss: 0.356, train accuracy: 0.883\n","epoch: 75, time: 29819.962s, loss: 1.094, train accuracy: 0.617\n","epoch: 75, time: 29830.494s, loss: 0.955, train accuracy: 0.609\n","epoch: 75, time: 29841.027s, loss: 1.033, train accuracy: 0.609\n","epoch: 75, time: 29851.571s, loss: 1.049, train accuracy: 0.586\n","epoch: 75, time: 29862.113s, loss: 1.160, train accuracy: 0.531\n","epoch: 75, time: 29872.657s, loss: 0.408, train accuracy: 0.852\n","epoch: 75, time: 29883.199s, loss: 1.237, train accuracy: 0.547\n","epoch: 75, time: 29893.736s, loss: 1.234, train accuracy: 0.516\n","epoch: 75, time: 29904.270s, loss: 1.109, train accuracy: 0.523\n","epoch: 75, time: 29914.805s, loss: 1.167, train accuracy: 0.594\n","epoch: 75, time: 29925.346s, loss: 0.325, train accuracy: 0.867\n","epoch: 75, time: 29935.890s, loss: 1.358, train accuracy: 0.469\n","epoch: 75, time: 29946.431s, loss: 0.361, train accuracy: 0.883\n","epoch: 75, time: 29956.980s, loss: 1.022, train accuracy: 0.594\n","epoch: 75, time: 29967.520s, loss: 1.050, train accuracy: 0.602\n","epoch: 75, time: 29978.062s, loss: 0.394, train accuracy: 0.859\n","epoch: 75, time: 29988.608s, loss: 0.327, train accuracy: 0.898\n","epoch: 75, time: 29999.148s, loss: 0.471, train accuracy: 0.852\n","epoch: 75, time: 30009.701s, loss: 0.505, train accuracy: 0.859\n","epoch: 75, time: 30020.245s, loss: 1.086, train accuracy: 0.555\n","epoch: 75, time: 30030.792s, loss: 0.465, train accuracy: 0.812\n","epoch: 75, time: 30041.345s, loss: 0.386, train accuracy: 0.875\n","epoch: 75, time: 30051.882s, loss: 0.416, train accuracy: 0.820\n","epoch: 75, time: 30062.431s, loss: 1.179, train accuracy: 0.578\n","epoch: 75, time: 30072.986s, loss: 1.313, train accuracy: 0.547\n","epoch: 75, time: 30083.540s, loss: 1.089, train accuracy: 0.562\n","epoch: 75, time: 30094.090s, loss: 0.466, train accuracy: 0.820\n","epoch: 75, time: 30104.637s, loss: 1.068, train accuracy: 0.562\n","epoch: 75, time: 30115.190s, loss: 0.515, train accuracy: 0.805\n","epoch: 75, time: 30125.740s, loss: 0.424, train accuracy: 0.859\n","epoch: 75, time: 30136.293s, loss: 1.191, train accuracy: 0.547\n","epoch: 75, time: 30146.832s, loss: 0.356, train accuracy: 0.828\n","epoch: 75, time: 30157.383s, loss: 1.205, train accuracy: 0.531\n","epoch: 75, time: 30167.928s, loss: 1.195, train accuracy: 0.531\n","epoch: 75, validation loss: 0.4311602870538545\n","epoch: 76, time: 30180.647s, loss: 0.322, train accuracy: 0.859\n","epoch: 76, time: 30191.190s, loss: 0.431, train accuracy: 0.867\n","epoch: 76, time: 30201.719s, loss: 0.458, train accuracy: 0.789\n","epoch: 76, time: 30212.256s, loss: 0.384, train accuracy: 0.891\n","epoch: 76, time: 30222.791s, loss: 0.410, train accuracy: 0.836\n","epoch: 76, time: 30233.326s, loss: 0.305, train accuracy: 0.906\n","epoch: 76, time: 30243.871s, loss: 1.149, train accuracy: 0.531\n","epoch: 76, time: 30254.401s, loss: 0.975, train accuracy: 0.609\n","epoch: 76, time: 30264.940s, loss: 0.417, train accuracy: 0.867\n","epoch: 76, time: 30275.479s, loss: 1.196, train accuracy: 0.555\n","epoch: 76, time: 30286.017s, loss: 1.213, train accuracy: 0.531\n","epoch: 76, time: 30296.564s, loss: 0.352, train accuracy: 0.875\n","epoch: 76, time: 30307.110s, loss: 0.516, train accuracy: 0.820\n","epoch: 76, time: 30317.647s, loss: 1.258, train accuracy: 0.547\n","epoch: 76, time: 30328.191s, loss: 1.231, train accuracy: 0.531\n","epoch: 76, time: 30338.743s, loss: 0.385, train accuracy: 0.883\n","epoch: 76, time: 30349.290s, loss: 0.406, train accuracy: 0.852\n","epoch: 76, time: 30359.836s, loss: 0.525, train accuracy: 0.773\n","epoch: 76, time: 30370.395s, loss: 0.420, train accuracy: 0.805\n","epoch: 76, time: 30380.953s, loss: 0.395, train accuracy: 0.844\n","epoch: 76, time: 30391.501s, loss: 1.077, train accuracy: 0.641\n","epoch: 76, time: 30402.049s, loss: 1.049, train accuracy: 0.594\n","epoch: 76, time: 30412.590s, loss: 1.031, train accuracy: 0.578\n","epoch: 76, time: 30423.140s, loss: 1.114, train accuracy: 0.547\n","epoch: 76, time: 30433.694s, loss: 1.014, train accuracy: 0.617\n","epoch: 76, time: 30444.241s, loss: 1.151, train accuracy: 0.570\n","epoch: 76, time: 30454.800s, loss: 0.486, train accuracy: 0.758\n","epoch: 76, time: 30465.360s, loss: 1.078, train accuracy: 0.633\n","epoch: 76, time: 30475.917s, loss: 0.376, train accuracy: 0.867\n","epoch: 76, time: 30486.461s, loss: 0.427, train accuracy: 0.812\n","epoch: 76, time: 30496.995s, loss: 0.445, train accuracy: 0.812\n","epoch: 76, time: 30507.529s, loss: 0.522, train accuracy: 0.805\n","epoch: 76, time: 30518.066s, loss: 0.377, train accuracy: 0.844\n","epoch: 76, time: 30528.599s, loss: 1.069, train accuracy: 0.602\n","epoch: 76, time: 30539.132s, loss: 1.329, train accuracy: 0.492\n","epoch: 76, time: 30549.662s, loss: 1.170, train accuracy: 0.570\n","epoch: 76, time: 30560.184s, loss: 1.200, train accuracy: 0.570\n","epoch: 76, time: 30570.703s, loss: 0.465, train accuracy: 0.805\n","epoch: 76, validation loss: 0.46277018498256006\n","epoch: 77, time: 30583.439s, loss: 0.369, train accuracy: 0.852\n","epoch: 77, time: 30593.947s, loss: 0.964, train accuracy: 0.625\n","epoch: 77, time: 30604.480s, loss: 0.388, train accuracy: 0.875\n","epoch: 77, time: 30614.999s, loss: 0.453, train accuracy: 0.844\n","epoch: 77, time: 30625.529s, loss: 1.421, train accuracy: 0.516\n","epoch: 77, time: 30636.063s, loss: 1.285, train accuracy: 0.492\n","epoch: 77, time: 30646.593s, loss: 1.237, train accuracy: 0.531\n","epoch: 77, time: 30657.132s, loss: 1.168, train accuracy: 0.516\n","epoch: 77, time: 30667.670s, loss: 0.578, train accuracy: 0.789\n","epoch: 77, time: 30678.206s, loss: 0.517, train accuracy: 0.797\n","epoch: 77, time: 30688.752s, loss: 1.163, train accuracy: 0.562\n","epoch: 77, time: 30699.296s, loss: 1.139, train accuracy: 0.586\n","epoch: 77, time: 30709.837s, loss: 0.425, train accuracy: 0.852\n","epoch: 77, time: 30720.378s, loss: 1.259, train accuracy: 0.523\n","epoch: 77, time: 30730.929s, loss: 0.525, train accuracy: 0.797\n","epoch: 77, time: 30741.464s, loss: 0.383, train accuracy: 0.867\n","epoch: 77, time: 30752.002s, loss: 0.437, train accuracy: 0.844\n","epoch: 77, time: 30762.558s, loss: 1.091, train accuracy: 0.547\n","epoch: 77, time: 30773.106s, loss: 0.430, train accuracy: 0.852\n","epoch: 77, time: 30783.655s, loss: 0.415, train accuracy: 0.852\n","epoch: 77, time: 30794.197s, loss: 0.368, train accuracy: 0.820\n","epoch: 77, time: 30804.751s, loss: 1.217, train accuracy: 0.578\n","epoch: 77, time: 30815.303s, loss: 1.236, train accuracy: 0.523\n","epoch: 77, time: 30825.857s, loss: 1.219, train accuracy: 0.562\n","epoch: 77, time: 30836.418s, loss: 0.390, train accuracy: 0.836\n","epoch: 77, time: 30846.977s, loss: 1.166, train accuracy: 0.500\n","epoch: 77, time: 30857.526s, loss: 0.330, train accuracy: 0.883\n","epoch: 77, time: 30868.090s, loss: 1.121, train accuracy: 0.586\n","epoch: 77, time: 30878.643s, loss: 1.198, train accuracy: 0.539\n","epoch: 77, time: 30889.199s, loss: 0.380, train accuracy: 0.867\n","epoch: 77, time: 30899.757s, loss: 0.344, train accuracy: 0.875\n","epoch: 77, time: 30910.319s, loss: 1.172, train accuracy: 0.578\n","epoch: 77, time: 30920.877s, loss: 0.508, train accuracy: 0.812\n","epoch: 77, time: 30931.435s, loss: 0.442, train accuracy: 0.867\n","epoch: 77, time: 30941.988s, loss: 0.425, train accuracy: 0.844\n","epoch: 77, time: 30952.543s, loss: 1.030, train accuracy: 0.555\n","epoch: 77, time: 30963.098s, loss: 0.462, train accuracy: 0.820\n","epoch: 77, time: 30973.653s, loss: 1.272, train accuracy: 0.555\n","epoch: 77, validation loss: 0.4312181549667041\n","epoch: 78, time: 30986.452s, loss: 0.469, train accuracy: 0.852\n","epoch: 78, time: 30996.999s, loss: 0.439, train accuracy: 0.805\n","epoch: 78, time: 31007.551s, loss: 1.018, train accuracy: 0.555\n","epoch: 78, time: 31018.108s, loss: 0.329, train accuracy: 0.898\n","epoch: 78, time: 31028.644s, loss: 0.477, train accuracy: 0.805\n","epoch: 78, time: 31039.180s, loss: 1.138, train accuracy: 0.562\n","epoch: 78, time: 31049.729s, loss: 0.440, train accuracy: 0.836\n","epoch: 78, time: 31060.291s, loss: 0.380, train accuracy: 0.859\n","epoch: 78, time: 31070.841s, loss: 1.166, train accuracy: 0.531\n","epoch: 78, time: 31081.393s, loss: 0.425, train accuracy: 0.852\n","epoch: 78, time: 31091.932s, loss: 1.392, train accuracy: 0.523\n","epoch: 78, time: 31102.478s, loss: 0.957, train accuracy: 0.664\n","epoch: 78, time: 31113.016s, loss: 1.094, train accuracy: 0.578\n","epoch: 78, time: 31123.554s, loss: 0.480, train accuracy: 0.844\n","epoch: 78, time: 31134.095s, loss: 0.571, train accuracy: 0.844\n","epoch: 78, time: 31144.637s, loss: 0.365, train accuracy: 0.859\n","epoch: 78, time: 31155.170s, loss: 1.199, train accuracy: 0.570\n","epoch: 78, time: 31165.698s, loss: 0.408, train accuracy: 0.844\n","epoch: 78, time: 31176.241s, loss: 0.945, train accuracy: 0.633\n","epoch: 78, time: 31186.782s, loss: 1.032, train accuracy: 0.562\n","epoch: 78, time: 31197.320s, loss: 1.157, train accuracy: 0.562\n","epoch: 78, time: 31207.858s, loss: 0.307, train accuracy: 0.875\n","epoch: 78, time: 31218.390s, loss: 1.025, train accuracy: 0.562\n","epoch: 78, time: 31228.939s, loss: 0.400, train accuracy: 0.828\n","epoch: 78, time: 31239.484s, loss: 0.483, train accuracy: 0.820\n","epoch: 78, time: 31250.029s, loss: 0.288, train accuracy: 0.898\n","epoch: 78, time: 31260.569s, loss: 1.335, train accuracy: 0.484\n","epoch: 78, time: 31271.107s, loss: 0.368, train accuracy: 0.852\n","epoch: 78, time: 31281.645s, loss: 1.025, train accuracy: 0.570\n","epoch: 78, time: 31292.191s, loss: 0.487, train accuracy: 0.781\n","epoch: 78, time: 31302.744s, loss: 1.373, train accuracy: 0.523\n","epoch: 78, time: 31313.297s, loss: 0.434, train accuracy: 0.812\n","epoch: 78, time: 31323.830s, loss: 1.260, train accuracy: 0.555\n","epoch: 78, time: 31334.379s, loss: 0.381, train accuracy: 0.867\n","epoch: 78, time: 31344.916s, loss: 0.381, train accuracy: 0.875\n","epoch: 78, time: 31355.463s, loss: 1.034, train accuracy: 0.570\n","epoch: 78, time: 31366.018s, loss: 1.259, train accuracy: 0.562\n","epoch: 78, time: 31376.559s, loss: 0.445, train accuracy: 0.812\n","epoch: 78, validation loss: 0.4339878721786206\n","epoch: 79, time: 31389.294s, loss: 0.379, train accuracy: 0.859\n","epoch: 79, time: 31399.825s, loss: 0.520, train accuracy: 0.844\n","epoch: 79, time: 31410.354s, loss: 1.399, train accuracy: 0.445\n","epoch: 79, time: 31420.889s, loss: 1.595, train accuracy: 0.469\n","epoch: 79, time: 31431.414s, loss: 0.462, train accuracy: 0.852\n","epoch: 79, time: 31441.951s, loss: 0.401, train accuracy: 0.852\n","epoch: 79, time: 31452.491s, loss: 0.389, train accuracy: 0.852\n","epoch: 79, time: 31463.032s, loss: 0.438, train accuracy: 0.844\n","epoch: 79, time: 31473.577s, loss: 1.128, train accuracy: 0.531\n","epoch: 79, time: 31484.125s, loss: 1.045, train accuracy: 0.555\n","epoch: 79, time: 31494.675s, loss: 0.404, train accuracy: 0.852\n","epoch: 79, time: 31505.214s, loss: 0.417, train accuracy: 0.828\n","epoch: 79, time: 31515.758s, loss: 0.372, train accuracy: 0.859\n","epoch: 79, time: 31526.313s, loss: 0.984, train accuracy: 0.570\n","epoch: 79, time: 31536.859s, loss: 1.300, train accuracy: 0.500\n","epoch: 79, time: 31547.416s, loss: 1.253, train accuracy: 0.539\n","epoch: 79, time: 31557.975s, loss: 1.104, train accuracy: 0.586\n","epoch: 79, time: 31568.524s, loss: 1.508, train accuracy: 0.492\n","epoch: 79, time: 31579.075s, loss: 0.478, train accuracy: 0.812\n","epoch: 79, time: 31589.626s, loss: 0.282, train accuracy: 0.867\n","epoch: 79, time: 31600.164s, loss: 0.449, train accuracy: 0.844\n","epoch: 79, time: 31610.712s, loss: 0.477, train accuracy: 0.828\n","epoch: 79, time: 31621.266s, loss: 0.423, train accuracy: 0.844\n","epoch: 79, time: 31631.824s, loss: 1.159, train accuracy: 0.539\n","epoch: 79, time: 31642.380s, loss: 1.441, train accuracy: 0.477\n","epoch: 79, time: 31652.938s, loss: 1.132, train accuracy: 0.562\n","epoch: 79, time: 31663.486s, loss: 0.506, train accuracy: 0.805\n","epoch: 79, time: 31674.039s, loss: 0.404, train accuracy: 0.828\n","epoch: 79, time: 31684.573s, loss: 1.315, train accuracy: 0.523\n","epoch: 79, time: 31695.126s, loss: 0.375, train accuracy: 0.844\n","epoch: 79, time: 31705.676s, loss: 1.140, train accuracy: 0.547\n","epoch: 79, time: 31716.233s, loss: 0.411, train accuracy: 0.844\n","epoch: 79, time: 31726.775s, loss: 0.459, train accuracy: 0.812\n","epoch: 79, time: 31737.323s, loss: 0.386, train accuracy: 0.875\n","epoch: 79, time: 31747.860s, loss: 0.362, train accuracy: 0.844\n","epoch: 79, time: 31758.400s, loss: 0.330, train accuracy: 0.875\n","epoch: 79, time: 31768.956s, loss: 1.313, train accuracy: 0.445\n","epoch: 79, time: 31779.500s, loss: 0.455, train accuracy: 0.828\n","epoch: 79, validation loss: 0.4425706050035033\n","epoch: 80, time: 31792.285s, loss: 0.429, train accuracy: 0.805\n","epoch: 80, time: 31802.804s, loss: 0.360, train accuracy: 0.836\n","epoch: 80, time: 31813.331s, loss: 1.199, train accuracy: 0.539\n","epoch: 80, time: 31823.857s, loss: 1.232, train accuracy: 0.539\n","epoch: 80, time: 31834.385s, loss: 1.201, train accuracy: 0.531\n","epoch: 80, time: 31844.911s, loss: 1.164, train accuracy: 0.578\n","epoch: 80, time: 31855.450s, loss: 0.448, train accuracy: 0.812\n","epoch: 80, time: 31865.987s, loss: 0.335, train accuracy: 0.867\n","epoch: 80, time: 31876.530s, loss: 0.327, train accuracy: 0.875\n","epoch: 80, time: 31887.066s, loss: 0.418, train accuracy: 0.828\n","epoch: 80, time: 31897.606s, loss: 0.366, train accuracy: 0.867\n","epoch: 80, time: 31908.150s, loss: 1.093, train accuracy: 0.547\n","epoch: 80, time: 31918.688s, loss: 1.220, train accuracy: 0.547\n","epoch: 80, time: 31929.236s, loss: 1.207, train accuracy: 0.539\n","epoch: 80, time: 31939.787s, loss: 0.352, train accuracy: 0.867\n","epoch: 80, time: 31950.327s, loss: 0.531, train accuracy: 0.852\n","epoch: 80, time: 31960.880s, loss: 1.136, train accuracy: 0.609\n","epoch: 80, time: 31971.415s, loss: 1.147, train accuracy: 0.492\n","epoch: 80, time: 31981.960s, loss: 1.115, train accuracy: 0.570\n","epoch: 80, time: 31992.502s, loss: 0.423, train accuracy: 0.820\n","epoch: 80, time: 32003.036s, loss: 1.205, train accuracy: 0.555\n","epoch: 80, time: 32013.586s, loss: 1.020, train accuracy: 0.617\n","epoch: 80, time: 32024.133s, loss: 1.232, train accuracy: 0.547\n","epoch: 80, time: 32034.679s, loss: 0.436, train accuracy: 0.859\n","epoch: 80, time: 32045.229s, loss: 0.393, train accuracy: 0.852\n","epoch: 80, time: 32055.773s, loss: 0.391, train accuracy: 0.828\n","epoch: 80, time: 32066.318s, loss: 0.421, train accuracy: 0.836\n","epoch: 80, time: 32076.866s, loss: 1.182, train accuracy: 0.531\n","epoch: 80, time: 32087.416s, loss: 0.479, train accuracy: 0.797\n","epoch: 80, time: 32097.960s, loss: 0.460, train accuracy: 0.852\n","epoch: 80, time: 32108.506s, loss: 1.199, train accuracy: 0.531\n","epoch: 80, time: 32119.053s, loss: 1.252, train accuracy: 0.508\n","epoch: 80, time: 32129.597s, loss: 0.414, train accuracy: 0.844\n","epoch: 80, time: 32140.145s, loss: 0.967, train accuracy: 0.680\n","epoch: 80, time: 32150.682s, loss: 0.362, train accuracy: 0.852\n","epoch: 80, time: 32161.221s, loss: 0.407, train accuracy: 0.836\n","epoch: 80, time: 32171.753s, loss: 0.406, train accuracy: 0.875\n","epoch: 80, time: 32182.290s, loss: 1.072, train accuracy: 0.602\n","epoch: 80, validation loss: 0.4346557265278627\n","epoch: 81, time: 32194.994s, loss: 0.515, train accuracy: 0.820\n","epoch: 81, time: 32205.524s, loss: 0.275, train accuracy: 0.898\n","epoch: 81, time: 32216.063s, loss: 1.269, train accuracy: 0.500\n","epoch: 81, time: 32226.578s, loss: 1.090, train accuracy: 0.562\n","epoch: 81, time: 32237.111s, loss: 0.337, train accuracy: 0.859\n","epoch: 81, time: 32247.658s, loss: 0.458, train accuracy: 0.812\n","epoch: 81, time: 32258.200s, loss: 1.043, train accuracy: 0.594\n","epoch: 81, time: 32268.742s, loss: 1.400, train accuracy: 0.500\n","epoch: 81, time: 32279.287s, loss: 1.040, train accuracy: 0.602\n","epoch: 81, time: 32289.844s, loss: 1.120, train accuracy: 0.562\n","epoch: 81, time: 32300.381s, loss: 0.510, train accuracy: 0.836\n","epoch: 81, time: 32310.915s, loss: 1.110, train accuracy: 0.578\n","epoch: 81, time: 32321.447s, loss: 0.506, train accuracy: 0.797\n","epoch: 81, time: 32331.982s, loss: 1.051, train accuracy: 0.516\n","epoch: 81, time: 32342.524s, loss: 1.541, train accuracy: 0.461\n","epoch: 81, time: 32353.063s, loss: 1.183, train accuracy: 0.539\n","epoch: 81, time: 32363.623s, loss: 1.078, train accuracy: 0.609\n","epoch: 81, time: 32374.169s, loss: 1.134, train accuracy: 0.578\n","epoch: 81, time: 32384.721s, loss: 0.430, train accuracy: 0.867\n","epoch: 81, time: 32395.269s, loss: 0.375, train accuracy: 0.859\n","epoch: 81, time: 32405.810s, loss: 0.388, train accuracy: 0.867\n","epoch: 81, time: 32416.357s, loss: 0.894, train accuracy: 0.648\n","epoch: 81, time: 32426.895s, loss: 0.372, train accuracy: 0.836\n","epoch: 81, time: 32437.449s, loss: 1.168, train accuracy: 0.602\n","epoch: 81, time: 32448.003s, loss: 1.270, train accuracy: 0.531\n","epoch: 81, time: 32458.539s, loss: 1.265, train accuracy: 0.531\n","epoch: 81, time: 32469.076s, loss: 1.072, train accuracy: 0.617\n","epoch: 81, time: 32479.626s, loss: 1.166, train accuracy: 0.594\n","epoch: 81, time: 32490.164s, loss: 0.342, train accuracy: 0.852\n","epoch: 81, time: 32500.704s, loss: 0.481, train accuracy: 0.867\n","epoch: 81, time: 32511.249s, loss: 1.214, train accuracy: 0.539\n","epoch: 81, time: 32521.812s, loss: 0.322, train accuracy: 0.891\n","epoch: 81, time: 32532.355s, loss: 1.215, train accuracy: 0.547\n","epoch: 81, time: 32542.887s, loss: 0.342, train accuracy: 0.906\n","epoch: 81, time: 32553.444s, loss: 0.329, train accuracy: 0.867\n","epoch: 81, time: 32563.982s, loss: 0.402, train accuracy: 0.859\n","epoch: 81, time: 32574.514s, loss: 1.262, train accuracy: 0.531\n","epoch: 81, time: 32585.057s, loss: 1.279, train accuracy: 0.539\n","epoch: 81, validation loss: 0.4428591733294001\n","epoch: 82, time: 32597.742s, loss: 0.402, train accuracy: 0.875\n","epoch: 82, time: 32608.253s, loss: 0.470, train accuracy: 0.781\n","epoch: 82, time: 32618.791s, loss: 1.136, train accuracy: 0.570\n","epoch: 82, time: 32629.312s, loss: 1.265, train accuracy: 0.531\n","epoch: 82, time: 32639.840s, loss: 0.363, train accuracy: 0.875\n","epoch: 82, time: 32650.371s, loss: 1.267, train accuracy: 0.562\n","epoch: 82, time: 32660.903s, loss: 0.473, train accuracy: 0.844\n","epoch: 82, time: 32671.445s, loss: 0.482, train accuracy: 0.820\n","epoch: 82, time: 32681.986s, loss: 1.161, train accuracy: 0.523\n","epoch: 82, time: 32692.522s, loss: 0.970, train accuracy: 0.609\n","epoch: 82, time: 32703.067s, loss: 0.390, train accuracy: 0.836\n","epoch: 82, time: 32713.614s, loss: 0.504, train accuracy: 0.828\n","epoch: 82, time: 32724.161s, loss: 0.359, train accuracy: 0.898\n","epoch: 82, time: 32734.703s, loss: 0.439, train accuracy: 0.812\n","epoch: 82, time: 32745.249s, loss: 0.378, train accuracy: 0.867\n","epoch: 82, time: 32755.791s, loss: 0.392, train accuracy: 0.875\n","epoch: 82, time: 32766.330s, loss: 0.331, train accuracy: 0.844\n","epoch: 82, time: 32776.876s, loss: 0.340, train accuracy: 0.883\n","epoch: 82, time: 32787.418s, loss: 1.148, train accuracy: 0.602\n","epoch: 82, time: 32797.962s, loss: 1.140, train accuracy: 0.578\n","epoch: 82, time: 32808.506s, loss: 0.382, train accuracy: 0.859\n","epoch: 82, time: 32819.047s, loss: 0.444, train accuracy: 0.820\n","epoch: 82, time: 32829.583s, loss: 0.406, train accuracy: 0.852\n","epoch: 82, time: 32840.124s, loss: 1.333, train accuracy: 0.461\n","epoch: 82, time: 32850.677s, loss: 1.172, train accuracy: 0.570\n","epoch: 82, time: 32861.232s, loss: 0.339, train accuracy: 0.883\n","epoch: 82, time: 32871.774s, loss: 1.066, train accuracy: 0.586\n","epoch: 82, time: 32882.321s, loss: 0.368, train accuracy: 0.867\n","epoch: 82, time: 32892.856s, loss: 0.437, train accuracy: 0.820\n","epoch: 82, time: 32903.397s, loss: 1.148, train accuracy: 0.547\n","epoch: 82, time: 32913.943s, loss: 0.383, train accuracy: 0.852\n","epoch: 82, time: 32924.485s, loss: 0.502, train accuracy: 0.844\n","epoch: 82, time: 32935.031s, loss: 1.023, train accuracy: 0.594\n","epoch: 82, time: 32945.580s, loss: 0.449, train accuracy: 0.844\n","epoch: 82, time: 32956.118s, loss: 1.412, train accuracy: 0.445\n","epoch: 82, time: 32966.671s, loss: 1.230, train accuracy: 0.508\n","epoch: 82, time: 32977.207s, loss: 1.060, train accuracy: 0.570\n","epoch: 82, time: 32987.749s, loss: 0.324, train accuracy: 0.883\n","epoch: 82, validation loss: 0.42271492326818805\n","epoch: 83, time: 33000.480s, loss: 1.092, train accuracy: 0.562\n","epoch: 83, time: 33011.007s, loss: 1.263, train accuracy: 0.516\n","epoch: 83, time: 33021.538s, loss: 1.173, train accuracy: 0.578\n","epoch: 83, time: 33032.070s, loss: 0.337, train accuracy: 0.883\n","epoch: 83, time: 33042.605s, loss: 0.369, train accuracy: 0.883\n","epoch: 83, time: 33053.139s, loss: 1.126, train accuracy: 0.617\n","epoch: 83, time: 33063.686s, loss: 0.335, train accuracy: 0.875\n","epoch: 83, time: 33074.218s, loss: 0.536, train accuracy: 0.773\n","epoch: 83, time: 33084.747s, loss: 0.440, train accuracy: 0.820\n","epoch: 83, time: 33095.292s, loss: 1.363, train accuracy: 0.523\n","epoch: 83, time: 33105.837s, loss: 1.208, train accuracy: 0.422\n","epoch: 83, time: 33116.371s, loss: 1.056, train accuracy: 0.602\n","epoch: 83, time: 33126.915s, loss: 1.240, train accuracy: 0.523\n","epoch: 83, time: 33137.453s, loss: 0.511, train accuracy: 0.789\n","epoch: 83, time: 33147.998s, loss: 0.408, train accuracy: 0.844\n","epoch: 83, time: 33158.540s, loss: 0.355, train accuracy: 0.836\n","epoch: 83, time: 33169.088s, loss: 1.053, train accuracy: 0.555\n","epoch: 83, time: 33179.638s, loss: 0.482, train accuracy: 0.797\n","epoch: 83, time: 33190.189s, loss: 0.351, train accuracy: 0.891\n","epoch: 83, time: 33200.739s, loss: 0.427, train accuracy: 0.836\n","epoch: 83, time: 33211.275s, loss: 0.327, train accuracy: 0.898\n","epoch: 83, time: 33221.815s, loss: 0.334, train accuracy: 0.875\n","epoch: 83, time: 33232.352s, loss: 0.382, train accuracy: 0.852\n","epoch: 83, time: 33242.890s, loss: 0.365, train accuracy: 0.875\n","epoch: 83, time: 33253.431s, loss: 1.117, train accuracy: 0.570\n","epoch: 83, time: 33263.966s, loss: 1.105, train accuracy: 0.602\n","epoch: 83, time: 33274.503s, loss: 0.376, train accuracy: 0.828\n","epoch: 83, time: 33285.043s, loss: 1.210, train accuracy: 0.555\n","epoch: 83, time: 33295.595s, loss: 1.011, train accuracy: 0.625\n","epoch: 83, time: 33306.136s, loss: 0.436, train accuracy: 0.828\n","epoch: 83, time: 33316.686s, loss: 0.379, train accuracy: 0.836\n","epoch: 83, time: 33327.233s, loss: 0.448, train accuracy: 0.828\n","epoch: 83, time: 33337.772s, loss: 1.155, train accuracy: 0.602\n","epoch: 83, time: 33348.311s, loss: 1.111, train accuracy: 0.547\n","epoch: 83, time: 33358.858s, loss: 0.440, train accuracy: 0.820\n","epoch: 83, time: 33369.389s, loss: 0.378, train accuracy: 0.875\n","epoch: 83, time: 33379.935s, loss: 0.448, train accuracy: 0.820\n","epoch: 83, time: 33390.475s, loss: 0.357, train accuracy: 0.891\n","epoch: 83, validation loss: 0.42843058212860813\n","epoch: 84, time: 33403.178s, loss: 0.388, train accuracy: 0.812\n","epoch: 84, time: 33413.716s, loss: 1.174, train accuracy: 0.531\n","epoch: 84, time: 33424.253s, loss: 0.400, train accuracy: 0.828\n","epoch: 84, time: 33434.790s, loss: 0.406, train accuracy: 0.836\n","epoch: 84, time: 33445.316s, loss: 0.443, train accuracy: 0.812\n","epoch: 84, time: 33455.856s, loss: 0.362, train accuracy: 0.875\n","epoch: 84, time: 33466.392s, loss: 1.066, train accuracy: 0.625\n","epoch: 84, time: 33476.942s, loss: 0.418, train accuracy: 0.844\n","epoch: 84, time: 33487.490s, loss: 0.493, train accuracy: 0.805\n","epoch: 84, time: 33498.026s, loss: 0.339, train accuracy: 0.867\n","epoch: 84, time: 33508.559s, loss: 1.383, train accuracy: 0.445\n","epoch: 84, time: 33519.099s, loss: 0.432, train accuracy: 0.844\n","epoch: 84, time: 33529.629s, loss: 0.392, train accuracy: 0.859\n","epoch: 84, time: 33540.160s, loss: 1.023, train accuracy: 0.625\n","epoch: 84, time: 33550.698s, loss: 1.175, train accuracy: 0.562\n","epoch: 84, time: 33561.234s, loss: 0.475, train accuracy: 0.836\n","epoch: 84, time: 33571.773s, loss: 0.431, train accuracy: 0.805\n","epoch: 84, time: 33582.304s, loss: 0.411, train accuracy: 0.844\n","epoch: 84, time: 33592.847s, loss: 0.414, train accuracy: 0.828\n","epoch: 84, time: 33603.390s, loss: 1.195, train accuracy: 0.531\n","epoch: 84, time: 33613.921s, loss: 0.405, train accuracy: 0.797\n","epoch: 84, time: 33624.463s, loss: 1.148, train accuracy: 0.555\n","epoch: 84, time: 33635.006s, loss: 0.320, train accuracy: 0.867\n","epoch: 84, time: 33645.549s, loss: 1.244, train accuracy: 0.562\n","epoch: 84, time: 33656.087s, loss: 0.394, train accuracy: 0.859\n","epoch: 84, time: 33666.631s, loss: 0.460, train accuracy: 0.844\n","epoch: 84, time: 33677.170s, loss: 1.423, train accuracy: 0.500\n","epoch: 84, time: 33687.700s, loss: 0.411, train accuracy: 0.844\n","epoch: 84, time: 33698.243s, loss: 0.451, train accuracy: 0.789\n","epoch: 84, time: 33708.779s, loss: 1.084, train accuracy: 0.594\n","epoch: 84, time: 33719.325s, loss: 0.320, train accuracy: 0.891\n","epoch: 84, time: 33729.860s, loss: 0.301, train accuracy: 0.867\n","epoch: 84, time: 33740.394s, loss: 1.361, train accuracy: 0.492\n","epoch: 84, time: 33750.938s, loss: 1.169, train accuracy: 0.523\n","epoch: 84, time: 33761.480s, loss: 1.133, train accuracy: 0.555\n","epoch: 84, time: 33772.029s, loss: 0.398, train accuracy: 0.836\n","epoch: 84, time: 33782.576s, loss: 0.471, train accuracy: 0.828\n","epoch: 84, time: 33793.116s, loss: 1.227, train accuracy: 0.539\n","epoch: 84, validation loss: 0.4313059075237083\n","epoch: 85, time: 33805.847s, loss: 0.253, train accuracy: 0.898\n","epoch: 85, time: 33816.365s, loss: 0.468, train accuracy: 0.828\n","epoch: 85, time: 33826.892s, loss: 1.069, train accuracy: 0.578\n","epoch: 85, time: 33837.421s, loss: 1.259, train accuracy: 0.523\n","epoch: 85, time: 33847.960s, loss: 0.425, train accuracy: 0.852\n","epoch: 85, time: 33858.493s, loss: 0.378, train accuracy: 0.812\n","epoch: 85, time: 33869.028s, loss: 1.133, train accuracy: 0.555\n","epoch: 85, time: 33879.571s, loss: 0.452, train accuracy: 0.805\n","epoch: 85, time: 33890.109s, loss: 1.079, train accuracy: 0.586\n","epoch: 85, time: 33900.645s, loss: 0.334, train accuracy: 0.891\n","epoch: 85, time: 33911.189s, loss: 1.071, train accuracy: 0.547\n","epoch: 85, time: 33921.719s, loss: 1.203, train accuracy: 0.555\n","epoch: 85, time: 33932.256s, loss: 0.453, train accuracy: 0.812\n","epoch: 85, time: 33942.794s, loss: 0.417, train accuracy: 0.859\n","epoch: 85, time: 33953.328s, loss: 1.132, train accuracy: 0.562\n","epoch: 85, time: 33963.877s, loss: 0.423, train accuracy: 0.805\n","epoch: 85, time: 33974.429s, loss: 1.180, train accuracy: 0.516\n","epoch: 85, time: 33984.972s, loss: 0.341, train accuracy: 0.906\n","epoch: 85, time: 33995.515s, loss: 0.426, train accuracy: 0.828\n","epoch: 85, time: 34006.049s, loss: 0.384, train accuracy: 0.852\n","epoch: 85, time: 34016.601s, loss: 0.300, train accuracy: 0.898\n","epoch: 85, time: 34027.143s, loss: 0.356, train accuracy: 0.836\n","epoch: 85, time: 34037.683s, loss: 1.292, train accuracy: 0.477\n","epoch: 85, time: 34048.232s, loss: 0.399, train accuracy: 0.859\n","epoch: 85, time: 34058.783s, loss: 1.054, train accuracy: 0.594\n","epoch: 85, time: 34069.341s, loss: 0.447, train accuracy: 0.805\n","epoch: 85, time: 34079.889s, loss: 1.154, train accuracy: 0.562\n","epoch: 85, time: 34090.438s, loss: 1.169, train accuracy: 0.570\n","epoch: 85, time: 34100.987s, loss: 0.485, train accuracy: 0.805\n","epoch: 85, time: 34111.535s, loss: 0.374, train accuracy: 0.812\n","epoch: 85, time: 34122.073s, loss: 1.193, train accuracy: 0.555\n","epoch: 85, time: 34132.608s, loss: 1.218, train accuracy: 0.523\n","epoch: 85, time: 34143.139s, loss: 0.311, train accuracy: 0.859\n","epoch: 85, time: 34153.672s, loss: 1.057, train accuracy: 0.570\n","epoch: 85, time: 34164.198s, loss: 1.311, train accuracy: 0.523\n","epoch: 85, time: 34174.726s, loss: 1.288, train accuracy: 0.484\n","epoch: 85, time: 34185.247s, loss: 1.144, train accuracy: 0.578\n","epoch: 85, time: 34195.776s, loss: 0.402, train accuracy: 0.883\n","epoch: 85, validation loss: 0.4322399480828344\n","epoch: 86, time: 34208.534s, loss: 1.184, train accuracy: 0.555\n","epoch: 86, time: 34219.058s, loss: 0.485, train accuracy: 0.797\n","epoch: 86, time: 34229.574s, loss: 0.387, train accuracy: 0.852\n","epoch: 86, time: 34240.105s, loss: 1.188, train accuracy: 0.531\n","epoch: 86, time: 34250.633s, loss: 1.250, train accuracy: 0.531\n","epoch: 86, time: 34261.160s, loss: 0.381, train accuracy: 0.844\n","epoch: 86, time: 34271.697s, loss: 1.285, train accuracy: 0.508\n","epoch: 86, time: 34282.233s, loss: 1.088, train accuracy: 0.617\n","epoch: 86, time: 34292.773s, loss: 0.288, train accuracy: 0.914\n","epoch: 86, time: 34303.317s, loss: 0.417, train accuracy: 0.820\n","epoch: 86, time: 34313.854s, loss: 1.211, train accuracy: 0.578\n","epoch: 86, time: 34324.397s, loss: 0.394, train accuracy: 0.844\n","epoch: 86, time: 34334.942s, loss: 1.133, train accuracy: 0.594\n","epoch: 86, time: 34345.485s, loss: 0.430, train accuracy: 0.836\n","epoch: 86, time: 34356.036s, loss: 0.319, train accuracy: 0.875\n","epoch: 86, time: 34366.584s, loss: 1.181, train accuracy: 0.555\n","epoch: 86, time: 34377.134s, loss: 0.522, train accuracy: 0.812\n","epoch: 86, time: 34387.693s, loss: 0.961, train accuracy: 0.633\n","epoch: 86, time: 34398.235s, loss: 0.514, train accuracy: 0.836\n","epoch: 86, time: 34408.778s, loss: 0.292, train accuracy: 0.898\n","epoch: 86, time: 34419.326s, loss: 1.241, train accuracy: 0.547\n","epoch: 86, time: 34429.873s, loss: 1.187, train accuracy: 0.547\n","epoch: 86, time: 34440.426s, loss: 1.268, train accuracy: 0.516\n","epoch: 86, time: 34450.973s, loss: 0.413, train accuracy: 0.852\n","epoch: 86, time: 34461.512s, loss: 0.323, train accuracy: 0.852\n","epoch: 86, time: 34472.061s, loss: 0.372, train accuracy: 0.852\n","epoch: 86, time: 34482.598s, loss: 0.454, train accuracy: 0.805\n","epoch: 86, time: 34493.129s, loss: 1.108, train accuracy: 0.562\n","epoch: 86, time: 34503.660s, loss: 0.452, train accuracy: 0.828\n","epoch: 86, time: 34514.186s, loss: 1.241, train accuracy: 0.555\n","epoch: 86, time: 34524.711s, loss: 0.348, train accuracy: 0.883\n","epoch: 86, time: 34535.240s, loss: 0.376, train accuracy: 0.836\n","epoch: 86, time: 34545.765s, loss: 0.410, train accuracy: 0.820\n","epoch: 86, time: 34556.295s, loss: 0.306, train accuracy: 0.891\n","epoch: 86, time: 34566.826s, loss: 0.404, train accuracy: 0.828\n","epoch: 86, time: 34577.350s, loss: 0.406, train accuracy: 0.844\n","epoch: 86, time: 34587.880s, loss: 1.260, train accuracy: 0.500\n","epoch: 86, time: 34598.411s, loss: 1.189, train accuracy: 0.570\n","epoch: 86, validation loss: 0.4255550318181133\n","epoch: 87, time: 34611.108s, loss: 0.483, train accuracy: 0.859\n","epoch: 87, time: 34621.620s, loss: 1.152, train accuracy: 0.562\n","epoch: 87, time: 34632.126s, loss: 1.101, train accuracy: 0.555\n","epoch: 87, time: 34642.649s, loss: 1.265, train accuracy: 0.586\n","epoch: 87, time: 34653.170s, loss: 1.314, train accuracy: 0.461\n","epoch: 87, time: 34663.685s, loss: 0.424, train accuracy: 0.828\n","epoch: 87, time: 34674.206s, loss: 0.403, train accuracy: 0.812\n","epoch: 87, time: 34684.736s, loss: 0.432, train accuracy: 0.836\n","epoch: 87, time: 34695.266s, loss: 1.558, train accuracy: 0.453\n","epoch: 87, time: 34705.804s, loss: 0.366, train accuracy: 0.852\n","epoch: 87, time: 34716.327s, loss: 1.078, train accuracy: 0.594\n","epoch: 87, time: 34726.866s, loss: 1.202, train accuracy: 0.555\n","epoch: 87, time: 34737.401s, loss: 1.258, train accuracy: 0.523\n","epoch: 87, time: 34747.927s, loss: 1.181, train accuracy: 0.500\n","epoch: 87, time: 34758.448s, loss: 0.998, train accuracy: 0.609\n","epoch: 87, time: 34768.978s, loss: 1.291, train accuracy: 0.508\n","epoch: 87, time: 34779.516s, loss: 1.152, train accuracy: 0.570\n","epoch: 87, time: 34790.050s, loss: 0.393, train accuracy: 0.828\n","epoch: 87, time: 34800.585s, loss: 0.627, train accuracy: 0.797\n","epoch: 87, time: 34811.104s, loss: 0.430, train accuracy: 0.805\n","epoch: 87, time: 34821.634s, loss: 0.252, train accuracy: 0.906\n","epoch: 87, time: 34832.166s, loss: 0.536, train accuracy: 0.812\n","epoch: 87, time: 34842.694s, loss: 0.946, train accuracy: 0.625\n","epoch: 87, time: 34853.221s, loss: 1.192, train accuracy: 0.586\n","epoch: 87, time: 34863.758s, loss: 0.395, train accuracy: 0.828\n","epoch: 87, time: 34874.295s, loss: 0.461, train accuracy: 0.844\n","epoch: 87, time: 34884.831s, loss: 1.222, train accuracy: 0.547\n","epoch: 87, time: 34895.360s, loss: 0.386, train accuracy: 0.859\n","epoch: 87, time: 34905.877s, loss: 0.961, train accuracy: 0.594\n","epoch: 87, time: 34916.402s, loss: 0.383, train accuracy: 0.875\n","epoch: 87, time: 34926.931s, loss: 1.234, train accuracy: 0.523\n","epoch: 87, time: 34937.466s, loss: 1.100, train accuracy: 0.531\n","epoch: 87, time: 34947.996s, loss: 0.279, train accuracy: 0.891\n","epoch: 87, time: 34958.522s, loss: 0.581, train accuracy: 0.797\n","epoch: 87, time: 34969.053s, loss: 1.323, train accuracy: 0.484\n","epoch: 87, time: 34979.589s, loss: 1.014, train accuracy: 0.609\n","epoch: 87, time: 34990.125s, loss: 1.008, train accuracy: 0.602\n","epoch: 87, time: 35000.652s, loss: 1.183, train accuracy: 0.570\n","epoch: 87, validation loss: 0.42795596174848105\n","Early Stopping!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NuMqxvtnxHQf"},"source":["## Show validation loss"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"aXeud6Por8CJ","outputId":"ea301c92-3465-4541-afea-6c5a394337ae"},"source":["#COPY\r\n","import pandas as pd\r\n","df_plot = pd.DataFrame(data = plot_valloss, columns=['Validation Loss', 'Epoch'])\r\n","df_plot.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Validation Loss</th>\n","      <th>Epoch</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.545350</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.524945</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.488717</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.515029</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.476607</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Validation Loss  Epoch\n","0         0.545350      1\n","1         0.524945      2\n","2         0.488717      3\n","3         0.515029      4\n","4         0.476607      5"]},"metadata":{"tags":[]},"execution_count":0}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"6JTSgfZvr8va","outputId":"fcd9cf37-a7ab-40d5-9564-1d8455aa2063"},"source":["#COPY\r\n","import plotly.express as px\r\n","\r\n","fig = px.line(df_plot, x=\"Epoch\", y=\"Validation Loss\", title='Validation Loss MAT_DA Model')\r\n","fig.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>\n","            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n","                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n","            <div id=\"39bbb0d6-f77d-412b-b54f-47b87308651b\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n","            <script type=\"text/javascript\">\n","                \n","                    window.PLOTLYENV=window.PLOTLYENV || {};\n","                    \n","                if (document.getElementById(\"39bbb0d6-f77d-412b-b54f-47b87308651b\")) {\n","                    Plotly.newPlot(\n","                        '39bbb0d6-f77d-412b-b54f-47b87308651b',\n","                        [{\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"Epoch=%{x}<br>Validation Loss=%{y}\", \"legendgroup\": \"\", \"line\": {\"color\": \"#636efa\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87], \"xaxis\": \"x\", \"y\": [0.545349524346496, 0.5249454680917613, 0.48871745102441133, 0.5150291472355694, 0.476606734589473, 0.47659739311824223, 0.4626345515632426, 0.4433440107907822, 0.4514259930485601, 0.4777448209109845, 0.4542912372520992, 0.45891947596312077, 0.44656741117109366, 0.44494383485078304, 0.4372128698109055, 0.45686698372938483, 0.43834432578290194, 0.4418970976811228, 0.4352051061607881, 0.42898487898586657, 0.4342332501718993, 0.443232506259418, 0.4331035207964972, 0.4317157719689392, 0.4322779499518592, 0.4329477683313366, 0.43594471115801636, 0.4357239541722767, 0.4454693873998707, 0.43097343348236733, 0.44731232460373754, 0.43252058692578316, 0.4297084819152157, 0.42905991691261974, 0.44538662009147695, 0.42533898706248063, 0.42273000365635477, 0.445811583225661, 0.42612892198664293, 0.44066582747232685, 0.4462760562645093, 0.4287994122073086, 0.4389288458488643, 0.4496808561689056, 0.431929467901238, 0.4274855342501008, 0.4319099263786507, 0.42083175451770777, 0.42599812197659825, 0.4361432710690285, 0.4468643074033103, 0.423291783692486, 0.45805159449450245, 0.41836467172418323, 0.427504698414284, 0.43044555568491727, 0.42793184423497493, 0.4346218629877196, 0.437357806511271, 0.4418028582260807, 0.449600787908792, 0.441852784614319, 0.43310684203974475, 0.4235464309070156, 0.4403686570460354, 0.4234778912527475, 0.4159142362918935, 0.4388221945208527, 0.43970215695499104, 0.43056381581180386, 0.44164556646143704, 0.4391668911046311, 0.4377577477998571, 0.4344847236297278, 0.4311602870538545, 0.46277018498256006, 0.4312181549667041, 0.4339878721786206, 0.4425706050035033, 0.4346557265278627, 0.4428591733294001, 0.42271492326818805, 0.42843058212860813, 0.4313059075237083, 0.4322399480828344, 0.4255550318181133, 0.42795596174848105], \"yaxis\": \"y\"}],\n","                        {\"legend\": {\"tracegroupgap\": 0}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Validation Loss MAT_DA Model\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Epoch\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Validation Loss\"}}},\n","                        {\"responsive\": true}\n","                    ).then(function(){\n","                            \n","var gd = document.getElementById('39bbb0d6-f77d-412b-b54f-47b87308651b');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })\n","                };\n","                \n","            </script>\n","        </div>\n","</body>\n","</html>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"ZnyGTtNir_Tu"},"source":["# COPY\r\n","df_plot.to_csv(\"/content/drive/MyDrive/Deep Learning/Project/MAT_DA_valloss.csv\", index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V7mUPLjMnIP7"},"source":["# Testing"]},{"cell_type":"markdown","metadata":{"id":"Gb_pmnOlxQR_"},"source":["## Test model on clean data"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"OwExvF2hmDNT","outputId":"8a4a3b2a-e775-4960-a43e-723a1e71b427"},"source":["correct_total = 0\r\n","\r\n","for i, (x_batch, y_batch) in enumerate(testloader):\r\n","  x_batch, y_batch = x_batch.to(device), y_batch.to(device)  # Move the data to the device that is used\r\n","\r\n","  y_pred = model_matda(x_batch)\r\n","  y_pred_max = torch.argmax(y_pred, dim=1)\r\n","\r\n","  correct_total += torch.sum(torch.eq(y_pred_max, y_batch)).item()\r\n","\r\n","print(f'Accuracy on the test set: {correct_total / len(testset):.3f}')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy on the test set: 0.869\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-bMfJ-29xcgx"},"source":["## Test model on perturbed data"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"YdcWcFrQozXp"},"source":["import pandas as pd\r\n","import seaborn as sn\r\n","from advertorch.utils import predict_from_logits"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"egqg9rVDgh5p"},"source":["\r\n","correct_total = 0\r\n","all_preds = []\r\n","y_true = []\r\n","\r\n","for i, (x_batch, y_batch) in enumerate(testloader):\r\n","  x_batch, y_batch = x_batch.to(device), y_batch.to(device)  # Move the data to the device that is used\r\n","  y_true.extend(y_batch)\r\n","\r\n","  adv = adversary.perturb(x_batch, y_batch)\r\n","\r\n","  y_adv_pred = predict_from_logits(model_matda(adv))\r\n","\r\n","  all_preds.extend(y_adv_pred)\r\n","  correct_total += torch.sum(torch.eq(y_adv_pred, y_batch)).item()\r\n","\r\n","print(f'Accuracy on the test set: {correct_total / len(testset):.3f}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"UtyxFDXpoNsS","outputId":"ce6320d9-d951-4afd-d6ac-49a494410025"},"source":["accuracy = correct_total / len(testset)\r\n","z = 1.96 #for 95% CI\r\n","n = len(all_preds)\r\n","\r\n","interval = z * np.sqrt( (0.824 * (1 - 0.824)) / n)\r\n","interval"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.007470053718956951"]},"metadata":{"tags":[]},"execution_count":0}]},{"cell_type":"markdown","metadata":{"id":"Nw1w3BG2xhqo"},"source":["## Visualise results"]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"XDEt7CDjswjq"},"source":["y_true_int = [int(x.cpu()) for x in y_true]\r\n","y_pred_int = [int(x.cpu()) for x in all_preds]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"VrN3yMS5pzFY","outputId":"4fd3a11c-2cb3-4363-f34c-bd054010b1f3"},"source":["data = {'y_Actual':    y_true_int,\r\n","        'y_Predicted': y_pred_int\r\n","        }\r\n","cm_df = pd.DataFrame(data, columns=['y_Actual', 'y_Predicted'])\r\n","\r\n","cm_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>y_Actual</th>\n","      <th>y_Predicted</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>7</td>\n","      <td>7</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   y_Actual  y_Predicted\n","0         0            0\n","1         7            7\n","2         3            3\n","3         3            3\n","4         7            7"]},"metadata":{"tags":[]},"execution_count":0}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"IYApaz82qOkF","outputId":"34b9e3dd-b1d8-471c-d51a-8680979898b0"},"source":["confusion_matrix = pd.crosstab(cm_df['y_Actual'], cm_df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\r\n","print(confusion_matrix)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Predicted    0    1    2    3    4    5    6    7    8    9\n","Actual                                                     \n","0          622   15   61   78   26   11  159    3   24    0\n","1           23  891    8   67    4    2    3    1    1    0\n","2           50    1  521   19  214    3  158    1   27    1\n","3          120   88   26  575  108    6   56    4   15    1\n","4           19    1  364   54  378    3  174    0    7    0\n","5            8    0    0    1    0  646    1  209    9  125\n","6          230   18  269   76  183    6  173    0   41    1\n","7            0    3    0    2    0  107    0  751    1  135\n","8            8    3   40   11    4   13   33   10  872    4\n","9            1    0    0    1    0   35    0   95    0  866\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"0bfPKtYNqQLo","outputId":"3fcb0eae-fe18-4b50-8f8b-012f35ad54bb"},"source":["sn.heatmap(confusion_matrix, annot=False)\r\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"PGmaMzr2tajb"},"source":[""],"execution_count":null,"outputs":[]}]}